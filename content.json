{"meta":{"title":"Espada","subtitle":"酸萝卜 ♂ 别吃","description":"wdnmd","author":"MatthewHan","url":"https://Matthew-Han.github.io","root":"/"},"pages":[{"title":"about","date":"2019-07-15T06:08:32.000Z","updated":"2025-09-03T13:36:10.878Z","comments":true,"path":"about/index.html","permalink":"https://matthew-han.github.io/about/index.html","excerpt":"","text":"酸萝卜♂别吃！ 介绍 姓名: MatthewHan 现居地: Hangzhou, P.R.China 联系 邮箱: &#x66;&#114;&#x65;&#x65;&#100;&#x6f;&#109;&#x32;&#51;&#x33;&#x40;&#x66;&#111;&#x78;&#x6d;&#x61;&#105;&#108;&#x2e;&#x63;&#111;&#109; WeChat: TWF0dGhldzRkcmVhbQ&#x3D;&#x3D;"},{"title":"archives","date":"2020-10-10T02:27:47.000Z","updated":"2025-09-03T13:30:02.160Z","comments":true,"path":"archives/index.html","permalink":"https://matthew-han.github.io/archives/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-07-12T05:22:11.000Z","updated":"2025-09-03T13:29:50.935Z","comments":true,"path":"tags/index.html","permalink":"https://matthew-han.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"蓄水池抽样","slug":"蓄水池抽样","date":"2022-04-25T03:23:02.000Z","updated":"2025-09-03T02:52:50.979Z","comments":true,"path":"post/0399dca0-c447-11ec-9a1f-a97b5b48cbc0/","permalink":"https://matthew-han.github.io/post/0399dca0-c447-11ec-9a1f-a97b5b48cbc0/","excerpt":"","text":"水塘抽样算法，正好今天的「每日一题」是考这个算法，不写个笔记记录下感觉又快忘完了。 Intro说白了就是有点像时间换空间？在一段超长且长度未知的数据流中，如果需要以一个相同的概率去实时抽样，则需要用到该算法。如果有一个数组 data ，需要随机跳出一个元素，我们之前都是通过 random.nextInt(data.length) 来得到这个元素的下标，从而得到该元素值。但是遇到需要在大小为 $n$ 的数组中有 $k$ 个值是相同的元素，需要以相同概率取出其中一个元素这样的问题，那就不得不先预处理，将这 $k$ 个值相同元素都放到另外的空间中，然后在调用 random 函数进行抽取。但如果是水塘抽样则可以做到像迭代器一样，随时可以停止，在前面的抽样的过程中，保证每个元素时被以相同的概率抽到。该算法的核心就是数学公式，在一次遍历中，可以做到保证每个需要被取出的元素抽到的概率是 $\\frac1k$ 。简单来说就是判断 random.nextInt(cnt) == 0 该条件是否成立， cnt 等于当前加入抽奖池的个数，当 cnt 为 $1$ 时， 第一个元素被选中的概率是 $\\frac11$ ；当 cnt 为 $2$ 时，第 $2$ 个元素被选中概率是 $\\frac12$ ；当 cnt 为 $3$ 是，第 $3$ 个元素被选中概率是 $\\frac13$ ；而且它并不会影响之前的元素是否被选中。当第 $k$ 个元素的概率是 $\\frac1k$，而第 $1$ 个元素被选中的概率就等于 $$\\frac11 \\times (1 - \\frac12) \\times (1 - \\frac13) \\times ··· \\times (1 - \\frac1k) &#x3D; \\frac1k$$所以每个元素被选中的概率都是 $\\frac1k$。这样就完成了随机抽样，并且可以对持续的流进行抽样。 Problem Description给定一个由非重叠的轴对齐矩形的数组 rects ，其中 rects[i] = [ai, bi, xi, yi] 表示 (ai, bi) 是第 i 个矩形的左下角点，(xi, yi) 是第 i 个矩形的右上角角点。设计一个算法来挑选一个随机整数点内的空间所覆盖的一个给定的矩形。矩形周长上的一个点包含在矩形覆盖的空间中。 在一个给定的矩形覆盖的空间内任何整数点都有可能被返回。 请注意 ，整数点是具有整数坐标的点。 实现 Solution 类: Solution(int[][] rects) 用给定的矩形数组 rects 初始化对象。 int[] pick() 返回一个随机的整数点 [u, v] 在给定的矩形所覆盖的空间内。 note 1 &lt;= rects.length &lt;= 100 rects[i].length == 4 -109 &lt;= ai &lt; xi &lt;= 109 -109 &lt;= bi &lt; yi &lt;= 109 xi - ai &lt;= 2000 yi - bi &lt;= 2000 所有的矩形不重叠。 pick 最多被调用 104 次。 e.g. 1234567891011121314输入: [&quot;Solution&quot;,&quot;pick&quot;,&quot;pick&quot;,&quot;pick&quot;,&quot;pick&quot;,&quot;pick&quot;][[[[-2,-2,-1,-1],[1,0,3,0]]],[],[],[],[],[]]输出: [null,[-1,-2],[2,0],[-2,-1],[3,0],[-2,-2]解释：Solution solution = new Solution([[-2, -2, 1, 1], [2, 2, 4, 6]]);solution.pick(); // 返回 [1, -2]solution.pick(); // 返回 [1, -1]solution.pick(); // 返回 [-1, -2]solution.pick(); // 返回 [-2, -2]solution.pick(); // 返回 [0, 0] Solution只需要将所有点取出，利用 TreeSet 的堆排序类似二分查找随机到一个矩形，再对该矩形的 x, y 的最大最小值进行蓄水池抽样即可，注意边长上的点也是符合条件的。 1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123; int max; int[][] rects; TreeMap&lt;Integer, Integer&gt; map; public Solution(int[][] rects) &#123; int prev = 0; this.rects = rects; this.map = new TreeMap&lt;&gt;(); for (int i = 0; i &lt; rects.length; i++) &#123; int curr = (rects[i][2] - rects[i][0] + 1) * (rects[i][3] - rects[i][1] + 1); map.put(curr + prev, i); prev += curr; this.max = prev; &#125; &#125; public int[] pick() &#123; Map.Entry&lt;Integer, Integer&gt; e = map.higherEntry(new Random().nextInt(max)); Integer idx = e.getValue(); int[] rect = rects[idx]; int x = 0; int y = 0; for (int i = rect[0]; i &lt;= rect[2]; i++) &#123; if (ThreadLocalRandom.current().nextInt(i - rect[0] + 1) == 0) &#123; x = i; &#125; &#125; for (int i = rect[1]; i &lt;= rect[3]; i++) &#123; if (ThreadLocalRandom.current().nextInt(i - rect[1] + 1) == 0) &#123; y = i; &#125; &#125; return new int[]&#123;x, y&#125;; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"数据结构：树状数组","slug":"数据结构：树状数组","date":"2022-04-07T03:16:26.000Z","updated":"2025-09-03T02:52:50.979Z","comments":true,"path":"post/1c40fd80-b621-11ec-9548-87744b45139b/","permalink":"https://matthew-han.github.io/post/1c40fd80-b621-11ec-9548-87744b45139b/","excerpt":"","text":"Intro首先，树状数组的应用场景在哪里呢？这里摘抄三叶姐题解中的一段： 针对不同的题目，我们有不同的方案可以选择（假设我们有一个数组）： 数组不变，求区间和：「前缀和」、「树状数组」、「线段树」多次修改某个数（单点），求区间和：「树状数组」、「线段树」多次修改某个区间，输出最终结果：「差分」多次修改某个区间，求区间和：「线段树」、「树状数组」（看修改区间范围大小）多次将某个区间变成同一个数，求区间和：「线段树」、「树状数组」（看修改区间范围大小） 作者：宫水三叶 看起来说前缀和搞不定的可以用树状数组来解决。 那么，树状数组是一种什么样的结构呢？首先它本身还是数组，不是像二叉树、字典树那样真正意义上的树了。因为没有必要做成那样的数据结构，它本身就是利用二进制的特性的来实现查询和更新操作的，数组结构已经完成可以满足分块处理的需求（太强了）。 假设有一个数组 arr = &#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ,11, 12, 13, 14, 15, 16&#125;，那么树状数组 tree 在实际的结构中可能存储的是如下的数据： 他看来还是像一颗二叉树，其中（下标从 1 开始） tree[1] = arr[1] tree[2] = arr[1] + arr[2] tree[3] = arr[3] tree[4] = tree[2] + tree[3] + arr[4] = arr[1] + arr[2] + arr[3] + arr[4] … 简单理解 tree[i] 就等于其子节点的和再加上对应数组坐标的值。那么这个结构能够帮助我们做什么呢？前面我们提到了树状数组本身就是利用二进制的特性。其中这里有个算法 lowbit(int x)，用于取出 x 的最低位 1。 比如 $9$ 的 二进制是 $1001$，他的 lowbit 就是 $1$，$10$ 的二进制是 $1010$，他的 lowbit 就是 $10$ 也就是 $2$。他的算法如下： 123public int lowbit(int x) &#123; return x &amp; -x;&#125; 我在 Intellij IDEA 中打了一个类名，GitHub 的 Copilot 就马上就帮我自动补全这个算法了。。 如果有一个前缀和的数组 a，我们求 $l$ 到 $r$ 的区间怎么求呢？答案一般会是 a[r] - a[l - 1] (l &gt;= 1) 或者 a[r + 1] - a[l] 之类的，其实树状数组也是利用 lowbit 算了个前缀和，但是它的时间复杂度不是 $O(n)$，而是 $O(logn)$。 假如现在要做一个更新操作，将 $idx$ 为 $5$ 的位置更新成 $val$，如果是前缀和数组，就需要从 $5$ 到 $16$ 区间的所有前缀和都更新一遍，但是对于树状数组来说，它的过程就是如图上所示只需要把 $5、6、8、16$ 这些节点更新了就行，因为他们的值都是由 $5$ 累加得到的。两者的代码: 12345678910public void _updateByPre(int idx, int val) &#123; for (int i = idx; i &lt; tree.length; i++) &#123; tree[i] += val - arr[i]; &#125;&#125;public void _updateByBinaryIndexedTree(int idx, int val) &#123; for (int i = idx; i &lt; tree.length; i += lowbit(i)) &#123; tree[i] += val - arr[i]; &#125;&#125; 如果是查询呢？假设我想查找 $idx &#x3D; 15$ 的前缀和，对于前缀和数组可以在 $O(1)$ 的情况下直接得到结果，而树状数组还是得需要 $O(logn)$ 的时间复杂度。树状数组需要把 $15、14、12、8$ 这些节点的值都加起来才能得到 $idx &#x3D; 15$ 的前缀和。两者的代码： 12345678910public int _queryByPre(int idx) &#123; return tree[idx];&#125;public int _queryByBinaryIndexedTree(int idx) &#123; int sum = 0; for (int i = idx; i &gt;= 0; i -= lowbit(i)) &#123; sum += tree[i]; &#125; return sum;&#125; 应用在题目中，求区间的和树状数组怎么做呢？那就是查找到两个端点的前缀和然后相减。树状数组模板代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package 默认模板;import java.util.Arrays;/** * @author &lt;a href=&quot;https://github.com/Matthew-Han&quot;&gt;Matthew Han&lt;/a&gt; * @date 2022/4/7 16:03 07 * @since 1.0 **/public class BinaryIndexedTree &#123; int[] tree; public BinaryIndexedTree(int[] arr) &#123; this.tree = new int[arr.length + 1]; for (int i = 0; i &lt; arr.length; i++) &#123; update(i + 1, arr[i]); &#125; &#125; public void update(int idx, int delta) &#123; for (int i = idx; i &lt; tree.length; i += lowBit(i)) &#123; tree[i] += delta; &#125; &#125; public int query(int idx) &#123; int res = 0; for (int i = idx; i &gt; 0; i -= lowBit(i)) &#123; res += tree[i]; &#125; return res; &#125; public int query(int left, int right) &#123; return query(right + 1) - query(left); &#125; public int lowBit(int x) &#123; return x &amp; -x; &#125; @Override public String toString() &#123; return Arrays.toString(tree); &#125;&#125; 利用 update 方法完成对原始数组初始化前缀和相加，其中注意不能从 0 开始，不然会无限循环，因为 lowBit(0) = 0。 Problem Description给你一个数组 nums ，请你完成两类查询。 其中一类查询要求 更新 数组 nums 下标对应的值 另一类查询要求返回数组 nums 中索引 left 和索引 right 之间（ 包含 ）的 nums 元素的 和 ，其中 left &lt;= right 实现 NumArray 类： NumArray(int[] nums) 用整数数组 nums 初始化对象 void update(int index, int val) 将 nums[index] 的值 更新 为 val int sumRange(int left, int right) 返回数组 nums 中索引 left 和索引 right 之间（ 包含 ）的 nums 元素的 和 （即，nums[left] + nums[left + 1], ..., nums[right]） note 1 &lt;= nums.length &lt;= 3 * 104 -100 &lt;= nums[i] &lt;= 100 0 &lt;= index &lt; nums.length -100 &lt;= val &lt;= 100 0 &lt;= left &lt;= right &lt; nums.length 调用 update 和 sumRange 方法次数不大于 3 * 104 e.g.1234567891011输入：[&quot;NumArray&quot;, &quot;sumRange&quot;, &quot;update&quot;, &quot;sumRange&quot;][[[1, 3, 5]], [0, 2], [1, 2], [0, 2]]输出：[null, 9, null, 8]解释：NumArray numArray = new NumArray([1, 3, 5]);numArray.sumRange(0, 2); // 返回 1 + 3 + 5 = 9numArray.update(1, 2); // nums = [1,2,5]numArray.sumRange(0, 2); // 返回 1 + 2 + 5 = 8 Solution树状数组可以在比较小的时间复杂度下解决这一题：#307 区域和检索 - 数组可修改 123456789101112131415161718192021class NumArray &#123; int[] nums; BinaryIndexedTree bit; public NumArray(int[] nums) &#123; this.nums = nums; this.bit = new BinaryIndexedTree(nums); &#125; public void update(int index, int val) &#123; bit.update(index + 1, val - nums[index]); nums[index] = val; &#125; public int sumRange(int left, int right) &#123; return bit.query(left, right); &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"数组","slug":"数组","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"树","slug":"树","permalink":"https://matthew-han.github.io/tags/%E6%A0%91/"}]},{"title":"力扣杯秋季编程大赛 2021 战队赛","slug":"力扣杯秋季编程大赛-2021-战队赛","date":"2021-10-18T08:05:24.000Z","updated":"2025-09-03T02:52:50.977Z","comments":true,"path":"post/25c59040-2fea-11ec-a701-53779506e8d2/","permalink":"https://matthew-han.github.io/post/25c59040-2fea-11ec-a701-53779506e8d2/","excerpt":"","text":"0x00第一次和小伙伴一起参加战队赛，根据以往经验以为只能做出来一题，结果还真就一题。但是第一题实在是太白给了，都不能算题，所以说相当于一题都没做出来。 坐牢 3 小时，不过我对第二题的印象很深刻，之前对于图中判环、跳环的问题一直处理不好，经此一役，不再害怕。 0x01第 0 题：开幕式焰火沾点白给了，一开始觉得应该没这么简单，还反复检查确认，多少沾点懦弱哥了，递归一套就完事了。 12345678910111213141516171819202122232425public class Lcp44 &#123; Set&lt;Integer&gt; set; /** * 开幕式火焰 * * @param root * @return */ public int numColor(TreeNode root) &#123; set = new HashSet&lt;&gt;(); dfs(root); return set.size(); &#125; public void dfs(TreeNode root) &#123; if (root == null) &#123; return; &#125; set.add(root.val); dfs(root.left); dfs(root.right); &#125;&#125; 第 1 题：自行车炫技赛场这题 byd 是真难读题啊，和小伙伴解题过程中碰到了一个小问题，解决了又来一个。不是 Wrong Answer 、Time Limit Exceeded 就是 Runtime Error 到比赛结束了都一致认为只要存在高度差速度就肯定会一直下降。其实，速度不一定会一直降的。可能会出现速度 +1、-1 一直重复走的情况。所以难点就是如何不走重复路，如果每次递归都开一个 vis 对象去判重的话，内存直接爆了，所以需要一个三维数组，三个向量分别是 x、 y、 v ，其中 x、y 是场地坐标，v 是速度。三个向量确定一个唯一值，重复跳出。我这里用的是 HashSet，比三维数组快一点。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class Solution &#123; int[] dx = &#123;-1, 1, 0, 0&#125;; int[] dy = &#123;0, 0, -1, 1&#125;; List&lt;int[]&gt; ans; Set&lt;String&gt; mem; boolean[][] global; int[] p; public int[][] bicycleYard(int[] position, int[][] terrain, int[][] obstacle) &#123; ans = new ArrayList&lt;&gt;(); mem = new HashSet&lt;&gt;(); global = new boolean[terrain.length][terrain[0].length]; p = position; bfs(1, position[0], position[1], terrain, obstacle); int[][] res = new int[ans.size()][2]; for (int i = 0; i &lt; ans.size(); i++) &#123; res[i] = ans.get(i); &#125; Arrays.sort(res, (o1, o2) -&gt; &#123; if (o1[0] == o2[0]) &#123; return Integer.compare(o1[1], o2[1]); &#125; else &#123; return Integer.compare(o1[0], o2[0]); &#125; &#125;); return res; &#125; public void bfs(int curr, int x, int y, int[][] terrain, int[][] obstacle) &#123; if (x &gt;= 0 &amp;&amp; y &gt;= 0 &amp;&amp; x &lt; terrain.length &amp;&amp; y &lt; terrain[0].length) &#123; for (int i = 0; i &lt; 4; i++) &#123; int newX = x + dx[i]; int newY = y + dy[i]; if (newX &gt;= 0 &amp;&amp; newY &gt;= 0 &amp;&amp; newX &lt; terrain.length &amp;&amp; newY &lt; terrain[0].length) &#123; int next = curr + terrain[x][y] - terrain[newX][newY] - obstacle[newX][newY]; // i, j, v 作为唯一 key String k = newX + &quot;-&quot; + newY + &quot;-&quot; + next; if (mem.contains(k)) &#123; continue; &#125; mem.add(k); if (next &gt;= 1) &#123; if (next == 1 &amp;&amp; (newX != p[0] || newY != p[1]) &amp;&amp; !global[newX][newY]) &#123; global[newX][newY] = true; ans.add(new int[]&#123;newX, newY&#125;); &#125; bfs(next, newX, newY, terrain, obstacle); &#125; &#125; &#125; &#125; &#125;&#125; 第一次组队参加战队赛，虽然结果不太理想，但是和小伙伴一起思考，一起交流的过程还是非常美妙的。想起了 OG 战队的 ceb 在 Ti8 Grand Finals 最后一场开始前的一句话： Lose together, win together, slay together, slay together, slay together.","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"}]},{"title":"LeetCode #1986 完成任务的最少工作时间段","slug":"LeetCode-1986-完成任务的最少工作时间段","date":"2021-09-03T07:39:05.000Z","updated":"2025-09-03T02:52:50.971Z","comments":true,"path":"post/041e2f70-0c8a-11ec-8fd3-4363d76d2529/","permalink":"https://matthew-han.github.io/post/041e2f70-0c8a-11ec-8fd3-4363d76d2529/","excerpt":"","text":"Problem Description你被安排了 n 个任务。任务需要花费的时间用长度为 n 的整数数组 tasks 表示，第 i 个任务需要花费 tasks[i] 小时完成。一个 工作时间段 中，你可以 至多 连续工作 sessionTime 个小时，然后休息一会儿。 你需要按照如下条件完成给定任务： 如果你在某一个时间段开始一个任务，你需要在 同一个 时间段完成它。 完成一个任务后，你可以 立马 开始一个新的任务。 你可以按 任意顺序 完成任务。 给你 tasks 和 sessionTime ，请你按照上述要求，返回完成所有任务所需要的 最少 数目的 工作时间段 。 测试数据保证 sessionTime 大于等于 tasks[i] 中的 最大值 。 note n == tasks.length 1 &lt;= n &lt;= 14 1 &lt;= tasks[i] &lt;= 10 max(tasks[i]) &lt;= sessionTime &lt;= 15 e.g.示例 1：12345输入：tasks = [1,2,3], sessionTime = 3输出：2解释：你可以在两个工作时间段内完成所有任务。- 第一个工作时间段：完成第一和第二个任务，花费 1 + 2 = 3 小时。- 第二个工作时间段：完成第三个任务，花费 3 小时。 示例 2：12345输入：tasks = [3,1,3,1,1], sessionTime = 8输出：2解释：你可以在两个工作时间段内完成所有任务。- 第一个工作时间段：完成除了最后一个任务以外的所有任务，花费 3 + 1 + 3 + 1 = 8 小 时。- 第二个工作时间段，完成最后一个任务，花费 1 小时。 示例 3：123输入：tasks = [1,2,3,4,5], sessionTime = 15输出：1解释：你可以在一个工作时间段以内完成所有任务。 Solution第 256 场周赛周赛第三题，那天早上没爬起来，今天尝试做下，感觉应该是状态压缩的动态规划。不过动态规划始终不会写，就尝试先画递归树，发现重复元素的路径可以压缩（一直没学过状态压缩，难道这就是状态压缩？）就先写个桶记录元素和元素个数，这样就不会走重复路径了。 然后写了个有点别扭的回溯，居然一次过了，看来以后 dp 的题，全用记忆化递归做了是要。。 1234567891011121314151617181920212223242526272829303132333435class Solution &#123; int ans = 0x3f3f3f3f; public int minSessions(int[] tasks, int sessionTime) &#123; int[] bucket = new int[11]; for (int task : tasks) &#123; bucket[task]++; &#125; dfs(bucket, 0, sessionTime, 0, tasks.length); return ans; &#125; public void dfs(int[] bucket, int sum, int sessionTime, int cnt, int len) &#123; if (len == 0) &#123; ans = Math.min(cnt + 1, ans); return; &#125; boolean flag = true; for (int i = 1; i &lt; bucket.length; i++) &#123; if (bucket[i] &gt; 0 &amp;&amp; i + sum &lt;= sessionTime) &#123; flag = false; break; &#125; &#125; if (flag) &#123; dfs(bucket, 0, sessionTime, cnt + 1, len); &#125; else &#123; for (int i = 1; i &lt; bucket.length; i++) &#123; if (bucket[i] &gt; 0 &amp;&amp; i + sum &lt;= sessionTime) &#123; bucket[i]--; dfs(bucket, i + sum, sessionTime, cnt, len - 1); bucket[i]++; &#125; &#125; &#125; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"},{"name":"动态规划","slug":"动态规划","permalink":"https://matthew-han.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"记忆化递归","slug":"记忆化递归","permalink":"https://matthew-han.github.io/tags/%E8%AE%B0%E5%BF%86%E5%8C%96%E9%80%92%E5%BD%92/"}]},{"title":"LeetCode #1981 最小化目标值与所选元素的差","slug":"LeetCode-1981-最小化目标值与所选元素的差","date":"2021-08-24T07:48:40.000Z","updated":"2025-09-03T02:52:50.971Z","comments":true,"path":"post/b26c6980-04af-11ec-b84f-7162fcaf05f2/","permalink":"https://matthew-han.github.io/post/b26c6980-04af-11ec-b84f-7162fcaf05f2/","excerpt":"","text":"Problem Description给你一个大小为 m x n 的整数矩阵 mat 和一个整数 target 。 从矩阵的 每一行 中选择一个整数，你的目标是 最小化 所有选中元素之 和 与目标值 target 的 绝对差 。 返回 最小的绝对差 。 a 和 b 两数字的 绝对差 是 a - b 的绝对值。 note m == mat.length n == mat[i].length 1 &lt;= m, n &lt;= 70 1 &lt;= mat[i][j] &lt;= 70 1 &lt;= target &lt;= 800 e.g.示例 1： 1234567输入：mat = [[1,2,3],[4,5,6],[7,8,9]], target = 13输出：0解释：一种可能的最优选择方案是：- 第一行选出 1- 第二行选出 5- 第三行选出 7所选元素的和是 13 ，等于目标值，所以绝对差是 0 。 示例 2： 1234567输入：mat = [[1],[2],[3]], target = 100输出：94解释：唯一一种选择方案是：- 第一行选出 1- 第二行选出 2- 第三行选出 3所选元素的和是 6 ，绝对差是 94 。 示例 3： 1234输入：mat = [[1,2,9,8,7]], target = 6输出：1解释：最优的选择方案是选出第一行的 7 。绝对差是 1 。 Solution第 255 场周赛第三题，一开始就看出来是 dp 了，不过一下子妹写出来，最后还是靠的记忆化递归过的。 123456789101112131415161718192021222324252627282930313233343536373839public class Solution &#123; Map&lt;Integer, Set&lt;Integer&gt;&gt; map; int ans = 0x3f3f3f3f; /** * 最小化目标值与所选元素的差 * * @param mat * @param target * @return */ public int minimizeTheDifference(int[][] mat, int target) &#123; map = new HashMap&lt;&gt;(); for (int[] ints : mat) &#123; Arrays.sort(ints); &#125; dfs(mat, target, 0, 0); return ans; &#125; public void dfs(int[][] mat, int target, int curr, int step) &#123; if (step &gt;= mat.length) &#123; ans = Math.min(Math.abs(target - curr), ans); return; &#125; for (int i = 0; i &lt; mat[0].length; i++) &#123; if (curr + mat[step][i] - target &gt; ans) &#123; break; &#125; if (map.get(step) != null &amp;&amp; map.get(step).contains(curr + mat[step][i])) &#123; continue; &#125; map.put(step, map.getOrDefault(step, new HashSet&lt;&gt;())); map.get(step).add(curr + mat[step][i]); dfs(mat, target, curr + mat[step][i], step + 1); &#125; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"},{"name":"动态规划","slug":"动态规划","permalink":"https://matthew-han.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"记忆化递归","slug":"记忆化递归","permalink":"https://matthew-han.github.io/tags/%E8%AE%B0%E5%BF%86%E5%8C%96%E9%80%92%E5%BD%92/"}]},{"title":"Redis 笔记十","slug":"Redis-笔记十","date":"2021-07-22T06:50:36.000Z","updated":"2025-09-04T09:22:32.299Z","comments":true,"path":"post/1e254360-eab9-11eb-9401-dda5e5a2198a/","permalink":"https://matthew-han.github.io/post/1e254360-eab9-11eb-9401-dda5e5a2198a/","excerpt":"","text":"Q：Redis主从同步与故障切换，有哪些坑？故障一：主从数据不一致因为主从库间的命令复制是异步进行的。 一方面，主从库间的网络可能会有传输延迟，所以从库不能及时地收到主库发送的命令，从库上执行同步命令的时间就会被延后。 另一方面，即使从库及时收到了主库的命令，但是，也可能会因为正在处理其它复杂度高的命令（例如集合操作命令）而阻塞。 解决方法 首先，在硬件环境配置方面，我们要尽量保证主从库间的网络连接状况良好。例如，我们要避免把主从库部署在不同的机房，或者是避免把网络通信密集的应用（例如数据分析应用）和 Redis 主从库部署在一起。 另外，我们还可以开发一个外部程序来监控主从库间的复制进度。 如果某个从库的进度差值大于我们预设的阈值，我们可以让客户端不再和这个从库连接进行数据读取，这样就可以减少读到不一致数据的情况。不过，为了避免出现客户端和所有从库都不能连接的情况，我们需要把复制进度差值的阈值设置得大一些。 故障二：读取过期数据这个问题主要发生在从库读取数据。 首先，我们都知道 Redis 同时使用了两种策略来删除过期的数据，分别是惰性删除策略和定期删除策略。 其中定期删除策略是指，Redis 每隔一段时间（默认 100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除，这样就可以及时释放一些内存。 因为从库无法删除数据，所以读到过期的数据之后，不会采用惰性删除，会导致返回过期的数据。但是只是 Redis 3.2 之前的版本，在 3.2 版本后，Redis 做了改进，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值。 即使使用了 Redis 3.2 后的版本，还是会出现读到过期数据的情况 因为 Redis 的过期分为两种 EXPIRE 和 PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间； EXPIREAT 和 PEXPIREAT：它们会直接把数据的过期时间设置为具体的一个时间点。 我们分开来看，如果设定的是 xx 秒&#x2F;天 之类的过期，就会因为网络拥塞、延迟导致过期时间延后。主从库全量同步花费了 2 分钟才完成。等从库开始执行这条命令时，时间已经是 9 点 2 分了。而 EXPIRE 命令是把 testkey 的过期时间设置为当前时间的 60s 后，也就是 9 点 3 分。如果客户端在 9 点 2 分 30 秒时在从库上读取 testkey，仍然可以读到 testkey 的值。但是，testkey 实际上已经过期了。 这也太拉胯了。。。讲道理从库同步主库数据（有需要过期的 kv）应该改成同步他的过期时间，而不是时长。 如果设定的是具体的过期日期，也会因为和主库的时钟不一致，从而产生问题。 所以应对过期 key 的问题，需要： 保证良好网络环境，以及使用程序监控从库复制进度，一旦从库复制进度超过阈值，不让客户端连接从库。 使用 Redis 3.2 及以上版本；尽量使用 EXPIREAT&#x2F;PEXPIREAT 命令设置过期时间，避免从库上的数据过期时间滞后。 另外，主从节点上的时钟要保持一致，具体的做法是，让主从节点和相同的 NTP 服务器（时间服务器）进行时钟同步。 故障三：不合理配置项导致的服务挂掉protected-mode 配置项这个配置项的作用是限定哨兵实例能否被其他服务器访问。当这个配置项设置为 yes 时，哨兵实例只能在部署的服务器本地进行访问。当设置为 no 时，其他服务器也可以访问这个哨兵实例。 正因为这样，如果 protected-mode 被设置为 yes，而其余哨兵实例部署在其它服务器，那么，这些哨兵实例间就无法通信。当主库故障时，哨兵无法判断主库下线，也无法进行主从切换，最终 Redis 服务不可用。 所以，我们在应用主从集群时，要注意将 protected-mode 配置项设置为 no，并且将 bind 配置项设置为其它哨兵实例的 IP 地址。这样一来，只有在 bind 中设置了 IP 地址的哨兵，才可以访问当前实例，既保证了实例间能够通信进行主从切换，也保证了哨兵的安全性。 cluster-node-timeout 配置项这个配置项设置了 Redis Cluster 中实例响应心跳消息的超时时间。 如果执行主从切换的实例超过半数，而主从切换时间又过长的话，就可能有半数以上的实例心跳超时，从而可能导致整个集群挂掉。所以，我建议你将 cluster-node-timeout 调大些（例如 10 到 20 秒）。 小结 Q：我们把 slave-read-only 设置为 no，让从库也能直接删除数据，以此来避免读到过期数据，你觉得，这是一个好方法吗？ A：不太好，因为增加一个特性是为了解决 bug，但是采用从库也能写数据的方式无疑是会增加 bug，还是会产生数据不一致的情况。。 Q：Redis支撑秒杀场景的关键技术和实践都有哪些秒杀场景的负载特征对支撑系统的要求第一个特征是瞬时并发访问量非常高。 第二个特征是读多写少，而且读操作是简单的查询操作。 Redis 可以在秒杀场景的哪些环节发挥作用？我们一般可以把秒杀活动分成三个阶段。在每一个阶段，Redis 所发挥的作用也不一样。第一阶段是秒杀活动前。在这个阶段，用户会不断刷新商品详情页，这会导致详情页的瞬时请求量剧增。这个阶段的应对方案，一般是尽量把商品详情页的页面元素静态化，然后使用 CDN 或是浏览器把这些静态化的元素缓存起来。 秒杀开始什么环节可以在 Redis 中进行？ 大量高并发的库存查验请求，这个环节使用 Redis 保存库存量，请求可以直接从 Redis 中读取库存并进行查验。 库存扣减操作，不能交给后端数据库处理。 额外的开销。Redis 中保存了库存量，而库存量的最新值又是数据库在维护，所以数据库更新后，还需要和 Redis 进行同步，这个过程增加了额外的操作逻辑，也带来了额外的开销。 下单量超过实际库存量，出现超售。由于数据库的处理速度较慢，不能及时更新库存余量，这就会导致大量库存查验的请求读取到旧的库存值，并进行下单。此时，就会出现下单数量大于实际的库存量，导致出现超售，这就不符合业务层的要求了。 库存的扣减在 Redis 中进行。而且，为了避免请求查询到旧的库存值，库存查验和库存扣减这两个操作需要保证原子性。 Redis 的哪些方法可以支撑秒杀场景？ 支持高并发。这个很简单，Redis 本身高速处理请求的特性就可以支持高并发。而且，如果有多个秒杀商品，我们也可以使用切片集群，用不同的实例保存不同商品的库存，这样就避免，使用单个实例导致所有的秒杀请求都集中在一个实例上的问题了。不过，需要注意的是，当使用切片集群时，我们要先用 CRC 算法计算不同秒杀商品 key 对应的 Slot，然后，我们在分配 Slot 和实例对应关系时，才能把不同秒杀商品对应的 Slot 分配到不同实例上保存。 保证库存查验和库存扣减原子性执行。针对这条要求，我们就可以使用 Redis 的原子操作或是分布式锁这两个功能特性来支撑了。 基于原子操作支撑秒杀场景虽然 Redis 具有原子性的加减，但是还有一步是查验操作，需要【查询 + 加减库存】，所以需要搞个 lua 脚本实现原子性操作。 基于分布式锁来支撑秒杀场景先让客户端向 Redis 申请分布式锁，只有拿到锁的客户端才能执行库存查验和库存扣减。这样一来，大量的秒杀请求就会在争夺分布式锁时被过滤掉。而且，库存查验和扣减也不用使用原子操作了，因为多个并发客户端只有一个客户端能够拿到锁，已经保证了客户端并发访问的互斥性。 所以，可以使用切片集群中的不同实例来分别保存分布式锁和商品库存信息。使用这种保存方式后，秒杀请求会首先访问保存分布式锁的实例。如果客户端没有拿到锁，这些客户端就不会查询商品库存，这就可以减轻保存库存信息的实例的压力了。 小结 前端静态页面的设计。秒杀页面上能静态化处理的页面元素，我们都要尽量静态化，这样可以充分利用 CDN 或浏览器缓存服务秒杀开始前的请求。 请求拦截和流控。在秒杀系统的接入层，对恶意请求进行拦截，避免对系统的恶意攻击，例如使用黑名单禁止恶意 IP 进行访问。如果 Redis 实例的访问压力过大，为了避免实例崩溃，我们也需要在接入层进行限流，控制进入秒杀系统的请求数量。 库存信息过期时间处理。Redis 中保存的库存信息其实是数据库的缓存，为了避免缓存击穿问题，我们不要给库存信息设置过期时间。 数据库订单异常处理。如果数据库没能成功处理订单，可以增加订单重试功能，保证订单最终能被成功处理。 Q：如何应对数据倾斜数据倾斜有两类。 数据量倾斜：在某些情况下，实例上的数据分布不均衡，某个实例上的数据特别多。 数据访问倾斜：虽然每个集群实例上的数据量相差不大，但是某个实例上的数据是热点数据，被访问得非常频繁。 数据量倾斜的成因和应对方法那么，数据量倾斜是怎么产生的呢？这主要有三个原因，分别是某个实例上保存了 bigkey、Slot 分配不均衡以及 Hash Tag。 bigkey 导致倾斜第一个原因是，某个实例上正好保存了 bigkey。bigkey 的 value 值很大（String 类型），或者是 bigkey 保存了大量集合元素（集合类型），会导致这个实例的数据量增加，内存资源消耗也相应增加。 解决： 一个根本的应对方法是，我们在业务层生成数据时，要尽量避免把过多的数据保存在同一个键值对中。 此外，如果 bigkey 正好是集合类型，我们还有一个方法，就是把 bigkey 拆分成很多个小的集合类型数据，分散保存在不同的实例上。 Slot 分配不均衡导致倾斜如果集群运维人员没有均衡地分配 Slot，就会有大量的数据被分配到同一个 Slot 中，而同一个 Slot 只会在一个实例上分布（该实例配置较高），这就会导致，大量数据被集中到一个实例上，造成数据倾斜。 在 Redis Cluster 中，我们可以使用 3 个命令完成 Slot 迁移。 CLUSTER SETSLOT：使用不同的选项进行三种设置，分别是设置 Slot 要迁入的目标实例，Slot 要迁出的源实例，以及 Slot 所属的实例。 CLUSTER GETKEYSINSLOT：获取某个 Slot 中一定数量的 key。 MIGRATE：把一个 key 从源实例实际迁移到目标实例。 Hash Tag 导致倾斜Hash Tag 是指加在键值对 key 中的一对花括号{}。这对括号会把 key 的一部分括起来，客户端在计算 key 的 CRC16 值时，只对 Hash Tag 花括号中的 key 内容进行计算。如果没用 Hash Tag 的话，客户端计算整个 key 的 CRC16 的值。 其中，user:profile:{3231}和 user:order:{3231}的 Hash Tag 一样，都是 3231，它们的 CRC16 计算值对 16384 取模后的值也是一样的，所以就对应映射到了相同的 Slot 1024 中。user:profile:{5328}和 user:order:{5328}也是相同的映射结果。 小结通常来说，热点数据以服务读操作为主，在这种情况下，我们可以采用热点数据多副本的方法来应对。 这个方法的具体做法是，我们把热点数据复制多份，在每一个数据副本的 key 中增加一个随机前缀，让它和其它副本数据不会被映射到同一个 Slot 中。 热点数据多副本方法只能针对只读的热点数据。如果热点数据是有读有写的话，就不适合采用多副本方法了，因为要保证多副本间的数据一致性，会带来额外的开销。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://matthew-han.github.io/tags/Redis/"}]},{"title":"Redis 笔记九","slug":"Redis-笔记九","date":"2021-07-20T03:16:51.000Z","updated":"2025-09-04T09:22:32.306Z","comments":true,"path":"post/ed60b400-e908-11eb-9a84-25c4901703d0/","permalink":"https://matthew-han.github.io/post/ed60b400-e908-11eb-9a84-25c4901703d0/","excerpt":"","text":"Q：单机上的锁和分布式锁的联系与区别对于在单机上运行的多线程程序来说，锁本身可以用一个变量表示。 变量值为 0 时，表示没有线程获取锁； 变量值为 1 时，表示已经有线程获取到锁了。 和单机上的锁类似，分布式锁同样可以用一个变量来实现。客户端加锁和释放锁的操作逻辑，也和单机上的加锁和释放锁操作逻辑一致：加锁时同样需要判断锁变量的值，根据锁变量值来判断能否加锁成功；释放锁时需要把锁变量值设置为 0，表明客户端不再持有锁。 但是，和线程在单机上操作锁不同的是，在分布式场景下，锁变量需要由一个共享存储系统来维护，只有这样，多个客户端才可以通过访问共享存储系统来访问锁变量。相应的，加锁和释放锁的操作就变成了读取、判断和设置共享存储系统中的锁变量值。 这样一来，我们就可以得出实现分布式锁的两个要求。 要求一：分布式锁的加锁和释放锁的过程，涉及多个操作。所以，在实现分布式锁时，我们需要保证这些锁操作的原子性； 要求二：共享存储系统保存了锁变量，如果共享存储系统发生故障或宕机，那么客户端也就无法进行锁操作了。在实现分布式锁时，我们需要考虑保证共享存储系统的可靠性，进而保证锁的可靠性。 Q：基于单个 Redis 节点实现分布式锁 在图中，客户端 A 和 C 同时请求加锁。因为 Redis 使用单线程处理请求，所以，即使客户端 A 和 C 同时把加锁请求发给了 Redis，Redis 也会串行处理它们的请求。 我们假设 Redis 先处理客户端 A 的请求，读取 lock_key 的值，发现 lock_key 为 0，所以，Redis 就把 lock_key 的 value 置为 1，表示已经加锁了。紧接着，Redis 处理客户端 C 的请求，此时，Redis 会发现 lock_key 的值已经为 1 了，所以就返回加锁失败的信息。 当客户端 A 持有锁时，锁变量 lock_key 的值为 1。客户端 A 执行释放锁操作后，Redis 将 lock_key 的值置为 0，表明已经没有客户端持有锁了。 要想保证操作的原子性，有两种通用的方法，分别是使用 Redis 的单命令操作和使用 Lua 脚本。 首先是 SETNX 命令，它用于设置键值对的值。具体来说，就是这个命令在执行时会判断键值对是否存在，如果不存在，就设置键值对的值，如果存在，就不做任何设置。 123456// 加锁SETNX lock_key 1// 业务逻辑DO THINGS// 释放锁DEL lock_key 对于释放锁操作来说，我们可以在执行完业务逻辑后，使用 DEL 命令删除锁变量。不过，你不用担心锁变量被删除后，其他客户端无法请求加锁了。因为 SETNX 命令在执行时，如果要设置的键值对（也就是锁变量）不存在，SETNX 命令会先创建键值对，然后设置它的值。所以，释放锁之后，再有客户端请求加锁时，SETNX 命令会创建保存锁变量的键值对，并设置锁变量的值，完成加锁。 总结来说，我们就可以用 SETNX 和 DEL 命令组合来实现加锁和释放锁操作。下面的伪代码示例显示了锁操作的过程，你可以看下。 使用 SETNX 和 DEL 命令组合实现分布锁，存在两个潜在的风险。风险一：假如某个客户端在执行了 SETNX 命令、加锁之后，紧接着却在操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。因此，锁就一直被这个客户端持有，其它客户端无法拿到锁，也无法访问共享数据和执行后续操作，这会给业务应用带来影响。 解决：针对这个问题，一个有效的解决方法是，给锁变量设置一个过期时间。这样一来，即使持有锁的客户端发生了异常，无法主动地释放锁，Redis 也会根据锁变量的过期时间，在锁变量过期后，把它删除。其它客户端在锁变量过期后，就可以重新请求加锁，这就不会出现无法加锁的问题了。 风险二：如果客户端 A 执行了 SETNX 命令加锁后，假设客户端 B 执行了 DEL 命令释放锁，此时，客户端 A 的锁就被误释放了。如果客户端 C 正好也在申请加锁，就可以成功获得锁，进而开始操作共享数据。这样一来，客户端 A 和 C 同时在对共享数据进行操作，数据就会被修改错误，这也是业务层不能接受的。 解决：要能区分来自不同客户端的锁操作，可以在锁变量的值上想想办法。在使用 SETNX 命令进行加锁的方法中，我们通过把锁变量值设置为 1 或 0，表示是否加锁成功。1 和 0 只有两种状态，无法表示究竟是哪个客户端进行的锁操作。所以，我们在加锁操作时，可以让每个客户端给锁变量设置一个唯一值，这里的唯一值就可以用来标识当前操作的客户端。在释放锁操作时，客户端需要判断，当前锁变量的值是否和自己的唯一标识相等，只有在相等的情况下，才能释放锁。这样一来，就不会出现误释放锁的问题了。SET 命令在执行时还可以带上 EX 或 PX 选项，用来设置键值对的过期时间。 1234SET key value [EX seconds | PX milliseconds] [NX]// 例子// 加锁, unique_value作为客户端唯一性的标识SET lock_key unique_value NX PX 10000 NX：类似 SETNX，当不存在才 set 一个 kv 虽然使用 SET 命令和 Lua 脚本在 Redis 单节点上实现分布式锁。但是现在只用了一个 Redis 实例来保存锁变量，如果这个 Redis 实例发生故障宕机了，那么锁变量就没有了。此时，客户端也无法进行锁操作了，这就会影响到业务的正常执行。所以，我们在实现分布式锁时，还需要保证锁的可靠性。那怎么提高呢？这就要提到基于多个 Redis 节点实现分布式锁的方式了。 基于多个 Redis 节点实现高可靠的分布式锁Redlock 算法的基本思路，是让客户端和多个独立的 Redis 实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁了，否则加锁失败。这样一来，即使有单个 Redis 实例发生故障，因为锁变量在其它实例上也有保存，所以，客户端仍然可以正常地进行锁操作，锁变量并不会丢失。 第一步是，客户端获取当前时间。 第二步是，客户端按顺序依次向 N 个 Redis 实例执行加锁操作。 这里的加锁操作和在单实例上执行的加锁操作一样，使用 SET 命令，带上 NX，EX&#x2F;PX 选项，以及带上客户端的唯一标识。当然，如果某个 Redis 实例发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给加锁操作设置一个超时时间。 如果客户端在和一个 Redis 实例请求加锁时，一直到超时都没有成功，那么此时，客户端会和下一个 Redis 实例继续请求加锁。加锁操作的超时时间需要远远地小于锁的有效时间，一般也就是设置为几十毫秒。 第三步是，一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时。 客户端只有在满足下面的这两个条件时，才能认为是加锁成功。 条件一：客户端从超过半数（大于等于 N&#x2F;2+1）的 Redis 实例上成功获取到了锁； 条件二：客户端获取锁的总耗时没有超过锁的有效时间。 在满足了这两个条件后，我们需要重新计算这把锁的有效时间，计算的结果是锁的最初有效时间减去客户端为获取锁的总耗时。 Q：Redis 与事务事务的执行过程包含三个步骤，Redis 提供了 MULTI、EXEC 两个命令来完成这三个步骤。 第一步，客户端要使用一个命令显式地表示一个事务的开启。在 Redis 中，这个命令就是 MULTI。 第二步，客户端把事务中本身要执行的具体操作（例如增删改数据）发送给服务器端。这些操作就是 Redis 本身提供的数据读写命令，例如 GET、SET 等。不过，这些命令虽然被客户端发送到了服务器端，但 Redis 实例只是把这些命令暂存到一个命令队列中，并不会立即执行。 第三步，客户端向服务器端发送提交事务的命令，让数据库实际执行第二步中发送的具体操作。Redis 提供的 EXEC 命令就是执行事务提交的。当服务器端收到 EXEC 命令后，才会实际执行命令队列中的所有命令。 12345678910111213#开启事务127.0.0.1:6379&gt; MULTIOK#将a:stock减1，127.0.0.1:6379&gt; DECR a:stockQUEUED#将b:stock减1127.0.0.1:6379&gt; DECR b:stockQUEUED#实际执行事务127.0.0.1:6379&gt; EXEC1) (integer) 42) (integer) 9 Q：Redis 与原子性先说个结论：虽然在这门课中声称是事务，但是 Redis 有个锤子的事务，原子性说白了也没法保障的，拉的一批。 情况一：在执行 EXEC 命令前，客户端发送的操作命令本身就有错误（比如语法错误，使用了不存在的命令），在命令入队时就被 Redis 实例判断出来了。那么整个事务就会被放弃，这个勉强算半个事务。 情况二：事务操作入队时，命令和操作的数据类型不匹配，但 Redis 实例没有检查出错误。例如出现了一条命令成功，一条失败的情况，那么并不会回滚，而是成功的命令就成功的执行了。 Redis 中并没有提供回滚机制。虽然 Redis 提供了 DISCARD 命令，但是，这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。 可以像如下这样主动地终结事务，反正就是没什么卵用。 123456789101112131415#读取a:stock的值4127.0.0.1:6379&gt; GET a:stock&quot;4&quot;#开启事务127.0.0.1:6379&gt; MULTI OK#发送事务的第一个操作，对a:stock减1127.0.0.1:6379&gt; DECR a:stockQUEUED#执行DISCARD命令，主动放弃事务127.0.0.1:6379&gt; DISCARDOK#再次读取a:stock的值，值没有被修改127.0.0.1:6379&gt; GET a:stock&quot;4&quot; 情况三：在执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败。在这种情况下，如果 Redis 开启了 AOF 日志，那么，只会有部分的事务操作被记录到 AOF 日志中。我们需要使用 redis-check-aof 工具检查 AOF 日志文件，这个工具可以把未完成的事务操作从 AOF 文件中去除。使用 AOF 恢复实例后，事务操作不会再被执行，从而保证了原子性。 总结：你看这个 Redis 啊？才搞几个命令就不回滚了，真的太逊了。这个 Redis 就是逊啦。 Q：Redis 与一致性可以理解一致性就是，应用系统从一个正确的状态到另一个正确的状态，而 ACID 就是说事务能够通过 AID 来保证这个 C 的过程。C 是目的，AID 都是手段。 所以个人感觉一致性拉胯 Q：Redis 与隔离性事务的隔离性保证，会受到和事务一起执行的并发操作的影响。而事务执行又可以分成命令入队（EXEC 命令执行前）和命令实际执行（EXEC 命令执行后）两个阶段，所以，我们就针对这两个阶段，分成两种情况来分析： 并发操作在 EXEC 命令前执行，此时，隔离性的保证要使用 WATCH 机制来实现，否则隔离性无法保证； 并发操作在 EXEC 命令后执行，此时，隔离性可以保证。 WATCH 机制：在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行，隔离性也得到了保证。 情况一：一个事务的 EXEC 命令还没有执行时，事务的命令操作是暂存在命令队列中的。此时，如果有其它的并发操作，我们就需要看事务是否使用了 WATCH 机制。 开启了 WATCH 机制（可以保证隔离性）： 未开启 WATCH 机制（无法保证隔离性）： 情况二：并发操作在 EXEC 命令之后被服务器端接收并执行。因为 Redis 是用单线程执行命令，而且，EXEC 命令执行后，Redis 会保证先把命令队列中的所有命令执行完。所以，在这种情况下，并发操作不会破坏事务的隔离性。 Q：Redis 与持久性如果 Redis 没有使用 RDB 或 AOF，那么事务的持久化属性肯定得不到保证。如果 Redis 使用了 RDB 模式，那么，在一个事务执行后，而下一次的 RDB 快照还未执行前，如果发生了实例宕机，这种情况下，事务修改的数据也是不能保证持久化的。 如果 Redis 采用了 AOF 模式，因为 AOF 模式的三种配置选项 no、everysec 和 always 都会存在数据丢失的情况，所以，事务的持久性属性也还是得不到保证。 所以，不管 Redis 采用什么持久化模式，事务的持久性属性是得不到保证的。 小结：Redis 通过 MULTI、EXEC、DISCARD 和 WATCH 四个命令来支持事务机制。 小问题Q：在执行事务时，如果 Redis 实例发生故障，而 Redis 使用了 RDB 机制，那么，事务的原子性还能得到保证吗？ A：可能能，RDB一般没这么快生成，所以理论上可以回滚到上一个 RDB 的版本。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://matthew-han.github.io/tags/Redis/"}]},{"title":"Redis 笔记八","slug":"Redis-笔记八","date":"2021-07-19T03:28:27.000Z","updated":"2025-09-04T09:22:32.297Z","comments":true,"path":"post/61c327b0-e841-11eb-88f0-e9ea35f6ec9b/","permalink":"https://matthew-han.github.io/post/61c327b0-e841-11eb-88f0-e9ea35f6ec9b/","excerpt":"","text":"Q：什么是缓存污染那什么是缓存污染呢？在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。这种情况，就是缓存污染。 如何解决缓存污染？LRU 的不足：因为只看数据的访问时间，使用 LRU 策略在处理扫描式单次查询操作时，无法解决缓存污染。所谓的扫描式单次查询操作，就是指应用对大量的数据进行一次全体读取，每个数据都会被读取，而且只会被读取一次。此时，因为这些被查询的数据刚刚被访问过，所以 LRU 字段值都很大。 LFU 的优化LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。 当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。 为了避免操作链表的开销，Redis 在实现 LRU 策略时使用了两个近似方法： Redis 是用 RedisObject 结构来保存数据的，RedisObject 结构中设置了一个 lru 字段，用来记录数据的访问时间戳； Redis 并没有为所有的数据维护一个全局的链表，而是通过随机采样方式，选取一定数量（例如 10 个）的数据放入候选集合，后续在候选集合中根据 lru 字段值的大小进行筛选。 在此基础上，Redis 在实现 LFU 策略的时候，只是把原来 24bit 大小的 lru 字段，又进一步拆分成了两部分。 ldt 值：lru 字段的前 16bit，表示数据的访问时间戳； counter 值：lru 字段的后 8bit，表示数据的访问次数。 总结一下：当 LFU 策略筛选数据时，Redis 会在候选集合中，根据数据 lru 字段的后 8bit 选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据 lru 字段的前 16bit 值大小，选择访问时间最久远的数据进行淘汰。 Redis 只使用了 8bit 记录数据的访问次数，而 8bit 记录的最大值是 255Redis 也注意到了这个问题。因此，在实现 LFU 策略时，Redis 并没有采用数据每被访问一次，就给对应的 counter 值加 1 的计数规则，而是采用了一个更优化的计数规则。 简单来说，LFU 策略实现的计数规则是：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。 1234double r = (double)rand()/RAND_MAX;...double p = 1.0/(baseval*server.lfu_log_factor+1);if (r &lt; p) counter++; 以下是记录了当 lfu_log_factor 取不同值时，在不同的实际访问次数情况下，计数器的值是如何变化的。 正是因为使用了非线性递增的计数器方法，即使缓存数据的访问次数成千上万，LFU 策略也可以有效地区分不同的访问次数，从而进行合理的数据筛选。从刚才的表中，我们可以看到，当 lfu_log_factor 取值为 10 时，百、千、十万级别的访问次数对应的 counter 值已经有明显的区分了。 我们在应用 LFU 策略时，一般可以将 lfu_log_factor 取值为 10。 在实际业务应用中，LRU 和 LFU 两个策略都有应用。LRU 和 LFU 两个策略关注的数据访问特征各有侧重，LRU 策略更加关注数据的时效性，而 LFU 策略更加关注数据的访问频次。通常情况下，实际应用的负载具有较好的时间局部性，所以 LRU 策略的应用会更加广泛。但是，在扫描式查询的应用场景中，LFU 策略就可以很好地应对缓存污染问题了。 Q：Redis如何应对并发访问这里是指的是多条 Redis 命令不具备原子性，Redis 是单线程执行单条指令时当然不会被发生竞争的问题。 为了保证并发访问的正确性，Redis 提供了两种方法，分别是加锁和原子操作。 原子操作是另一种提供并发访问控制的方法。原子操作是指执行过程保持原子性的操作，而且原子操作执行时并不需要再加锁，实现了无锁操作。这样一来，既能保证并发控制，还能减少对系统并发性能的影响。 并发访问中需要对什么进行控制？并发访问控制对应的操作主要是数据修改操作。当客户端需要修改数据时，基本流程分成两步： 客户端先把数据读取到本地，在本地进行修改； 客户端修改完数据后，再写回 Redis。 我们把这个流程叫做“读取 - 修改 - 写回”操作（Read-Modify-Write，简称为 RMW 操作）。当有多个客户端对同一份数据执行 RMW 操作的话，我们就需要让 RMW 操作涉及的代码以原子性方式执行。访问同一份数据的 RMW 操作代码，就叫做临界区代码。 可以看到，客户端 A 在 t1 时读取库存值 10 并扣减 1，在 t2 时，客户端 A 还没有把扣减后的库存值 9 写回 Redis，而在此时，客户端 B 读到库存值 10，也扣减了 1，B 记录的库存值也为 9 了。等到 t3 时，A 往 Redis 写回了库存值 9，而到 t4 时，B 也写回了库存值 9。如果按正确的逻辑处理，客户端 A 和 B 对库存值各做了一次扣减，库存值应该为 8。所以，这里的库存值明显更新错了。 Redis 的两种原子操作方法为了实现并发控制要求的临界区代码互斥执行，Redis 的原子操作采用了两种方法： 把多个操作在 Redis 中实现成一个操作，也就是单命令操作； 把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本。 我们先来看下 Redis 本身的单命令操作。Redis 是使用单线程来串行处理客户端的请求操作命令的，所以，当 Redis 执行某个命令操作时，其他命令是无法执行的，这相当于命令操作是互斥执行的。当然，Redis 的快照生成、AOF 重写这些操作，可以使用后台线程或者是子进程执行，也就是和主线程的操作并行执行。不过，这些操作只是读取数据，不会修改数据，所以，我们并不需要对它们做并发控制。 Redis 提供了 INCR&#x2F;DECR 命令，把这三个操作转变为一个原子操作了。INCR&#x2F;DECR 命令可以对数据进行增值 &#x2F; 减值操作，而且它们本身就是单个命令操作，Redis 在执行它们时，本身就具有互斥性。 所以，如果我们执行的 RMW 操作是对数据进行增减值的话，Redis 提供的原子操作 INCR 和 DECR 可以直接帮助我们进行并发控制。 lua 脚本Redis 的 Lua 脚本可以包含多个操作，这些操作都会以原子性的方式执行，绕开了单命令操作的限制。不过，如果把很多操作都放在 Lua 脚本中原子执行，会导致 Redis 执行脚本的时间增加，同样也会降低 Redis 的并发性能。所以建议在编写 Lua 脚本时，避免把不需要做并发控制的操作写入脚本中。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://matthew-han.github.io/tags/Redis/"}]},{"title":"Redis 笔记七","slug":"Redis-笔记七","date":"2021-07-15T07:31:53.000Z","updated":"2025-09-04T09:22:32.320Z","comments":true,"path":"post/ba05d6d0-e53e-11eb-908d-87267ebfe3de/","permalink":"https://matthew-han.github.io/post/ba05d6d0-e53e-11eb-908d-87267ebfe3de/","excerpt":"","text":"Q：缓存异常（上）：解决缓存和数据库的数据不一致问题缓存和数据库的数据不一致是如何发生的？首先，我们得清楚“数据的一致性”具体是啥意思。其实，这里的“一致性”包含了两种情况： 缓存中有数据，那么，缓存的数据值需要和数据库中的值相同； 缓存中本身没有数据，那么，数据库中的值必须是最新值。 不符合这两种情况的，就属于缓存和数据库的数据不一致问题了。 对于读写缓存来说，如果要对数据进行增删改，就需要在缓存中进行，同时还要根据采取的写回策略，决定是否同步写回到数据库中。 同步直写策略：写缓存时，也同步写数据库，缓存和数据库中的数据一致； 异步写回策略：写缓存时不同步写数据库，等到数据从缓存中淘汰时，再写回数据库。使用这种策略时，如果数据还没有写回数据库，缓存就发生了故障，那么，此时，数据库就没有最新的数据了。 新增数据如果是新增数据，数据会直接写到数据库中，不用对缓存做任何操作，此时，缓存中本身就没有新增数据，而数据库中是最新值，这种情况符合我们刚刚所说的一致性的第 2 种情况，所以，此时，缓存和数据库的数据是一致的。 删改数据情况一： 我们假设应用先删除缓存，再更新数据库，如果缓存删除成功，但是数据库更新失败，那么，应用再访问数据时，缓存中没有数据，就会发生缓存缺失。然后，应用再访问数据库，但是数据库中的值为旧值，应用就访问到旧值了。 应用要把数据 X 的值从 10 更新为 3，先在 Redis 缓存中删除了 X 的缓存值，但是更新数据库却失败了。如果此时有其他并发的请求访问 X，会发现 Redis 中缓存缺失，紧接着，请求就会访问数据库，读到的却是旧值 10。 情况二： 我们先更新数据库，再删除缓存中的值。应用要把数据 X 的值从 10 更新为 3，先成功更新了数据库，然后在 Redis 缓存中删除 X 的缓存，但是这个操作却失败了，这个时候，数据库中 X 的新值为 3，Redis 中的 X 的缓存值为 10，这肯定是不一致的。如果刚好此时有其他客户端也发送请求访问 X，会先在 Redis 中查询，该客户端会发现缓存命中，但是读到的却是旧值 10。 总结： 在更新数据库和删除缓存值的过程中，无论这两个操作的执行顺序谁先谁后，只要有一个操作失败了，就会导致客户端读取到旧值。 如何解决数据不一致问题？ 首先，没有银弹，没有完美的解决方案和手段，无法做到 100% 解决一致性问题。只能是根据业务的实际情况去选择相对最优的方案。 重试机制具体来说，可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。 如果能够成功地删除或更新，我们就要把这些值从消息队列中去除，以免重复操作，此时，我们也可以保证数据库和缓存的数据一致了。否则的话，我们还需要再次进行重试。如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。 说白了就是把需要更新的数据的消息存在 MQ 中，只有成功操作了（更新 Redis、数据库），才在 MQ 中消费弹出。 当然引进了 MQ 是为了解决一致性的问题，但是还是会引来新的问题，就是 MQ 的消费与执行的一致性。。。 高并发下的问题在高并发的场景下，无论先更新 Redis 还是先更新 database 都会有一点的时间差，这段时间差，如果有其他线程进行读写数据，依然存在数据不一致的问题。 因为 Redis 的 database 两者的操作就不符合原子性，所以直接躺平吧。 Q：缓存异常（下）：解决缓存雪崩、击穿、穿透难题 沾点老八股了 缓存雪崩缓存雪崩是指大量的应用请求无法在 Redis 缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增。 说白了就是大量 kv 在同一时刻过期，而该时刻正是业务高峰期。 当然 Redis 的突然宕机也会造成缓存雪崩。 事前应对 避免给大量的数据设置相同的过期时间。如果业务层的确要求有些数据同时失效。 可以在用 EXPIRE 命令给每个数据设置过期时间时，给这些数据的过期时间增加一个较小的随机数（例如，随机增加 1~3 分钟），这样一来，不同数据的过期时间有所差别，但差别又不会太大，既避免了大量数据同时过期，同时也保证了这些数据基本在相近的时间失效，仍然能满足业务需求。 事后应对通过服务降级，来应对缓存雪崩。 所谓的服务降级，是指发生缓存雪崩时，针对不同的数据采取不同的处理方式。 当业务应用访问的是非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息； 当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。 当 Redis 出现突然宕机的情况 在业务系统中实现服务熔断或请求限流机制。 主从节点切换恢复 Redis 服务 缓存击穿缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。缓存击穿的情况，经常发生在热点数据过期失效时。 说白了就是热点 key，本身的流量就大，但是 Redis 里却没有数据 如何对敌？为了避免缓存击穿给数据库带来的激增压力，我们的解决方法也比较直接，对于访问特别频繁的热点数据，我们就不设置过期时间了。这样一来，对热点数据的访问请求，都可以在缓存中进行处理，而 Redis 数万级别的高吞吐量可以很好地应对大量的并发请求访问。 缓存穿透缓存穿透是指要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。 跟缓存雪崩、缓存击穿这两类问题相比，缓存穿透的影响更大一些。 那么，缓存穿透会发生在什么时候呢？一般来说，有两种情况。 业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据； 恶意攻击：专门访问数据库中没有的数据。 如何对敌？第一种方案是，缓存空值或缺省值。 一旦发生缓存穿透，我们就可以针对查询的数据，在 Redis 中缓存一个空值或是和业务层协商确定的缺省值（例如，库存的缺省值可以设为 0）。紧接着，应用发送的后续请求再进行查询时，就可以直接从 Redis 中读取空值或缺省值，返回给业务应用了，避免了把大量请求发送给数据库处理，保持了数据库的正常运行。 使用布隆过滤器快速判断数据是否存在 我们可以在把数据写入数据库时，使用布隆过滤器做个标记。当缓存缺失后，应用查询数据库时，可以通过查询布隆过滤器快速判断数据是否存在。如果不存在，就不用再去数据库中查询了。 在请求入口的前端进行请求检测 前端拦截恶意的请求 总结 针对缓存雪崩，合理地设置数据过期时间，以及搭建高可靠缓存集群； 针对缓存击穿，在缓存访问非常频繁的热点数据时，不要设置过期时间； 针对缓存穿透，提前在入口前端实现恶意请求检测，或者规范数据库的数据删除操作，避免误删除。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://matthew-han.github.io/tags/Redis/"}]},{"title":"Redis 笔记六","slug":"Redis-笔记六","date":"2021-07-14T08:18:47.000Z","updated":"2025-09-04T09:22:32.322Z","comments":true,"path":"post/1cae1360-e47c-11eb-8456-9d0bf7563314/","permalink":"https://matthew-han.github.io/post/1cae1360-e47c-11eb-8456-9d0bf7563314/","excerpt":"","text":"Q：什么是内存碎片 我们可以把这些分散的空座位叫作“车厢座位碎片”，知道了这一点，操作系统的内存碎片就很容易理解了。虽然操作系统的剩余内存空间总量足够，但是应用申请的是一块连续地址空间的 N 字节，但在剩余的内存空间中，没有大小为 N 字节的连续空间了，那么，这些剩余空间就是内存碎片（比如上图中的“空闲 2 字节”和“空闲 1 字节”，就是这样的碎片）。 Q：内存碎片是如何形成的其实，内存碎片的形成有内因和外因两个层面的原因。简单来说，内因是操作系统的内存分配机制，外因是 Redis 的负载特征。 内因：内存分配器的分配策略Redis 可以使用 libc、jemalloc、tcmalloc 多种内存分配器来分配内存，默认使用 jemalloc。 jemalloc 的分配策略之一，是按照一系列固定的大小划分内存空间，例如 8 字节、16 字节、32 字节、48 字节，…, 2KB、4KB、8KB 等。当程序申请的内存最接近某个固定值时，jemalloc 会给它分配相应大小的空间。 这样的分配方式本身是为了减少分配次数。例如，Redis 申请一个 20 字节的空间保存数据，jemalloc 就会分配 32 字节，此时，如果应用还要写入 10 字节的数据，Redis 就不用再向操作系统申请空间了，因为刚才分配的 32 字节已经够用了，这就避免了一次分配操作。 外因：键值对大小不一样和删改操作应用 A 保存 6 字节数据，jemalloc 按分配策略分配 8 字节。如果应用 A 不再保存新数据，那么，这里多出来的 2 字节空间就是内存碎片了。 第二个外因是，这些键值对会被修改和删除，这会导致空间的扩容和释放。具体来说，一方面，如果修改后的键值对变大或变小了，就需要占用额外的空间或者释放不用的空间。另一方面，删除的键值对就不再需要内存空间了，此时，就会把空间释放出来，形成空闲空间。 一开始，应用 A、B、C、D 分别保存了 3、1、2、4 字节的数据，并占据了相应的内存空间。然后，应用 D 删除了 1 个字节，这个 1 字节的内存空间就空出来了。紧接着，应用 A 修改了数据，从 3 字节变成了 4 字节。为了保持 A 数据的空间连续性，操作系统就需要把 B 的数据拷贝到别的空间，比如拷贝到 D 刚刚释放的空间中。此时，应用 C 和 D 也分别删除了 2 字节和 1 字节的数据，整个内存空间上就分别出现了 2 字节和 1 字节的空闲碎片。如果应用 E 想要一个 3 字节的连续空间，显然是不能得到满足的。因为，虽然空间总量够，但却是碎片空间，并不是连续的。 如何判断是否有内存碎片？Redis 自身提供了 INFO 命令 12345678INFO memory# Memoryused_memory:1073741736used_memory_human:1024.00Mused_memory_rss:1997159792used_memory_rss_human:1.86G…mem_fragmentation_ratio:1.86 这里有一个 mem_fragmentation_ratio 的指标，它表示的就是 Redis 当前的内存碎片率。那么，这个碎片率是怎么计算的呢？其实，就是上面的命令中的两个指标 used_memory_rss 和 used_memory 相除的结果。 mem_fragmentation_ratio = used_memory_rss/ used_memory used_memory_rss 是操作系统实际分配给 Redis 的物理内存空间，里面就包含了碎片； used_memory 是 Redis 为了保存数据实际申请使用的空间。 经验之谈： mem_fragmentation_ratio 大于 1 但小于 1.5。这种情况是合理的。这是因为，刚才我介绍的那些因素是难以避免的。毕竟，内因的内存分配器是一定要使用的，分配策略都是通用的，不会轻易修改；而外因由 Redis 负载决定，也无法限制。所以，存在内存碎片也是正常的。 mem_fragmentation_ratio 大于 1.5 。这表明内存碎片率已经超过了 50%。一般情况下，这个时候，我们就需要采取一些措施来降低内存碎片率了。 mem_fragmentation_ratio 小于 1，发生了 swap Matthew Han：mem_fragmentation_ratio 小于 1的情况，还可能会触发内存淘汰机制，删除大量的 key，阻塞主线程。 如何清理内存碎片？ 直接重启 Redis 实例（但是没有持久化AOF、RDB，数据就会丢失） 从 4.0-RC3 版本以后，Redis 自身提供了一种内存碎片自动清理的方法。 内存碎片清理，简单来说，就是“搬家让位，合并空间”。 Matthew Han：沾点 JVM GC 的标记 -清除了 需要注意的是：碎片清理是有代价的，操作系统需要把多份数据拷贝到新位置，把原有空间释放出来，这会带来时间开销。 Matthew Han：时间换空间了属实是 首先，Redis 需要启用自动内存碎片清理，可以把 activedefrag 配置项设置为 yes，命令如下： 1config set activedefrag yes 我们可以通过设置参数，来控制碎片清理的开始和结束时机，以及占用的 CPU 比例，从而减少碎片清理对 Redis 本身请求处理的性能影响。 这两个参数分别设置了触发内存清理的一个条件，如果同时满足这两个条件，就开始清理。在清理的过程中，只要有一个条件不满足了，就停止自动清理。 active-defrag-ignore-bytes 100mb：表示内存碎片的字节数达到 100MB 时，开始清理； active-defrag-threshold-lower 10：表示内存碎片空间占操作系统分配给 Redis 的总空间比例达到 10% 时，开始清理。 为了尽可能减少碎片清理对 Redis 正常请求处理的影响，自动内存碎片清理功能在执行时，还会监控清理操作占用的 CPU 时间，而且还设置了两个参数，分别用于控制清理操作占用的 CPU 时间比例的上、下限，既保证清理工作能正常进行，又避免了降低 Redis 性能。这两个参数具体如下： active-defrag-cycle-min 25： 表示自动清理过程所用 CPU 时间的比例不低于 25%，保证清理能正常开展； active-defrag-cycle-max 75：表示自动清理过程所用 CPU 时间的比例不高于 75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞 Redis，导致响应延迟升高。 Q：缓冲区引发的惨案客户端输入和输出缓冲区为了避免客户端和服务器端的请求发送和处理速度不匹配，服务器端给每个连接的客户端都设置了一个输入缓冲区和输出缓冲区，我们称之为客户端输入缓冲区和输出缓冲区。 输入缓冲区会先把客户端发送过来的命令暂存起来，Redis 主线程再从输入缓冲区中读取命令，进行处理。当 Redis 主线程处理完数据后，会把结果写入到输出缓冲区，再通过输出缓冲区返回给客户端。 如何应对输入缓冲区溢出？ 写入了 bigkey，比如一下子写入了多个百万级别的集合类型数据； 服务器端处理请求的速度过慢，例如，Redis 主线程出现了间歇性阻塞，无法及时处理正常发送的请求，导致客户端发送的请求在缓冲区越积越多。 避免输入缓冲区溢出。我们可以从两个角度去考虑如何避免，一是把缓冲区调大，二是从数据命令的发送和处理速度入手。 输入缓冲区没法调大 如何应对输出缓冲区溢出？ 服务器端返回 bigkey 的大量结果； 执行了 MONITOR 命令； 缓冲区大小设置得不合理。 和输入缓冲区不同，我们可以通过 client-output-buffer-limit 配置项，来设置输出缓冲区的大小。 主从集群中的缓冲区 全量同步 在全量复制过程中，主节点在向从节点传输 RDB 文件的同时，会继续接收客户端发送的写命令请求。这些写命令就会先保存在复制缓冲区中，等 RDB 文件传输完成后，再发送给从节点去执行。主节点上会为每个从节点都维护一个复制缓冲区，来保证主从节点间的数据同步。 复制缓冲区一旦发生溢出，主节点也会直接关闭和从节点进行复制操作的连接，导致全量复制失败。 复制积压缓冲区的溢出问题 增量同步 我们再来看下增量复制时使用的缓冲区，这个缓冲区称为复制积压缓冲区。主节点在把接收到的写命令同步给从节点时，同时会把这些写命令写入复制积压缓冲区。一旦从节点发生网络闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区中，读取断连期间主节点接收到的写命令，进而进行增量同步。 其实他就是 repl_backlog_buffer，复制积压缓冲区是一个大小有限的环形缓冲区。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://matthew-han.github.io/tags/Redis/"}]},{"title":"Redis 笔记五","slug":"Redis-笔记五","date":"2021-07-14T06:32:04.000Z","updated":"2025-09-04T09:22:32.304Z","comments":true,"path":"post/3414aaf0-e46d-11eb-9597-7d5c165039f4/","permalink":"https://matthew-han.github.io/post/3414aaf0-e46d-11eb-9597-7d5c165039f4/","excerpt":"","text":"Q：如何应对变慢的Redis（总结） 个人总结版本 AOF 重写问题，比如设置了 everysec ，上一次还妹写完，下一次又来了 发生了 swap 内存交换 查看基线性能 查看延迟的绝对值 是否有慢查询 是否会出现同一时刻大批量 kv 的过期 是否存在 bigkey 是否存在透明大页 是否出现频繁切换 socket，需要绑核 主从集群下是否主库过大，导致 RDB 载入阻塞 老师总结版本 获取 Redis 实例在当前环境下的基线性能。 是否用了慢查询命令？如果是的话，就使用其他命令替代慢查询命令，或者把聚合计算命令放在客户端做。 是否对过期 key 设置了相同的过期时间？对于批量删除的 key，可以在每个 key 的过期时间上加一个随机数，避免同时删除。 是否存在 bigkey？ 对于 bigkey 的删除操作，如果你的 Redis 是 4.0 及以上的版本，可以直接利用异步线程机制减少主线程阻塞；如果是 Redis 4.0 以前的版本，可以使用 SCAN 命令迭代删除；对于 bigkey 的集合查询和聚合操作，可以使用 SCAN 命令在客户端完成。 Redis AOF 配置级别是什么？业务层面是否的确需要这一可靠性级别？如果我们需要高性能，同时也允许数据丢失，可以将配置项 no-appendfsync-on-rewrite 设置为 yes，避免 AOF 重写和 fsync 竞争磁盘 IO 资源，导致 Redis 延迟增加。当然， 如果既需要高性能又需要高可靠性，最好使用高速固态盘作为 AOF 日志的写入盘。 Redis 实例的内存使用是否过大？发生 swap 了吗？如果是的话，就增加机器内存，或者是使用 Redis 集群，分摊单机 Redis 的键值对数量和内存压力。同时，要避免出现 Redis 和其他内存需求大的应用共享机器的情况。 在 Redis 实例的运行环境中，是否启用了透明大页机制？如果是的话，直接关闭内存大页机制就行了。 是否运行了 Redis 主从集群？如果是的话，把主库实例的数据量大小控制在 2~4GB，以免主从复制时，从库因加载大的 RDB 文件而阻塞。 是否使用了多核 CPU 或 NUMA 架构的机器运行 Redis 实例？使用多核 CPU 时，可以给 Redis 实例绑定物理核；使用 NUMA 架构时，注意把 Redis 实例和网络中断处理程序运行在同一个 CPU Socket 上。 Q：如何应对变慢的Redis（SUB：Redis 自身） 如何判断 Redis 是不是真的变慢了。一个最直接的方法，就是查看 Redis 的响应延迟。 看基线性能。基于当前环境下的 Redis 基线性能做判断。所谓的基线性能呢，也就是一个系统在低压力、无干扰下的基本性能，这个性能只由当前的软硬件配置决定。 如何应对 Redis 变慢？ Redis 自身操作特性的影响 慢查询命令 例子：Value 类型为 String 时，GET&#x2F;SET 操作主要就是操作 Redis 的哈希表索引。这个操作复杂度基本是固定的，即 $O(1)$。但是，当 Value 类型为 Set 时，SORT、SUNION&#x2F;SMEMBERS 操作复杂度分别为 $O(N+M*log(M))$ 和 $O(N)$。其中，$N$ 为 Set 中的元素个数，$M$ 为 SORT 操作返回的元素个数。这个复杂度就增加了很多。 解决手段 用其他高效命令代替。比如说，如果你需要返回一个 SET 中的所有成员时，不要使用 SMEMBERS 命令，而是要使用 SSCAN 多次迭代返回，避免一次返回大量数据，造成线程阻塞。 当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。 keys 命令 123redis&gt; KEYS *name*1) &quot;lastname&quot;2) &quot;firstname&quot; 因为 KEYS 命令需要遍历存储的键值对，所以操作延时高。如果你不了解它的实现而使用了它，就会导致 Redis 性能变慢。所以，KEYS 命令一般不被建议用于生产环境中。 过期 key 操作（删除操作是阻塞的，Redis 4.0 后可以用异步线程机制来减少阻塞影响） 默认情况下，Redis 每 100 毫秒会删除一些过期 key。具体算法： 采样 ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 个数的 key，并将其中过期的 key 全部删除； 如果超过 25% 的 key 过期了，则重复删除的过程，直到过期 key 的比例降至 25% 以下。 频繁使用带有相同时间参数的 EXPIREAT 命令设置过期 key 解决手段：如果一批 key 的确是同时过期，你还可以在 EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数，这样，既保证了 key 在一个邻近时间范围内被删除，又避免了同时过期造成的压力。 说白了就是不要出现同一时刻大量 key 过期导致的雪崩。 Q：如何应对变慢的Redis（SUB：文件系统：AOF）always 策略并不使用后台子线程来执行。 当主线程使用后台子线程执行了一次 fsync，需要再次把新接收的操作记录写回磁盘时，如果主线程发现上一次的 fsync 还没有执行完，那么它就会阻塞。所以，如果后台子线程执行的 fsync 频繁阻塞的话（比如 AOF 重写占用了大量的磁盘 IO 带宽），主线程也会阻塞，导致 Redis 性能变慢。 Q：如何应对变慢的Redis（SUB：操作系统 swap）内存 swap 是操作系统里将内存数据在内存和磁盘间来回换入和换出的机制。 通常，触发 swap 的原因主要是物理机器内存不足，对于 Redis 而言，有两种常见的情况： Redis 实例自身使用了大量的内存，导致物理机器的可用内存不足； Redis 实例在同一台机器上运行的其他进程，在进行大量的文件读写操作。文件读写本身会占用系统内存，这会导致分配给 Redis 实例的内存量变少，进而触发 Redis 发生 swap。 针对这个问题，我也给你提供一个解决思路：增加机器的内存或者使用 Redis 集群。 Q：如何应对变慢的Redis（SUB：操作系统内存大页）除了内存 swap，还有一个和内存相关的因素，即内存大页机制（Transparent Huge Page, THP），也会影响 Redis 性能。 Linux 内核从 2.6.38 开始支持内存大页机制，该机制支持 2MB 大小的内存页分配，而常规的内存页分配是按 4KB 的粒度来执行的。 如果采用了内存大页，那么，即使客户端请求只修改 100B 的数据，Redis 也需要拷贝 2MB 的大页。相反，如果是常规内存页机制，只用拷贝 4KB。两者相比，你可以看到，当客户端请求修改或新写入数据较多时，内存大页机制将导致大量的拷贝，这就会影响 Redis 正常的访存操作，最终导致性能变慢。 出现问题之后该机制可以关闭。 Q：缓存满了怎么办Redis 有一个重要机制，即缓存数据的淘汰机制。 可以设置一个最大容量 1CONFIG SET maxmemory 4gb Redis 缓存有哪些淘汰策略？ 在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis 4.0 后新增）四种。 在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）三种。 3.0 之后的默认情况下，Redis 在使用的内存空间超过 maxmemory 值时，并不会淘汰数据，也就是设定的 noeviction 策略。对应到 Redis 缓存，也就是指，一旦缓存被写满了，再有写请求来时，Redis 不再提供服务，而是直接返回错误。 volatile 这种淘汰策略。它们筛选的候选数据范围，被限制在已经设置了过期时间的键值对上。* volatile-ttl 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。 volatile-random 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。 volatile-lru 会使用 LRU 算法筛选设置了过期时间的键值对。 volatile-lfu 会使用 LFU 算法选择设置了过期时间的键值对。 allkeys 这种淘汰策略的备选淘汰数据范围，就扩大到了所有键值对，无论这些键值对是否设置了过期时间。* allkeys-random 策略，从所有键值对中随机选择并删除数据； allkeys-lru 策略，使用 LRU 算法在所有数据中进行筛选。 allkeys-lfu 策略，使用 LFU 算法在所有数据中进行筛选。 在 Redis 中，LRU 算法被做了简化，以减轻数据淘汰对缓存性能的影响。具体来说，Redis 默认会记录每个数据的最近一次访问的时间戳（由键值对数据结构 RedisObject 中的 lru 字段记录）。然后，Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://matthew-han.github.io/tags/Redis/"}]},{"title":"Redis 笔记四","slug":"Redis-笔记四","date":"2021-07-12T06:48:13.000Z","updated":"2025-09-04T09:22:32.313Z","comments":true,"path":"post/20dc2440-e2dd-11eb-b58c-3b03d3077551/","permalink":"https://matthew-han.github.io/post/20dc2440-e2dd-11eb-b58c-3b03d3077551/","excerpt":"","text":"Q：异步机制Redis 实例有哪些阻塞点？Redis 实例在运行时，要和许多对象进行交互，这些不同的交互就会涉及不同的操作，下面我们来看看和 Redis 实例交互的对象，以及交互时会发生的操作。 客户端：网络 IO，键值对增删改查操作，数据库操作； 磁盘：生成 RDB 快照，记录 AOF 日志，AOF 日志重写； 主从节点：主库生成、传输 RDB 文件，从库接收 RDB 文件、清空数据库、加载 RDB 文件； 切片集群实例：向其他实例传输哈希槽信息，数据迁移。 0. 和客户端交互时的阻塞点网络 IO 有时候会比较慢，但是 Redis 使用了 IO 多路复用机制，避免了主线程一直处在等待网络连接或请求到来的状态，所以，网络 IO 不是导致 Redis 阻塞的因素。 Redis 中涉及集合的操作复杂度通常为 $O(N)$，我们要在使用时重视起来。例如集合元素全量查询操作 HGETALL、SMEMBERS，以及集合的聚合统计操作，例如求交、并和差集。这些操作可以作为 Redis 的第一个阻塞点：集合全量查询和聚合操作。 bigkey 删除操作就是 Redis 的第二个阻塞点。删除操作对 Redis 实例性能的负面影响很大，而且在实际业务开发时容易被忽略，所以一定要重视它。既然频繁删除键值对都是潜在的阻塞点了，那么，在 Redis 的数据库级别操作中，清空数据库（例如 FLUSHDB 和 FLUSHALL 操作）必然也是一个潜在的阻塞风险，因为它涉及到删除和释放所有的键值对。所以，这就是 Redis 的第三个阻塞点：清空数据库。 1. 和磁盘交互时的阻塞点Redis 的第四个阻塞点了：AOF 日志同步写。 2. 主从节点交互时的阻塞点在主从集群中，主库需要生成 RDB 文件，并传输给从库。主库在复制的过程中，创建和传输 RDB 文件都是由子进程来完成的，不会阻塞主线程。但是，对于从库来说，它在接收了 RDB 文件后，需要使用 FLUSHDB 命令清空当前数据库，这就正好撞上了刚才我们分析的第三个阻塞点。此外，从库在清空当前数据库后，还需要把 RDB 文件加载到内存，这个过程的快慢和 RDB 文件的大小密切相关，RDB 文件越大，加载过程越慢，所以，加载 RDB 文件就成为了 Redis 的第五个阻塞点。 3. 切片集群实例交互时的阻塞点当我们部署 Redis 切片集群时，每个 Redis 实例上分配的哈希槽信息需要在不同实例间进行传递，同时，当需要进行负载均衡或者有实例增删时，数据会在不同的实例间进行迁移。不过，哈希槽的信息量不大，而数据迁移是渐进式执行的，所以，一般来说，这两类操作对 Redis 主线程的阻塞风险不大。 除非迁移的是 bigkey。 五个阻塞点： 集合全量查询和聚合操作； bigkey 删除； 清空数据库； AOF 日志同步写； 从库加载 RDB 文件。 哪些阻塞点可以异步执行？如果一个操作能被异步执行，就意味着，它并不是 Redis 主线程的关键路径上的操作。我再解释下关键路径上的操作是啥。这就是说，客户端把请求发送给 Redis 后，等着 Redis 返回数据结果的操作。 对于 Redis 来说，读操作是典型的关键路径操作，因为客户端发送了读操作之后，就会等待读取的数据返回，以便进行后续的数据处理。而 Redis 的第一个阻塞点“集合全量查询和聚合操作”都涉及到了读操作，所以，它们是不能进行异步操作了。 我们再来看看删除操作。删除操作并不需要给客户端返回具体的数据结果，所以不算是关键路径操作。而我们刚才总结的第二个阻塞点“bigkey 删除”，和第三个阻塞点“清空数据库”，都是对数据做删除，并不在关键路径上。因此，我们可以使用后台子线程来异步执行删除操作。 对于第四个阻塞点“AOF 日志同步写”来说，为了保证数据可靠性，Redis 实例需要保证 AOF 日志中的操作记录已经落盘，这个操作虽然需要实例等待，但它并不会返回具体的数据结果给实例。所以，我们也可以启动一个子线程来执行 AOF 日志的同步写，而不用让主线程等待 AOF 日志的写完成。 对于 Redis 的五大阻塞点来说，除了“集合全量查询和聚合操作”和“从库加载 RDB 文件”，其他三个阻塞点涉及的操作都不在关键路径上，所以，我们可以使用 Redis 的异步子线程机制来实现 bigkey 删除，清空数据库，以及 AOF 日志同步写。 异步的子线程机制Redis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行。 异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能，Redis 也提供了新的命令来执行这两个操作。 键值对删除：当你的集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，我建议你使用 UNLINK 命令。 清空数据库：可以在 FLUSHDB 和 FLUSHALL 命令后加上 ASYNC 选项，这样就可以让后台子线程异步地清空数据库，如下所示： 12FLUSHDB ASYNCFLUSHALL AYSNC Q：CPU 与 Redis主流的 CPU 架构一个 CPU 处理器中一般有多个运行核心，我们把一个运行核心称为一个物理核，每个物理核都可以运行应用程序。每个物理核都拥有私有的一级缓存（Level 1 cache，简称 L1 cache），包括一级指令缓存和一级数据缓存，以及私有的二级缓存（Level 2 cache，简称 L2 cache）。不同的物理核还会共享一个共同的三级缓存（Level 3 cache，简称为 L3 cache）。 另外，现在主流的 CPU 处理器中，每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存。 在主流的服务器上，一个 CPU 处理器会有 10 到 20 多个物理核。同时，为了提升服务器的处理能力，服务器上通常还会有多个 CPU 处理器（也称为多 CPU Socket），每个处理器有自己的物理核（包括 L1、L2 缓存），L3 缓存，以及连接的内存，同时，不同处理器间通过总线连接。 在多 CPU 架构上，应用程序可以在不同的处理器上运行。在刚才的图中，Redis 可以先在 Socket 1 上运行一段时间，然后再被调度到 Socket 2 上运行。 但是，有个地方需要你注意一下：如果应用程序先在一个 Socket 上运行，并且把数据保存到了内存，然后被调度到另一个 Socket 上运行，此时，应用程序再进行内存访问时，就需要访问之前 Socket 上连接的内存，这种访问属于远端内存访问。和访问 Socket 直接连接的内存相比，远端内存访问会增加应用程序的延迟。 在多 CPU 架构下，一个应用程序访问所在 Socket 的本地内存和访问远端内存的延迟并不一致，所以，我们也把这个架构称为非统一内存访问架构（Non-Uniform Memory Access，NUMA 架构）。 CPU 多核对 Redis 性能的影响CPU 的 context switch 次数比较多会影响 Redis 的读写性能。 context switch 是指线程的上下文切换，这里的上下文就是线程的运行时信息。在 CPU 多核的环境中，一个线程先在一个 CPU 核上运行，之后又切换到另一个 CPU 核上运行，这时就会发生 context switch。 如果在 CPU 多核场景下，Redis 实例被频繁调度到不同 CPU 核上运行的话，那么，对 Redis 实例的请求处理时间影响就更大了。每调度一次，一些请求就会受到运行时信息、指令和数据重新加载过程的影响，这就会导致某些请求的延迟明显高于其他请求。 我们可以使用 taskset 命令把一个程序绑定在一个核上运行。 1taskset -c 0 ./redis-server CPU 的 NUMA 架构对 Redis 性能的影响如果网络中断处理程序和 Redis 实例各自所绑的 CPU 核不在同一个 CPU Socket 上，那么，Redis 实例读取网络数据时，就需要跨 CPU Socket 访问内存，这个过程会花费较多时间。 所以，为了避免 Redis 跨 CPU Socket 访问网络数据，我们最好把网络中断程序和 Redis 实例绑在同一个 CPU Socket 上，这样一来，Redis 实例就可以直接从本地内存读取网络数据了。 在 CPU 的 NUMA 架构下，对 CPU 核的编号规则，并不是先把一个 CPU Socket 中的所有逻辑核编完，再对下一个 CPU Socket 中的逻辑核编码，而是先给每个 CPU Socket 中每个物理核的第一个逻辑核依次编号，再给每个 CPU Socket 中的物理核的第二个逻辑核依次编号。 1234567lscpuArchitecture: x86_64...NUMA node0 CPU(s): 0-5,12-17NUMA node1 CPU(s): 6-11,18-23... 绑核的风险和解决方案把 Redis 实例和物理核绑定，可以让主线程、子进程、后台线程共享使用 2 个逻辑核，可以在一定程度上缓解 CPU 资源竞争。但是，因为只用了 2 个逻辑核，它们相互之间的 CPU 竞争仍然还会存在。如果你还想进一步减少 CPU 竞争，我再给你介绍一种方案。 另一种方案：修改 Redis 源码（略）","categories":[{"name":"中间件","slug":"中间件","permalink":"https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://matthew-han.github.io/tags/Redis/"}]},{"title":"Redis 笔记三","slug":"Redis-笔记三","date":"2021-07-12T06:47:26.000Z","updated":"2025-09-04T09:22:32.315Z","comments":true,"path":"post/04c289c0-e2dd-11eb-9088-bdddfe01ee68/","permalink":"https://matthew-han.github.io/post/04c289c0-e2dd-11eb-9088-bdddfe01ee68/","excerpt":"","text":"Q：万金油的 String 不一定好用场景： 开发一个图片存储系统，要求这个系统能快速地记录图片 ID 和图片在存储系统中保存时的 ID（可以直接叫作图片存储对象 ID）。同时，还要能够根据图片 ID 快速查找到图片存储对象 ID。 用 10 位数来表示图片 ID 和图片存储对象 ID，例如，图片 ID 为 1101000051，它在存储系统中对应的 ID 号是 3301000051。 初始设计： 图片 ID 和图片存储对象 ID 正好一一对应，是典型的“键 - 单值”模式。所谓的“单值”，就是指键值对中的值就是一个值，而不是一个集合，这和 String 类型提供的“一个键对应一个值的数据”的保存形式刚好契合。 刚开始，我们保存了 1 亿张图片，大约用了 6.4GB 的内存。但是，随着图片数据量的不断增加，我们的 Redis 内存使用量也在增加，结果就遇到了大内存 Redis 实例因为生成 RDB 而响应变慢的问题。很显然，String 类型并不是一种好的选择，我们还需要进一步寻找能节省内存开销的数据类型方案。 内存使用量大的原因String 类型并不是适用于所有场合的，它有一个明显的短板，就是它保存数据时所消耗的内存空间较多。 其实，除了记录实际数据，String 类型还需要额外的内存空间记录数据长度、空间使用等信息，这些信息也叫作元数据。 反正就是除了本身的应存的数据之外，还保留很多其他的元数据，所以占用内存较大。 如何优化在保存单值的键值对时，可以采用基于 Hash 类型的二级编码方法。这里说的二级编码，就是把一个单值的数据拆分成两部分，前一部分作为 Hash 集合的 key，后一部分作为 Hash 集合的 value，这样一来，我们就可以把单值数据保存到 Hash 集合中了。 以图片 ID 1101000060 和图片存储对象 ID 3302000080 为例，我们可以把图片 ID 的前 7 位（1101000）作为 Hash 类型的键，把图片 ID 的最后 3 位（060）和图片存储对象 ID 分别作为 Hash 类型值中的 key 和 value。 二级编码一定要把图片 ID 的前 7 位作为 Hash 类型的键，把最后 3 位作为 Hash 类型值中的 key 吗？其实，二级编码方法中采用的 ID 长度是有讲究的。 Redis Hash 类型的两种底层实现结构，分别是压缩列表和哈希表。那么，Hash 类型底层结构什么时候使用压缩列表，什么时候使用哈希表呢？其实，Hash 类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash 类型就会用哈希表来保存数据了。 这两个阈值分别对应以下两个配置项： hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。 hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度。 如果我们往 Hash 集合中写入的元素个数超过了 hash-max-ziplist-entries，或者写入的单个元素大小超过了 hash-max-ziplist-value，Redis 就会自动把 Hash 类型的实现结构由压缩列表转为哈希表。一旦从压缩列表转为了哈希表，Hash 类型就会一直用哈希表进行保存，而不会再转回压缩列表了。在节省内存空间方面，哈希表就没有压缩列表那么高效了。 为了能充分使用压缩列表的精简内存布局，我们一般要控制保存在 Hash 集合中的元素个数。所以，在刚才的二级编码中，我们只用图片 ID 最后 3 位作为 Hash 集合的 key，也就保证了 Hash 集合的元素个数不超过 1000，同时，我们把 hash-max-ziplist-entries 设置为 1000，这样一来，Hash 集合就可以一直使用压缩列表来节省内存空间了。 个人总结这篇就是说了 String 在大量的键值对方面内存容量上有点拉胯，可以抽取出这些 key 的共性，再搞一个集合类型作为 value。当然如果 key 各个都不太一样就不太好搞了。 另外，教你了怎么采用压缩列表能够更大程度的节省空间。然后这个何时采用压缩列表何时采用其他的数据结构，配置项可配的。 另外，压缩列表是一块连续内存，对 CPU cache 也友好，CPU 命中率也不错，所以读取速度也非常快。 Q：有一亿个keys要统计，应该用哪种集合 在移动应用中，需要统计每天的新增用户数和第二天的留存用户数； 在电商网站的商品评论中，需要统计评论列表中的最新评论； 在签到打卡中，需要统计一个月内连续打卡的用户数； 在网页访问记录中，需要统计独立访客（Unique Visitor，UV）量。 聚合统计 统计手机 App 每天的新增用户数和第二天的留存用户数 所谓的聚合统计，就是指统计多个集合元素的聚合结果，包括：统计多个集合的共有元素（交集统计）；把两个集合相比，统计其中一个集合独有的元素（差集统计）；统计多个集合的所有元素（并集统计）。 我们还需要把每一天登录的用户 ID，记录到一个新集合中，我们把这个集合叫作每日用户 Set，它有两个特点：key 是 user:id 以及当天日期，例如 user:id:20200803；value 是 Set 集合，记录当天登录的用户 ID。 当要计算 8 月 4 日的留存用户时，我们只需要再计算 user:id:20200803 和 user:id:20200804 两个 Set 的交集，就可以得到同时在这两个集合中的用户 ID 了，这些就是在 8 月 3 日登录，并且在 8 月 4 日留存的用户。 执行的命令如下： 1SINTERSTORE user:id:rem user:id:20200803 user:id:20200804 Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞。所以，我给你分享一个小建议：你可以从主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的风险了。 排序统计 电商网站上提供最新评论列表 List 是按照元素进入 List 的顺序进行排序的，而 Sorted Set 可以根据元素的权重来排序，我们可以自己来决定每个元素的权重值。比如说，我们可以根据元素插入 Sorted Set 的时间确定权重值，先插入的元素权重小，后插入的元素权重大。 这样会出现翻页过程中，新插入元素，导致第二页出现重复数据的情况（其实这种情况因被允许，我看很多网站其实都是存在该现象） 如果不想出现这样的情况，就用 Sorted Set，因为他的取的权重还是老的，所以不会出现新的元素。除非你又获取了新的元素，拿到的新的权重，不然就是老的权重。 1ZRANGEBYSCORE comments N-9 N 二值状态统计 签到打卡的场景 Bitmap 提供了 GETBIT&#x2F;SETBIT 操作，使用一个偏移值 offset 对 bit 数组的某一个 bit 位进行读和写。不过，需要注意的是，Bitmap 的偏移量是从 0 开始算的，也就是说 offset 的最小值是 0。当使用 SETBIT 对一个 bit 位进行写操作时，这个 bit 位会被设置为 1。Bitmap 还提供了 BITCOUNT 操作，用来统计这个 bit 数组中所有“1”的个数。 那么，具体该怎么用 Bitmap 进行签到统计呢？ 借助一个具体的例子来说明。假设我们要统计 ID 3000 的用户在 2020 年 8 月份的签到情况，就可以按照下面的步骤进行操作。 第一步，执行下面的命令，记录该用户 8 月 3 号已签到。 1SETBIT uid:sign:3000:202008 2 1 第二步，检查该用户 8 月 3 日是否签到。 1GETBIT uid:sign:3000:202008 3 第三步，统计该用户在 8 月份的签到次数。 1BITCOUNT uid:sign:3000:202008 所以，如果只需要统计数据的二值状态，例如商品有没有、用户在不在等，就可以使用 Bitmap，因为它只用一个 bit 位就能表示 0 或 1。在记录海量数据时，Bitmap 能够有效地节省内存空间。 基数统计 统计网页的 UV 网页 UV 的统计有个独特的地方，就是需要去重，一个用户一天内的多次访问只能算作一次。在 Redis 的集合类型中，Set 类型默认支持去重，所以看到有去重需求时，我们可能第一时间就会想到用 Set 类型。 我们来结合一个例子看一看用 Set 的情况。有一个用户 user1 访问 page1 时，你把这个信息加到 Set 中： 1SADD page1:uv user1 但是，如果 page1 非常火爆，UV 达到了千万，这个时候，一个 Set 就要记录千万个用户 ID。对于一个搞大促的电商网站而言，这样的页面可能有成千上万个，如果每个页面都用这样的一个 Set，就会消耗很大的内存空间。 这时候，就要用到 Redis 提供的 HyperLogLog 了。HyperLogLog 是一种用于统计基数的数据集合类型，它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。 在统计 UV 时，你可以用 PFADD 命令（用于向 HyperLogLog 中添加新元素）把访问页面的每个用户都添加到 HyperLogLog 中。 1PFADD page1:uv user1 user2 user3 user4 user5 接下来，就可以用 PFCOUNT 命令直接获得 page1 的 UV 值了，这个命令的作用就是返回 HyperLogLog 的统计结果。 1PFCOUNT page1:uv **HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%**。这也就意味着，你使用 HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。 Q：GEO 是怎么搞定位置信息服务的实际上，GEO 类型的底层数据结构就是用 Sorted Set 来实现的。 为了能高效地对经纬度进行比较，Redis 采用了业界广泛使用的 GeoHash 编码方法，这个方法的基本原理就是“二分区间，区间编码”。 就是每次划分成两个区间，左 0 右 1。 对纬度的编码方式，和对经度的一样，只是纬度的范围是[-90，90]，下面这张表显示了对纬度值 39.86 的编码过程。 对进度和维度进行 N 次的二分法。 我们刚刚计算的经纬度（116.37，39.86）的各自编码值是 11010 和 10111，组合之后，第 0 位是经度的第 0 位 1，第 1 位是纬度的第 0 位 1，第 2 位是经度的第 1 位 1，第 3 位是纬度的第 1 位 0，以此类推，就能得到最终编码值 1110011101，如下图所示： 地理空间被划分成了一个个方格 不同位的做 GEOHASH 编码，可以得到精度不同的方格。 如何操作 GEO 类型？在使用 GEO 类型时，我们经常会用到两个命令，分别是 GEOADD 和 GEORADIUS。 GEOADD 命令：用于把一组经纬度信息和相对应的一个 ID 记录到 GEO 类型集合中； GEORADIUS 命令：会根据输入的经纬度位置，查找以这个经纬度为中心的一定范围内的其他元素。 以叫车应用的车辆匹配场景为例，假设车辆 ID 是 33，经纬度位置是（116.034579，39.030452），我们可以用一个 GEO 集合保存所有车辆的经纬度，集合 key 是 cars:locations。执行下面的这个命令，就可以把 ID 号为 33 的车辆的当前经纬度位置存入 GEO 集合中： 1GEOADD cars:locations 116.034579 39.030452 33 LBS 应用执行下面的命令时，Redis 会根据输入的用户的经纬度信息（116.054579，39.030452 ），查找以这个经纬度为中心的 5 公里内的车辆信息，并返回给 LBS 应用。当然， 你可以修改“5”这个参数，来返回更大或更小范围内的车辆信息。 1GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10","categories":[{"name":"中间件","slug":"中间件","permalink":"https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://matthew-han.github.io/tags/Redis/"}]},{"title":"Redis 笔记二","slug":"Redis-笔记二","date":"2021-07-08T09:42:46.000Z","updated":"2025-09-04T09:22:32.308Z","comments":true,"path":"post/d9851020-dfd0-11eb-9b07-0d08f44604fc/","permalink":"https://matthew-han.github.io/post/d9851020-dfd0-11eb-9b07-0d08f44604fc/","excerpt":"","text":"Q：什么是主从模式那我们总说的 Redis 具有高可靠性，又是什么意思呢？ 其实，这里有两层含义：一是数据尽量少丢失，二是服务尽量少中断。AOF 和 RDB 保证了前者，而对于后者，Redis 的做法就是增加副本冗余量，将一份数据同时保存在多个实例上。即使有一个实例出现了故障，需要过一段时间才能恢复，其他实例也可以对外提供服务，不会影响业务使用。 实际上，Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。 读操作：主库、从库都可以接收； 写操作：首先到主库执行，然后，主库将写操作同步给从库。 Q：主从之间什么时候进行第一次同步当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。 例如，现在有实例 1（ip：172.16.19.3）和实例 2（ip：172.16.19.5），我们在实例 2 上执行以下这个命令后，实例 2 就变成了实例 1 的从库，并从实例 1 上复制数据： 1replicaof 172.16.19.3 6379 简单来说就是以下流程： 第一阶段，主从库间建立连接、协商同步的过程，主要是为全量复制做准备 第二阶段，主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件。 第三阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。 也就是说从库全量复制完了之后，之后都是增量同步。查考下文的repl_backlog_buffer。 Q：主从级联模式分担全量复制时的主库压力一主多从的模式下，所有的从库都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。 那么，有没有好的解决方法可以分担主库压力呢？ 主 - 从 - 从模式。这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销。 1replicaof 所选从库的IP 6379 Q：主从库间网络断了怎么办？采用增量模式同步 当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。 repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。 不过，有一个地方我要强调一下，因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。 所以恢复的过程精髓在于 repl_backlog_buffer，对于该值不能太小，导致圆环被覆写。 Q：哨兵机制的基本流程哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。 在监控和选主这两个任务中，哨兵需要做出两个决策： 在监控任务中，哨兵需要判断主库是否处于下线状态； 在选主任务中，哨兵也要决定选择哪个从库实例作为主库。 主观下线与客观下线哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”。 哨兵机制通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。 在判断主库是否下线时，不能由一个哨兵说了算，只有大多数的哨兵实例，都判断主库已经“主观下线”了，主库才会被标记为“客观下线” 简单来说，“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N&#x2F;2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。 所以最好采用奇数个（大于等于 3）个哨兵节点。 如何筛选 + 打分？ 选择优先级最高的 用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。比如，你有两个从库，它们的内存大小不一样，你可以手动给内存大的实例设置一个高优先级。在选主时，哨兵会给优先级高的从库打高分，如果有一个从库优先级最高，那么它就是新主库了。如果从库的优先级都一样，那么哨兵开始第二轮打分。 和旧主库同步程度最接近的从库得分高。 repl_backlog_buffer 中的位置，而从库会用 slave_repl_offset 这个值记录当前的复制进度。就像下图所示，旧主库的 master_repl_offset 是 1000，从库 1、2 和 3 的 slave_repl_offset 分别是 950、990 和 900，那么，从库 2 就应该被选为新主库。 如右图： ID 号小的从库得分高。 在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库。 也就是保证一定能选出一个从库来当新主库 Q：哨兵之间的选举基于 pub&#x2F;sub 机制的哨兵集群组成哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub&#x2F;sub 机制，也就是发布 &#x2F; 订阅机制。 只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换。 在主从集群中，主库上有一个名为 __sentinel__:hello 的频道，不同哨兵就是通过它来相互发现，实现互相通信的。 这样哨兵节点之间就完成了彼此的通信建立。 基于 pub&#x2F;sub 机制的哨兵集群与主从库连接这是由哨兵向主库发送 INFO 命令来完成的。就像下图所示，哨兵 2 给主库发送 INFO 命令，主库接受到这个命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列表中的连接信息，和每个从库建立连接，并在这个连接上持续地对从库进行监控。哨兵 1 和 3 可以通过相同的方法和从库建立连接。 基于 pub&#x2F;sub 机制的客户端事件通知哨兵就是一个运行在特定模式下的 Redis 实例，只不过它并不服务请求操作，只是完成监控、选主和通知的任务。所以，每个哨兵实例也提供 pub&#x2F;sub 机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。 有了 pub&#x2F;sub 机制，哨兵和哨兵之间、哨兵和从库之间、哨兵和客户端之间就都能建立起连接了。 由哪个哨兵执行主从切换？切换新主库需要选出一个 leader 来进行操作。 具体步骤（个人总结）： 先判断主观下线，发送主观下线的命令，等待其他哨兵节点回应。 收到其他哨兵节点的回应，当主观下线的票数大于 N &#x2F; 2 + 1 时，标记主库是客观下线的事实，此时，这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。 发送这个命令时会先投自己一票，并且只能投一次赞成票，后面接收到这个选 leader 的命令都是否决票 在投票过程中，任何一个想成为 Leader 的哨兵，要满足两个条件：第一，拿到半数以上的赞成票；第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。 投票选 leader 中的细节： 其他哨兵收到投票请求后，由于自己还没有询问进入判定“客观下线”的流程，所以该哨兵是可以直接投票给“先做事”的哨兵，不会投 leader 票给自己。 存在的问题（我在群里的提问）： 我提出的问题：假如哨兵集群主库挂了，所有哨兵实例在同一时刻判断主观下线，然后同时接收到其他哨兵的消息，都到了客观下线的这一步，然后同时给自己投上一票 leader 票，是不是就没法选出 leader 了。。这种小概率会发生吗？ 收到群友们的热心解答： Q：假设有一个 Redis 集群，是“一主四从”，同时配置了包含 5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例都发生故障了，此时，Redis 主库如果有故障，还能正确地判断主库“客观下线”吗？如果可以的话，还能进行主从库自动切换吗？ A：这种情况，无论投票是怎么样，都没选出 leader 进行主从切换，因为哨兵实例数太少了，不满足大于等于 3。 最后，一个经验：要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds。在项目中，因为这个值在不同的哨兵实例上配置不一致，导致哨兵集群一直没有对有故障的主库形成共识，也就没有及时切换主库，最终的结果就是集群服务不稳定。 Q：切片集群（Redis 官网集群模式）Redis 如何保存更多数据？ 纵向扩展：升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 CPU。就像下图中，原来的实例内存是 8GB，硬盘是 50GB，纵向扩展后，内存增加到 24GB，磁盘增加到 150GB。 横向扩展：横向增加当前 Redis 实例的个数，就像下图中，原来使用 1 个 8GB 内存、50GB 磁盘的实例，现在使用三个相同配置的实例。 数据切片和实例的对应分布关系具体来说，Redis Cluster 方案采用哈希槽（Hash Slot，接下来我会直接称之为 Slot），来处理数据和实例之间的映射关系。在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。 具体的映射过程分为两大步：首先根据键值对的 key，按照CRC16 算法计算一个 16 bit 的值；然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。 手动指定每个实例上的哈希槽数量：使用 cluster meet 命令手动建立实例间的连接，形成集群，再使用 cluster addslots 命令，指定每个实例上的哈希槽个数。 在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。 客户端如何定位数据？Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。 客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。 在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个： 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽； 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。 说白了就是，客户端先存一个默认值（默认该值在某个实例上），但是哈希槽会移动，所以请求的结果不一定会直接得到数据，需要对返回的结果进行二次请求。 Redis Cluster 方案提供了一种重定向机制，所谓的“重定向”，就是指，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令。 MOVED命令实例给客户端返回下面的 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址： 12GET hello:key(error) MOVED 13320 172.16.19.5:6379 其中，MOVED 命令表示，客户端请求的键值对所在的哈希槽 13320，实际是在 172.16.19.5 这个实例上。通过返回的 MOVED 命令，就相当于把哈希槽所在的新实例的信息告诉给客户端了。这样一来，客户端就可以直接和 172.16.19.5 连接，并发送操作请求了。 会改变本地缓存，下次会直接请求正确的实例，如果哈希槽没变的话。 ASK 命令12GET hello:key(error) ASK 13320 172.16.19.5:6379 这个结果中的 ASK 命令就表示，客户端请求的键值对所在的哈希槽 13320，在 172.16.19.5 这个实例上，但是这个哈希槽正在迁移。此时，客户端需要先给 172.16.19.5 这个实例发送一个 ASKING 命令。这个命令的意思是，让这个实例允许执行客户端接下来发送的命令。然后，客户端再向这个实例发送 GET 命令，以读取数据。 不同点： 客户端ASK重定向命令和 MOVED 命令不同，ASK 命令并不会更新客户端缓存的哈希槽分配信息。所以，在上图中，如果客户端再次请求 Slot 2 中的数据，它还是会给实例 2 发送请求。这也就是说，ASK 命令的作用只是让客户端能给新实例发送一次请求，而不像 MOVED 命令那样，会更改本地缓存，让后续所有命令都发往新实例。 Redis Cluster不采用把key直接映射到实例的方式，而采用哈希槽的方式原因 摘自评论区 @Kaito 整个集群存储key的数量是无法预估的，key的数量非常多时，直接记录每个key对应的实例映射关系，这个映射表会非常庞大，这个映射表无论是存储在服务端还是客户端都占用了非常大的内存空间。 Redis Cluster采用无中心化的模式（无proxy，客户端与服务端直连），客户端在某个节点访问一个key，如果这个key不在这个节点上，这个节点需要有纠正客户端路由到正确节点的能力（MOVED响应），这就需要节点之间互相交换路由表，每个节点拥有整个集群完整的路由关系。如果存储的都是key与实例的对应关系，节点之间交换信息也会变得非常庞大，消耗过多的网络资源，而且就算交换完成，相当于每个节点都需要额外存储其他节点的路由表，内存占用过大造成资源浪费。 当集群在扩容、缩容、数据均衡时，节点之间会发生数据迁移，迁移时需要修改每个key的映射关系，维护成本高。 而在中间增加一层哈希槽，可以把数据和节点解耦，key通过Hash计算，只需要关心映射到了哪个哈希槽，然后再通过哈希槽和节点的映射表找到节点，相当于消耗了很少的CPU资源，不但让数据分布更均匀，还可以让这个映射表变得很小，利于客户端和服务端保存，节点之间交换信息时也变得轻量。 当集群在扩容、缩容、数据均衡时，节点之间的操作例如数据迁移，都以哈希槽为基本单位进行操作，简化了节点扩容、缩容的难度，便于集群的维护和管理。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://matthew-han.github.io/tags/Redis/"}]},{"title":"Redis 笔记一","slug":"Redis-笔记一","date":"2021-07-08T09:40:34.000Z","updated":"2025-09-04T09:22:32.302Z","comments":true,"path":"post/8b513a00-dfd0-11eb-b078-eb0d993c7e2d/","permalink":"https://matthew-han.github.io/post/8b513a00-dfd0-11eb-b078-eb0d993c7e2d/","excerpt":"","text":"Q：Redis 变慢的原因一 这里存在一个问题，哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。对于追求“快”的 Redis 来说，这是不太能接受的。 所以，Redis 会对哈希表做 rehash 操作。rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。那具体怎么做呢？ 其实，为了使 rehash 操作更高效，Redis 默认使用了两个全局哈希表：哈希表 1 和哈希表 2。一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步： 给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍； 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中； 释放哈希表 1 的空间。 到此，我们就可以从哈希表 1 切换到哈希表 2，用增大的哈希表 2 保存更多数据，而原来的哈希表 1 留作下一次 rehash 扩容备用。 Q：渐进式 rehash 拷贝 简单来说就是在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。 因为在进行渐进式 rehash 的过程中， 字典会同时使用 ht[0] 和 ht[1] 两个哈希表， 所以在渐进式 rehash 进行期间， 字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行： 比如说， 要在字典里面查找一个键的话， 程序会先在 ht[0] 里面进行查找， 如果没找到的话， 就会继续到 ht[1] 里面进行查找， 诸如此类。 另外， 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 ht[1] 里面， 而 ht[0] 则不再进行任何添加操作： 这一措施保证了 ht[0] 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。 Redis 会执行定时任务，定时任务中就包含了 rehash 操作。所谓的定时任务，就是按照一定频率（例如每 100ms&#x2F; 次）执行的任务。 Q：Redis 的几种数据结构 大类型下对应多种实现转换规则是基于一个key的数据大小和元素个数，配置文件中可配。 Q：为什么说 Redis 单线程这么快我们通常说，Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。 多线程的坏处： 为了保证共享资源的正确性，就需要有额外的机制进行保证，而这个额外的机制，就会带来额外的开销。 并发访问控制也是难点，降低系统代码的易调试性和可维护性 单线程快的原因： 高效的数据结构（哈希表、跳表） 多路复用机制 什么是多路复用机制？基本 IO 模型与阻塞点：以 Get 请求为例，为了处理一个 Get 请求，需要监听客户端请求（bind&#x2F;listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结果，即向 socket 中写回数据（send）。 但是，在这里的网络 IO 操作中，有潜在的阻塞点，分别是 accept() 和 recv()。当 Redis 监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept() 函数这里，导致其他客户端无法和 Redis 建立连接。类似的，当 Redis 通过 recv() 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。 这就导致 Redis 整个线程阻塞，无法处理其他客户端请求，效率很低。不过，幸运的是，socket 网络模型本身支持非阻塞模式。 针对监听套接字，我们可以设置非阻塞模式：当 Redis 调用 accept() 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待。但是，你要注意的是，调用 accept() 时，已经存在监听套接字了。 Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select&#x2F;epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。 也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。 现在，我们知道了，Redis 单线程是指它对网络 IO 和数据读写的操作采用了一个线程，而采用单线程的一个核心原因是避免多线程开发的并发控制问题。单线程的 Redis 也能获得高性能，跟多路复用的 IO 模型密切相关，因为这避免了 accept() 和 send()&#x2F;recv() 潜在的网络 IO 操作阻塞点。 Q：AOFAOF 写日志是主线程发起，在命令执行后才记录日志，所以不会阻塞当前的写操作。 其次，AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。 三种写回策略也就是 AOF 配置项 appendfsync 的三个可选值。 Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘； Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘； No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。 我们一定要小心 AOF 文件过大带来的性能问题。如何解决？利用 AOF 重写机制 重写机制具有“多变一”功能。所谓的“多变一”，也就是说，旧日志文件中的多条命令，在重写后的新日志中变成了一条命令。 AOF 重写会阻塞吗？和 AOF 日志由主线程写回不同，重写过程是由后台子进程 bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。 我把重写的过程总结为“一个拷贝，两处日志”。 “一个拷贝”就是指，每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。此时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。 “两处日志”又是什么呢？ 因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。 而第二处日志，就是指新的 AOF 重写日志。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。 主线程 fork 子线程的一瞬间是会发生阻塞的 Q：RDB（Redis DataBase） 快照RDB 重写会阻塞吗？如何做快照？Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。 save：在主线程中执行，会导致阻塞； bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。 简单来说，bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。 bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。此时，如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本（键值对 C’）。然后，主线程在这个数据副本上进行修改。同时，bgsave 子进程可以继续把原来的数据（键值对 C）写入 RDB 文件。 这里对数据的快照，我觉得很妙。 当存在在「快照备份的过程」中（T 时刻），如果是读操作无所谓，写操作的话，需要先将该数据复制一份副本，然后主线程在该副本上进行修改，这样子线程存储的数据则是「老」的数据，这样的话，在「快照备份的过程中」能保证快照的数据都是 T 时刻的数据了，无论该过程结束的时间是 T + N 秒。 多久做快照？虽然 bgsave 执行时不阻塞主线程，但是，如果频繁地执行全量快照，也会带来两方面的开销。 一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。 另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了（所以，在 Redis 中如果有一个 bgsave 在运行，就不会再启动第二个 bgsave 子进程） 原文中「所以，在 Redis 中如果有一个 bgsave 在运行，就不会再启动第二个 bgsave 子进程」指的是 Redis 实际的机制，并不会出现多个 bgsave 子进程来用于快照。 优化 Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。混 合使用 RDB 和 AOF，正好可以取两者之长，避两者之短，以较小的性能开销保证数据可靠性和性能。 关于混合使用个人感想 By Matthew Han 关于 AOF 和 RDB，AOF 有点像一个软件的小版本升级，version 1.1 &#x3D;&#x3D;&gt; version 1.2，可能只有几条数据的更新，此时采用 AOF 进行数据更新比较好，但是到了一个大的版本，比如 version 3.8，此时最好重新下一个最新版本的客户端了，所以对于 Redis 来说利用 RDB 比较好。 很多人要说了，诶？AOF 不是会重写操作记录实现 All In One 吗？那这样理解的话，无论数据怎么更新、增加、删除， AOF 的操作都应该比 RDB 这种全量的少啊？我看评论区 Kaito 的发言： RDB 文件内容是经过压缩的二进制数据（不同数据类型数据做了针对性优化），文件很小。 觉得应该是如果一段时间后数据几乎全改了，此时的 AOF 文件一定是比 RDB 大的，恢复速度肯定也比不上 RDB。而且删除操作多的话，RDB 更占优势，AOF 应该会记录删除的操作记录。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://matthew-han.github.io/tags/Redis/"}]},{"title":"大容量数组随机读写的效率问题","slug":"大容量数组随机读写的效率问题","date":"2021-07-01T01:40:32.000Z","updated":"2025-09-03T02:52:50.978Z","comments":true,"path":"post/5311af30-da0d-11eb-a7d5-3f834b7c5511/","permalink":"https://matthew-han.github.io/post/5311af30-da0d-11eb-a7d5-3f834b7c5511/","excerpt":"","text":"背景昨天在刷 AcWing 每日一题的第 3732 题「矩阵复原」时，发现在大容量数组作为缓存时提交无限 TLE，但是该用 HashMap 就 ac 了。 在我浅薄的知识勺中，一直认为数组的下标作为 key 随机访问其下标的元素数据时是要快于一些集合的，HashMap 有着复杂的数据结构，底层也是数组、链表和红黑树，怎么样都不会比一维数组作为缓存来的快吧，但实际上在该背景下确实是 HashMap 的效率更高。 来看这段算法的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.*;public class Main &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int k = sc.nextInt(); while (k-- &gt; 0) &#123; int n = sc.nextInt(); int m = sc.nextInt(); int[][] mat1 = new int[n][m]; int[][] mat2 = new int[m][n]; // int[] cache = new int[250001]; Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); int[][] res = new int[n][m]; for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; m; j++) &#123; mat1[i][j] = sc.nextInt(); // cache[mat1[i][j]] = j; map.put(mat1[i][j], j); &#125; &#125; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; mat2[i][j] = sc.nextInt(); // res[j][cache[mat2[i][j]]] = mat2[i][j]; res[j][map.get(mat2[i][j])] = mat2[i][j]; &#125; &#125; StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; n; i++) &#123; sb.setLength(0); for (int j = 0; j &lt; m; j++) &#123; sb.append(res[i][j]).append(&quot; &quot;); &#125; System.out.println(sb.toString()); &#125; &#125; &#125;&#125; 注释的地方是原先 TLE 的代码，只通过了大概 9 个 case（一共 11 个）。为什么会出现这样的情况呢？查阅了网上少量的资料和群友的解释大概是 CPU 高速缓存的命中问题，初始化需要分配的连续内存太大，造成CPU高速缓存整个缓存行失效，大大的降低了高速缓存的命中性。 可惜大学学的东西早忘完了，寻址算法都记不清了。这次正好也让我学习了在算法题中对于大数组的使用要谨慎，并非使用数组利用下标读写就是效率最高的。 2021.7.2 更新以上那段代码，我尝试在 HashMap 的初始化设定一个容量，就像这样：Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(250000 * 4 / 3 + 1); 发现这样果然超时了，感觉 TLE 的原因就在于初始化分配的大小。在数据量较小的 case 上，「一直扩容」是会比初始化过大的容量（250000）快的， TLE 应该是在一些数据量较小的 case 上。 Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(n * m * 4 / 3 + 1) 这样写性能是最强的，用时最少。所以效率排名是这样的： Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(n * m * 4 / 3 + 1) Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;() int[] cache = new int[n * m + 1]; int[] cache = new int[250001]; HashMap 居然比数组随机读写的速度还要快，泪目，HashMap 永远滴神！ 2021.7.6 更新在复习《Redis核心技术与实战》这门课的时候，评论区的同学都非常厉害，老师抛出了一个问题： 如果在数组上是随机访问，对CPU高速缓存还友好不？ 虽然是关于 Redis 的数据结构，但是其实本质和我们这道算法题碰到的问题类似，其中一个同学的解答非常好，我就直接在抄过来了 @irats: 数组通过下标访问数据虽然是O(1)，但是由于cpu读取数据从高速缓存读，而高速缓存的容量很小。 比如cpu要读取nums[0]，cpu发现高速缓存没有nums[0]，就会从内存把num[0]以及nums[0]附近的数据(比如还拖取了nums[1])都拖取到高速缓存中。如果接下来cpu要读取nums[1]，由于nums[1]已经在告诉缓存中，那么cpu能马上拿到数据。但如果cpu想要读取nums[100]，显然高速缓存中没有这个数据，然后就又要到内存中把nums[100]和他附近的数据拖到高速缓存。假设高速缓存只能存两个数字。那么因为读取nums[100]，就会把原本在nums[0]的数据替换掉。如果接下来cpu又读nums[0]。。那么就又要从内存中获取。 也就是说，老师问的对cpu友好，说的并不是你理解的时间复杂度。而是对于这种从高速缓存读取数据的行为。顺便说一句，在《深入理解操作系统中》中把要读取的数据附近的数据一起拖到高速缓存的行为，叫空间局部性。","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"数组","slug":"数组","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"内存","slug":"内存","permalink":"https://matthew-han.github.io/tags/%E5%86%85%E5%AD%98/"}]},{"title":"LeetCode 第 243 场周赛","slug":"LeetCode-1882-使用服务器处理任务","date":"2021-06-07T02:17:24.000Z","updated":"2025-09-03T02:52:50.971Z","comments":true,"path":"post/7f7138a0-c736-11eb-a4ac-bd3aa37357c3/","permalink":"https://matthew-han.github.io/post/7f7138a0-c736-11eb-a4ac-bd3aa37357c3/","excerpt":"","text":"Problem Description 给你两个下标从 0 开始的整数数组 servers 和 tasks ，长度分别为 n 和 m 。servers[i] 是第 i 台服务器的权重 ，而 tasks[j] 是处理第 j 项任务所需要的时间（单位：秒）。 你正在运行一个仿真系统，在处理完所有任务后，该系统将会关闭。每台服务器只能同时处理一项任务。第 0 项任务在第 0 秒可以开始处理，相应地，第 j 项任务在第 j 秒可以开始处理。处理第 j 项任务时，你需要为它分配一台权重最小的空闲服务器。如果存在多台相同权重的空闲服务器，请选择下标最小的服务器。如果一台空闲服务器在第 t 秒分配到第 j 项任务，那么在 t + tasks[j] 时它将恢复空闲状态。 如果没有空闲服务器，则必须等待，直到出现一台空闲服务器，并尽可能早地处理剩余任务。 如果有多项任务等待分配，则按照下标递增的顺序完成分配。 如果同一时刻存在多台空闲服务器，可以同时将多项任务分别分配给它们。 构建长度为 m 的答案数组 ans ，其中 ans[j] 是第 j 项任务分配的服务器的下标。 返回答案数组 ans 。 note servers.length == n tasks.length == m 1 &lt;= n, m &lt;= 2 * 105 1 &lt;= servers[i], tasks[j] &lt;= 2 * 105 e.g. 示例 1： 12345678910输入：servers = [3,3,2], tasks = [1,2,3,2,1,2]输出：[2,2,0,2,1,2]解释：事件按时间顺序如下：0 秒时，第 0 项任务加入到任务队列，使用第 2 台服务器处理到 1 秒。1 秒时，第 2 台服务器空闲，第 1 项任务加入到任务队列，使用第 2 台服务器处理到 3 秒。2 秒时，第 2 项任务加入到任务队列，使用第 0 台服务器处理到 5 秒。3 秒时，第 2 台服务器空闲，第 3 项任务加入到任务队列，使用第 2 台服务器处理到 5 秒。4 秒时，第 4 项任务加入到任务队列，使用第 1 台服务器处理到 5 秒。5 秒时，所有服务器都空闲，第 5 项任务加入到任务队列，使用第 2 台服务器处理到 7 秒。 示例 2： 1234567891011输入：servers = [5,1,4,3,2], tasks = [2,1,2,4,5,2,1]输出：[1,4,1,4,1,3,2]解释：事件按时间顺序如下：0 秒时，第 0 项任务加入到任务队列，使用第 1 台服务器处理到 2 秒。1 秒时，第 1 项任务加入到任务队列，使用第 4 台服务器处理到 2 秒。2 秒时，第 1 台和第 4 台服务器空闲，第 2 项任务加入到任务队列，使用第 1 台服务器处理到 4 秒。3 秒时，第 3 项任务加入到任务队列，使用第 4 台服务器处理到 7 秒。4 秒时，第 1 台服务器空闲，第 4 项任务加入到任务队列，使用第 1 台服务器处理到 9 秒。5 秒时，第 5 项任务加入到任务队列，使用第 3 台服务器处理到 7 秒。6 秒时，第 6 项任务加入到任务队列，使用第 2 台服务器处理到 7 秒。 Solution第 243 场周赛的第三题，虽然这场没参加（周赛基本都起不来），不过后来做了下还挺有趣，TLE 了一发，感觉很适合拿来面试的考察求职者的代码设计以及优化能力。主要考察堆排序、队列、多任务处理这些点。 甚至我都快想要开多个线程来做了。 这题可以直接模拟，模拟法需要注意的三个地方吧，不然会超时： 注意存在某个时刻会出现多个任务可被执行 防止 TLE ：直接跳转到运行队列中的最先空闲下来的服务器时间节点 防止 TLE ：两个优先队列处理（运行态和就绪态） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class Solution &#123; public int[] assignTasks(int[] servers, int[] tasks) &#123; int[] ans = new int[tasks.length]; // 运行态 // 运行中的服务器, 之前这里是 Queue, 没有及时 break, 所以拉了 // int[]: 长度为 2, 第 1 位是 serverId, 第 2 位是当前时间 + task 需要执行的时长 PriorityQueue&lt;int[]&gt; runtimeServerQueue = new PriorityQueue&lt;&gt;((o1, o2) -&gt; &#123; return Integer.compare(o1[1], o2[1]); &#125;); // 就绪态 // 等待被分配的服务器 // int[]: 长度为 2, 第 1 位是 serverId, 第 2 位是服务器权重 PriorityQueue&lt;int[]&gt; pendingServerQueue = new PriorityQueue&lt;&gt;((o1, o2) -&gt; &#123; // 先判权重升序, 权重一样, 则按照下标升序 if (o1[1] == o2[1]) &#123; return Integer.compare(o1[0], o2[0]); &#125; else &#123; return Integer.compare(o1[1], o2[1]); &#125; &#125;); // 先将所有的服务器塞到等待队列中 for (int i = 0; i &lt; servers.length; i++) &#123; pendingServerQueue.offer(new int[]&#123;i, servers[i]&#125;); &#125; // 每秒需要被执行的任务 Queue&lt;Integer&gt; taskQueue = new LinkedList&lt;&gt;(); for (int t : tasks) &#123; taskQueue.offer(t); &#125; int sec = 0; int trueSec = 0; while (!taskQueue.isEmpty()) &#123; int b = 0x3f3f3f3f; // step0. 先处理在运行的 serverQueue int limit = runtimeServerQueue.size(); for (int i = 0; i &lt; limit; i++) &#123; int[] task = runtimeServerQueue.poll(); // 根据当前和当前储存的预期完成时间比较, 一致则说明任务完成 if (task[1] == trueSec) &#123; // 加入到等待队列 pendingServerQueue.offer(new int[]&#123;task[0], servers[task[0]]&#125;); &#125; else &#123; // b: 运行中的服务器中最先会空闲的预期时间 b = Math.min(b, task[1]); runtimeServerQueue.offer(task); // 因为是优先队列, 一旦 else 了, Queue 后面服务器都不可能是这个时间节点完成 // 所以这里可以 break, 不然会 TLE break; &#125; &#125; // step1. 选择 空闲 / 权重最小 / 下标最小 的服务器 // 存在空闲服务器 if (!pendingServerQueue.isEmpty()) &#123; // 因为可能轮转了很多轮, 所以 taskQueue 里面的很多任务都可以在当前时间执行了(可能会有多个任务可执行) while (sec &lt; trueSec &amp;&amp; !taskQueue.isEmpty() &amp;&amp; !pendingServerQueue.isEmpty()) &#123; int task = taskQueue.poll(); int[] runnableServer = pendingServerQueue.poll(); ans[sec++] = runnableServer[0]; // 将 空闲的服务器 加入到 运行的服务器队列 中 runtimeServerQueue.offer(new int[]&#123;runnableServer[0], trueSec + task&#125;); &#125; trueSec++; &#125; else &#123; // 防止 TLE 关键, 跳转到 runtime 服务器最先空闲的时间节点 trueSec = b; &#125; &#125; return ans; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"},{"name":"队列","slug":"队列","permalink":"https://matthew-han.github.io/tags/%E9%98%9F%E5%88%97/"},{"name":"堆排序","slug":"堆排序","permalink":"https://matthew-han.github.io/tags/%E5%A0%86%E6%8E%92%E5%BA%8F/"}]},{"title":"位运算算法题小技巧","slug":"位运算算法题小技巧","date":"2021-02-25T09:29:13.000Z","updated":"2025-09-03T02:52:50.977Z","comments":true,"path":"post/ec90b090-774b-11eb-ac09-a1bcb7588087/","permalink":"https://matthew-han.github.io/post/ec90b090-774b-11eb-ac09-a1bcb7588087/","excerpt":"","text":"位运算位运算的效率就不说了，每次学会一些小技巧就忘了，还是基础不够扎实吧。。 计算某个 int 值的第 i 位（二进制位）是什么，可以用 num &gt;&gt; i; 有符号右移，不要在用 Integer 的 API 了 0 与 1 的转换（仅存在 1 与 0），num = 1 - num; 汉明码常用：for (int i = 0; i &lt; 32; i++) &#123;&#125; 懂得都懂 汉明码常用：多个数计算汉明码距离，只要找到 1 的个数和 0 的个数相乘即可 num1 与 num2 不用缓存 tmp 的交换，num1 ^= num2; num2 ^= num1; num1 ^= num2; 但是要记住 num1 与 num2 不能相等，不然会直接等于 0 判断奇偶这个老是记不住，(num &amp; 1 == 0); 因为任何二进制位和 1 做 &amp; 运算都是本身，偶数的末尾是 0 x ^ y ^ x = y，x ^ 0 = x这个经常多用用，前缀和、异或的题属于是考麻了！ 后续再更…","categories":[{"name":"Java 技巧","slug":"Java-技巧","permalink":"https://matthew-han.github.io/categories/Java-%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"位运算","slug":"位运算","permalink":"https://matthew-han.github.io/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"}]},{"title":"千千万万设计模式之装饰器模式","slug":"千千万万设计模式之装饰器模式","date":"2021-01-08T07:48:41.000Z","updated":"2025-09-03T02:52:50.977Z","comments":true,"path":"post/ecde1650-5185-11eb-84eb-99b80bd7ffbc/","permalink":"https://matthew-han.github.io/post/ecde1650-5185-11eb-84eb-99b80bd7ffbc/","excerpt":"","text":"装饰器模式未完待续…","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://matthew-han.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://matthew-han.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"装饰器模式","slug":"装饰器模式","permalink":"https://matthew-han.github.io/tags/%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F/"}]},{"title":"分布式事务与 Seata 初探","slug":"分布式事务与-Seata-初探","date":"2020-12-10T03:31:13.000Z","updated":"2025-09-03T02:52:50.977Z","comments":true,"path":"post/2752cd30-3a98-11eb-b0c9-0b16b97a2613/","permalink":"https://matthew-han.github.io/post/2752cd30-3a98-11eb-b0c9-0b16b97a2613/","excerpt":"","text":"分布式事务布式事务的实现有很多种，最具有代表性的是由Oracle Tuxedo系统提出的XA分布式事务协议。 XA协议包含两阶段提交（2PC）和三阶段提交（3PC）两种实现。 当然该协议主要是一种理论方式，具体落地有相应的组件（Seata等）或者代码中自行实现。 二段式提交 当队员收到就位确认提示后，如果已经就位，就选择“是”，如果还没就位，就选择“否”。 相应的，在队长发起就位确认的时候，有可能某些队员还并没有就位。 那么XA协议究竟是什么样子呢？在XA协议中包含着两个角色：事务协调者和事务参与者。 成功的流程让我们来看一看他们之间的交互流程： 在XA分布式事务的第一阶段，作为事务协调者的节点会首先向所有的参与者节点发送Prepare请求。 在接到Prepare请求之后，每一个参与者节点会各自执行与事务有关的数据更新，写入Undo Log和Redo Log。如果参与者执行成功，暂时不提交事务，而是向事务协调节点返回“完成”消息。 当事务协调者接到了所有参与者的返回消息，整个分布式事务将会进入第二阶段。 在XA分布式事务的第二阶段，如果事务协调节点在之前所收到都是正向返回，那么它将会向所有事务参与者发出Commit请求。 接到Commit请求之后，事务参与者节点会各自进行本地的事务提交，并释放锁资源。当本地事务完成提交后，将会向事务协调者返回“完成”消息。 当事务协调者接收到所有事务参与者的“完成”反馈，整个分布式事务完成。 失败的流程在XA的第一阶段，如果某个事务参与者反馈失败消息，说明该节点的本地事务执行不成功，必须回滚。 于是在第二阶段，事务协调节点向所有的事务参与者发送Abort请求。接收到Abort请求之后，各个事务参与者节点需要在本地进行事务的回滚操作，回滚操作依照Undo Log来进行。 以上就是XA两阶段提交协议的详细过程。 细节首先 2PC 是一个同步阻塞协议，像第一阶段协调者会等待所有参与者响应才会进行下一步操作，当然第一阶段的协调者有超时机制，假设因为网络原因没有收到某参与者的响应或某参与者挂了，那么超时后就会判断事务失败，向所有参与者发送回滚命令。 二段式提交的不足 性能问题 XA协议遵循强一致性。在事务执行过程中，各个节点占用着数据库资源，只有当所有节点准备完毕，事务协调者才会通知提交，参与者提交后释放资源。这样的过程有着非常明显的性能问题。 协调者单点故障问题 事务协调者是整个XA模型的核心，一旦事务协调者节点挂掉，参与者收不到提交或是回滚通知，参与者会一直处于中间状态无法完成事务。（参与者不具备超时机制） 丢失消息导致的不一致问题。 在XA协议的第二个阶段，如果发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就导致了节点之间数据的不一致。 三段式提交 MQ事务 利用消息中间件来异步完成事务的后一半更新，实现系统的最终一致性。这个方式避免了像XA协议那样的性能问题。 XA三阶段提交 XA三阶段提交在两阶段提交的基础上增加了CanCommit阶段，并且引入了超时机制。一旦事物参与者迟迟没有接到协调者的commit请求，会自动进行本地commit。这样有效解决了协调者单点故障的问题。但是性能问题和不一致的问题仍然没有根本解决。 TCC事务 TCC事务是Try - Confirm - Cancel三种指令的缩写，其逻辑模式类似于XA两阶段提交，但是实现方式是在代码层面来人为实现。 其实从思想上看和 2PC 差不多，都是先试探性的执行，如果都可以那就真正的执行，如果不行就回滚。 比如说一个事务要执行A、B、C三个操作，那么先对三个操作执行预留动作。如果都预留成功了那么就执行确认操作，如果有一个预留失败那就都执行撤销动作。 TCC 对业务代码的侵入较大，开发量也比较大但是提供了较好的性能。 XA 和 TCC 的区别XA 是一整个长事务，对数据库进行加锁，所以性能拉胯而且会有长事务风险。但是 TCC 是几个小事务（本地事务），最终一致性，不会出现长事务的锁风险，保证分布式性能。 在 Seata 中如需改造成 TCC 模式，需要加上核心注解@LocalTCC，并写三个接口，分别对应 Try - Confirm - Cancel，如saveOrder()、commit()、rollbackTcc()方法。代码量确实会大一些，并且后期维护加重。 SeataTC：seata 服务端 TM：@GlobalTransactional注解的方法，事务的发起方 RM：一个数据库就是 RM，事务的参与方 TM 开启分布式事务，TM 向 TC 注册全局事务记录 业务场景，编排数据库，服务等事务内资源，RM 向 TC 报备资源准备状态 TM 结束分布式事务，事务一阶段结束（TM 通知 TC 提交或回滚分布式事务） TC 汇总事务信息，决定分布式事务是提交还是回滚 TC 通知所有 RM 提交或回滚资源，事务二阶段结束","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"分布式事务","slug":"分布式事务","permalink":"https://matthew-han.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"name":"Seata","slug":"Seata","permalink":"https://matthew-han.github.io/tags/Seata/"},{"name":"中间件","slug":"中间件","permalink":"https://matthew-han.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"数据结构：字典树","slug":"数据结构：字典树","date":"2020-11-23T03:36:58.000Z","updated":"2025-09-03T02:52:50.978Z","comments":true,"path":"post/23cb19a0-2d3d-11eb-a175-c13ddf029711/","permalink":"https://matthew-han.github.io/post/23cb19a0-2d3d-11eb-a175-c13ddf029711/","excerpt":"","text":"介绍Trie (发音为 “try”) 或前缀树是一种树数据结构，用于检索字符串数据集中的键。这一高效的数据结构有多种应用： 自动补全 谷歌搜索建议 拼写检查 文字处理软件中的拼写检查 IP 路由 (最长前缀匹配) 使用Trie树的最长前缀匹配算法，Internet 协议（IP）路由中利用转发表选择路径 T9 (九宫格) 打字预测 T9（九宫格输入），在 20 世纪 90 年代常用于手机输入。 单词游戏 Trie 树可通过剪枝搜索空间来高效解决 Boggle 单词游戏 还有其他的数据结构，如平衡树和哈希表，使我们能够在字符串数据集中搜索单词。为什么我们还需要 Trie 树呢？尽管哈希表可以在 O(1) 时间内寻找键值，却无法高效的完成以下操作： 找到具有同一前缀的全部键值。 按词典序枚举字符串的数据集。 Trie 树优于哈希表的另一个理由是，随着哈希表大小增加，会出现大量的冲突，时间复杂度可能增加到 O(n)，其中 n 是插入的键的数量。与哈希表相比，Trie 树在存储多个具有相同前缀的键时可以使用较少的空间。此时 Trie 树只需要 O(m) 的时间复杂度，其中 m 为键长。而在平衡树中查找键值需要O(mlogn) 时间复杂度。 数据结构图 Problem Description实现一个 Trie (前缀树)，包含 insert, search, 和 startsWith 这三个操作。 note 你可以假设所有的输入都是由小写字母 a-z 构成的。 保证所有输入均为非空字符串。 e.g.12345678Trie trie = new Trie();trie.insert(&quot;apple&quot;);trie.search(&quot;apple&quot;); // 返回 truetrie.search(&quot;app&quot;); // 返回 falsetrie.startsWith(&quot;app&quot;); // 返回 truetrie.insert(&quot;app&quot;); trie.search(&quot;app&quot;); // 返回 true Solution利用前缀树就能很好的解决这一题 #208 实现 Trie (前缀树)。 首先构建一个前缀树的数据结构模型 12345678910111213141516171819202122static class TireTree &#123; private boolean isEnd; private final TireTree[] data; private Character ele; private final static int CAPACITY = 26; public TireTree(char ele) &#123; this.ele = ele; this.data = new TireTree[CAPACITY]; this.isEnd = false; &#125; @Override public String toString() &#123; return &quot;TireTree&#123;&quot; + &quot;isEnd=&quot; + isEnd + &quot;, data=&quot; + Arrays.toString(data) + &quot;, ele=&quot; + ele + &#x27;&#125;&#x27;; &#125;&#125; 当然还可以扩展出set、get方法以供方便调用。 继续完善解决该题，难点在于insert方法，当插入某串字符串的子串时，需要将末尾节点的isEnd标记为置true；如果出现新的字符，需要插入一个新的节点。search方法只要递归判断末尾节点标记位是否为true即可，而startsWith只要递归判断prefix能否在该树下走完。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107public class ImplementTriePrefixTreeII &#123; static class TireTree &#123; private boolean isEnd; private final TireTree[] data; private Character ele; private final int CAPACITY = 26; public TireTree(char ele) &#123; this.ele = ele; data = new TireTree[CAPACITY]; isEnd = false; &#125; @Override public String toString() &#123; return &quot;TireTree&#123;&quot; + &quot;isEnd=&quot; + isEnd + &quot;, data=&quot; + Arrays.toString(data) + &quot;, ele=&quot; + ele + &#x27;&#125;&#x27;; &#125; &#125; TireTree tireTree; /** * #208 实现 Trie (前缀树) * * 执行用时： 37 ms , 在所有 Java 提交中击败了 99.72% 的用户 * 内存消耗： 48.6 MB , 在所有 Java 提交中击败了 55.22% 的用户 */ public ImplementTriePrefixTreeII() &#123; tireTree = new TireTree(&#x27;$&#x27;); &#125; private void insert(TireTree tireTree, String target, int index) &#123; if (index &gt;= target.length()) &#123; return; &#125; char curr = target.charAt(index); TireTree currTree = tireTree.data[curr - &#x27;a&#x27;]; if (currTree == null) &#123; tireTree.data[curr - &#x27;a&#x27;] = new TireTree(curr); currTree = tireTree.data[curr - &#x27;a&#x27;]; currTree.ele = curr; &#125; if (currTree.ele == curr &amp;&amp; index == target.length() - 1) &#123; currTree.isEnd = true; return; &#125; insert(currTree, target, index + 1); &#125; /** * 复合查询 * * @param tireTree * @param target * @param index * @param isPrefix 是否是前缀查询 * @return */ private boolean search(TireTree tireTree, String target, int index, boolean isPrefix) &#123; char curr = target.charAt(index); TireTree currTree = tireTree.data[curr - &#x27;a&#x27;]; if (currTree == null) &#123; return false; &#125; else &#123; if (currTree.ele == curr) &#123; if (index == target.length() - 1) &#123; return isPrefix || currTree.isEnd; &#125; else &#123; return search(currTree, target, index + 1, isPrefix); &#125; &#125; else &#123; return false; &#125; &#125; &#125; /** * Inserts a word into the trie. */ public void insert(String word) &#123; TireTree tmp = tireTree; insert(tmp, word, 0); &#125; /** * Returns if the word is in the trie. */ public boolean search(String word) &#123; TireTree tmp = tireTree; return search(tmp, word, 0, false); &#125; /** * Returns if there is any word in the trie that starts with the given prefix. */ public boolean startsWith(String prefix) &#123; TireTree tmp = tireTree; return search(tmp, prefix, 0, true); &#125; &#125;","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"},{"name":"数据结构","slug":"Java技术/数据结构","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"},{"name":"字典树","slug":"字典树","permalink":"https://matthew-han.github.io/tags/%E5%AD%97%E5%85%B8%E6%A0%91/"},{"name":"树","slug":"树","permalink":"https://matthew-han.github.io/tags/%E6%A0%91/"}]},{"title":"走进JVM之内存布局","slug":"走进JVM之内存布局","date":"2020-09-23T09:15:41.000Z","updated":"2025-09-04T09:32:09.382Z","comments":true,"path":"post/5a0667d0-fd7d-11ea-ad87-11fe3cadc827/","permalink":"https://matthew-han.github.io/post/5a0667d0-fd7d-11ea-ad87-11fe3cadc827/","excerpt":"","text":"《码出高效》系列笔记（一）：面向对象中的类 《码出高效》系列笔记（一）：面向对象中的方法 《码出高效》系列笔记（一）：面向对象中的其他知识点 《码出高效》系列笔记（二）：代码风格 《码出高效》系列笔记（三）：异常与日志 《码出高效》系列笔记（四）：数据结构与集合的框架 《码出高效》系列笔记（四）：数据结构与集合的数组和泛型 《码出高效》系列笔记（四）：元素的比较 走进JVM之内存布局 走进JVM之字节码与类加载 走进JVM之GC 内存布局 1.堆（Heap）存储着所有实例对象，GC的相关详见上一篇 2.元空间（Metaspace）永久代和元空间都是对方法区的一个实现，方法区是一块所有线程共享的内存区域。Java7及之前为永久代（Perm），之后均为元空间，所以类元信息、字段、静态属性、方法、常量等都移动至元空间。 区别于永久代，元空间在本地内存中分配。 3.虚拟机栈（JVM Stack）JVM中的虚拟机栈是描述Java方法执行的内存区域，他是线程私有的。栈中的元素用于支持虚拟机方法调用，每个方法从开始调用到执行完成的过程，就是栈帧从入栈到出栈的过程。 通过递归调用可以更好地理解方法的调用，尤其是二叉树的中序遍历，逐级返回有点类似JVM类加载机制的双亲委派模型 局部变量表存放方法参数和局部变量的区域 操作数栈 局部变量表 常量池引用 操作栈操作站是一个初始状态为空的桶式结构栈。在方法执行的过程中，会有各种指令往栈中写入和提取信息。 动态连接每个栈帧包含一个常量池中对当前方法的引用，目的是支持方法调用过程的动态链接。 方法返回地址 正常退出，一些关键字return等 异常退出 只要是退出都会返回到方法被调用的位置。方法退出的过程相当于弹出当前栈帧。 返回值压入上层调用栈帧 异常信息抛给能够处理的栈帧 PC计数器指向方法调用后的下一条指令 4.本地方法栈（Native Method Stacks）线程对象私有，虚拟机栈主内，本地方法栈主外。 线程调用本地方法的时候，会进入一个不再受JVM约束的世界，优点：极高的执行效率、偏底层的跨进程操作；缺点：威胁程序运行的稳定性。 JNI最著名的本地方法：System.currentTImeMillis()。 5.程序计数寄存器（Program Counter Register）略 6.小结从线程共享的角度来看，堆（Heap）和元空间（Metaspace）是线程共享的，其他都是线程内部私有的。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://matthew-han.github.io/tags/JVM/"},{"name":"Java","slug":"Java","permalink":"https://matthew-han.github.io/tags/Java/"},{"name":"内存布局","slug":"内存布局","permalink":"https://matthew-han.github.io/tags/%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/"}]},{"title":"走进JVM之字节码与类加载","slug":"走进JVM之字节码与类加载","date":"2020-09-22T11:09:25.000Z","updated":"2025-09-04T09:32:15.761Z","comments":true,"path":"post/132bab40-fcc4-11ea-ab6f-7dc412045e4d/","permalink":"https://matthew-han.github.io/post/132bab40-fcc4-11ea-ab6f-7dc412045e4d/","excerpt":"","text":"《码出高效》系列笔记（一）：面向对象中的类 《码出高效》系列笔记（一）：面向对象中的方法 《码出高效》系列笔记（一）：面向对象中的其他知识点 《码出高效》系列笔记（二）：代码风格 《码出高效》系列笔记（三）：异常与日志 《码出高效》系列笔记（四）：数据结构与集合的框架 《码出高效》系列笔记（四）：数据结构与集合的数组和泛型 《码出高效》系列笔记（四）：元素的比较 走进JVM之内存布局 走进JVM之字节码与类加载 走进JVM之GC 字节码JVM主流还是HotSpot，是OpenJDK最主流的一种。 跨平台需要一个中间层，那就是字节码（ByteCode），JVM会将字节码编译执行，热点代码还会通过JIT动态编译成机器码提高效率。 一个Java类文件，用十六进制表示二进制流。其中，起始的4个直接非常特殊：cafe babe。是Gosling定义的一个魔法数，标志该文件是一个Java类文件。 JVM在字节码上设计一套操作码助记符，用特殊的单词来标记。 一个.java文件转换成字节码甚至是机器码文件需要以下几步： Java &#x3D;&#x3D;&gt; 词法解析 &#x3D; token流 &#x3D;&gt; 语法解析 &#x3D;&#x3D;&gt; 语义分析 &#x3D;&#x3D;&gt; 生成字节码 &#x3D;&#x3D;&gt; 字节码 其中，语法解析的目的是组装成一颗语法树，再通过语义分析阶段检查类型、关键字、作用域是否合规。 字节码必须通过类加载过程加载到JVM环境后才可以执行。执行有3种模式 解释执行 JIT编译执行 JIT编译执行与解释混合执行 主流的JVM就是混合执行，在控制台输入java -version也可以看到mixed mode的字样，表示是混合执行。 类加载过程类是在运行期间第一次使用时动态加载的，而不是一次性加载所有类。因为如果一次性加载，那么会占用很多的内存。 流程主要分成三大步： 加载 只是类加载的第一个阶段，不要和类加载混淆。主要干三件事情： 通过类的完全限定名称获取定义该类的二进制字节流。 将该字节流表示的静态存储结构转换为方法区的运行时存储结构。 在内存中生成一个代表该类的 Class 对象，作为方法区中该类各种数据的访问入口。 链接（验证、准备、解析） 初始化 分为主动引用和被动应用。 主动引用： new关键字、main类等 被动引用： 静态字段、常量、SuperClass[] sca = new SuperClass[10];这样一个数组的初始化。 通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自 Object 的子类，其中包含了数组的属性和方法。 初始化的过程：读取字节码的二进制数据到内存中，在JVM的方法区内，然后利用字节码文件创建一个Class对象作用在堆区。 所以说类加载是一个将.class字节码文件实例化成Class对象并进行相关初始化的过程。 类加载器双亲委派模型，或者叫「溯源委派加载模型」更合适。因为类加载器类似原始部落，存在权利等级制度，最高的一层是BootStrap。 低层次的当前类加载器，不能覆盖更高层的加载器加载的类。所以低层的加载器想要加载某个类时，需要向上逐级询问：该类加载了吗？高一级的父加载器往往都是懒狗，收到下级的请求会转发该请求给自身的上级。 所以一次询问一定会传递到BootStrap ClassLoader。加载不到时，才会逐级向下尝试加载。如果父类都加载不了，就会允许当前类加载器加载，不然肯定是优先父类加载器加载。 所以是按需加载。 父子关系是通过组合关系实现，非继承关系。 这个模型的好处： 避免重复加载 安全性问题，防止核心的加载器已加载的类被「覆盖、篡改」 例子： ​ 比如在自己开发的环境中，不要定义和核心API同名的包名。 1.根加载器（Bootstrap）最底层的加载器，由C++实现，没有父加载器所以没有继承java.lang.ClassLoader，负责将存放在&lt;JRE_HOME&gt;\\lib目录中的，或者被 -Xbootclasspath参数所指定的路径中的。 负责装载最核心的类：Object、System、String等。 根类加载器加载的类，打印他的Classloader只会是null，因为不是在JVM体系内。 例如：System.out.println(Object.class.getClassLoader()); 2.扩展类加载器（Platform）纯Java语言编写。用于加载一些扩展的系统类（也就是安全性和重要性比上者稍差一点），比如：XML、加密、压缩。 这个类加载器是由 ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现。它负责将&lt;JAVA_HOME&gt;/lib/ext或者被java.ext.dir系统变量所指定路径中的所有类库加载到内存中，开发者可以直接使用扩展类加载器。 Java9之前是ExtClass，之后是PlatformClass。 3.应用类加载器（Application）这个类加载器是由 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。 负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器。比如自己写的TestFuck类，该类就是被该加载器所加载。 4.自定义加载器ClassLoader该类和Class都位于java.lang这个包下，主要是对双亲委派模型的实现。 loadClass方法 经典递归实现 先检查当前类是否已经在当前加载器加载了，如果没有，向上请求（上级也是这个模式） 直到父类加载器抛出ClassNotFoundException，此时尝试自己去加载。 一般不覆写该方法，因为还是要遵循双亲委派模型的机制。 findClass方法123protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; throw new ClassNotFoundException(name);&#125; 源码很简单，该方法需要覆写，因为上面说了，loadClass是递归父类加载器直到抛出该异常。那么需要覆写该方法实现自己的自定义的类。 defineClass方法通常与findClass方法一起使用，在findClass里面调用该方法返回。 继承ClassLoader类，覆写findClass方法。 什么时候需要自定义类加载器？ 隔离加载类：中间件不同的jar包相互影响 修改类的加载方式 扩展加载源：网络层面、数据库、电视机顶盒也能加载 防止源码泄露 5.热部署当我们的一个类已经被加载后，通过双亲委派模型，他并不会重新加载。但是我们在编译器中开发的时候可以选择热部署的方式。他又是怎么实现的呢？ 双亲委派模型的核心在于loadClass方法，如果直接略过或者覆写该方法，就不会出现无限向上级请求加载的情况了（递归倒了，哭😢）。 破坏双亲委派模型的2种方式： 不走loadClass方法 将上级类加载器下本应该（交给父加载器加载）加载的jar包删了，这样上级就会抛出异常，直到逐级返回下级加载「虚假的类」 第二种方式有点嗯了。。 6.线程上下文加载器我们根加载器属实位高权重，但是保不准它也有求于小弟的时候。比如mysql-connect-java.jar，每个计科学生都知道的经典数据库驱动。 在BootStrap加载器下有个rt.jar中有个类叫做java.sql.DriverManager，会去加载Driver.class，而该class是一个接口，并没有实现类，它的实现类在第三方的jar包中，也就是驱动中的类，相当于反向加载了。 12public Void run() &#123; ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); 这里的Void是定义的一个类，不是void关键字。 双亲委派模型可不允许反向加载，所以这里采用的是线程上下文加载器，该方式虽然也破坏了双亲委派模型，但是更为灵活。 12ClassLoader cl = Thread.currentThread().getContextClassLoader();return ServiceLoader.load(service, cl);","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://matthew-han.github.io/tags/JVM/"},{"name":"Java","slug":"Java","permalink":"https://matthew-han.github.io/tags/Java/"},{"name":"字节码","slug":"字节码","permalink":"https://matthew-han.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"},{"name":"类加载过程","slug":"类加载过程","permalink":"https://matthew-han.github.io/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B/"}]},{"title":"走进JVM之GC","slug":"走进JVM之GC","date":"2020-09-22T08:36:41.000Z","updated":"2025-09-04T10:59:40.619Z","comments":true,"path":"post/bd0fa690-fcae-11ea-897f-29deed537cb3/","permalink":"https://matthew-han.github.io/post/bd0fa690-fcae-11ea-897f-29deed537cb3/","excerpt":"","text":"《码出高效》系列笔记（一）：面向对象中的类 《码出高效》系列笔记（一）：面向对象中的方法 《码出高效》系列笔记（一）：面向对象中的其他知识点 《码出高效》系列笔记（二）：代码风格 《码出高效》系列笔记（三）：异常与日志 《码出高效》系列笔记（四）：数据结构与集合的框架 《码出高效》系列笔记（四）：数据结构与集合的数组和泛型 《码出高效》系列笔记（四）：元素的比较 走进JVM之内存布局 走进JVM之字节码与类加载 走进JVM之GC GC知识点主要分三个部分： 如何判断该对象要回收（是垃圾） 回收的算法有哪些？ 垃圾收集器 判断一个对象是否可以回收1. 引用计数法 Python采用该种算法，但是解决了相互引用的问题 为对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。 在两个对象出现循环引用的情况下，此时引用计数器永远不为 0，导致无法对它们进行回收。正是因为循环引用的存在，因此 Java 虚拟机不使用引用计数算法。 2. GC root（可达性算法） 从GCroot出发遍历，标记每个可访达的对象为活动对象，遍历不到的对象（Obj4）就会被接下来要讲的几种算法回收了。 GC root可以是以下几种： Java 方法栈桢中的局部变量； 已加载类的静态变量； JNI handles； 已启动且未停止的 Java 线程。 多线程环境下，会产生误报和漏报。 误报：A线程修改了访问，B线程会导致垃圾也被标记了，不会被清除，造成内存浪费。 漏报：将仍被应用的对象标记为垃圾。 误报和漏报的理解：误报大不了不回收嘛，漏报比较严重。垃圾回收是先标记活的对象，后回收死的对象，那么如果标记好后，其它线程产生了垃圾，即将活的变死了，这种内存是不会释放的。另外，如果这时产生了新对象，由于没被标记为活的，所以被释放了，这就危险了。 Q：如何解决？（实际JVM虚拟机并不会出现这种情况） A：Stop-the-world 以及安全点（安全词），垃圾回收线程工作时，其他非垃圾回收线程一律等待！ 垃圾回收算法1.标记 - 清除算法利用GC root遍历到的标记（非垃圾），那么其余的就是垃圾了，直接把剩下的对象标记为空闲内存。 优点：标记和清除的过程效率不高 缺点：产生大量不连续碎片，就无法给大内存的对象分配空间了 2.标记 - 整理算法（压缩算法）即把存活的对象聚集到内存区域的起始位置，从而留下一段连续的内存空间。 优点：结果是很美好的，拥有了连续的内存空间，所以一般老年代使用该种算法，因为老年代的频率明显比新生代低很多。 缺点：性能拉胯，毕竟要移动。（让我想到了为么MySQL用b+树，而不用有序数组，因为数据量大的时候插入、删除、移动的效率太低下了） 3.复制算法将内存划分为大小相等的两块（Java8的中S0、S1），每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。（有点像数组的System.arraycopy，利用from和to两个指针）。 所以所谓的S0和S1是相互复制然后全标记的，都会成为「空」的空间和复制来的对象的空间。 主要的不足是每次S0和S1肯定有一块是空的，为了接下来的复制，所以也算是小浪费。 HotSpot 虚拟机的 Eden 和 Survivor 大小比例默认为 8:1，保证了内存的利用率达到 90%。如果每次回收有多于 10% 的对象存活，那么一块 Survivor 就不够用了，此时需要依赖于老年代进行空间分配担保，也就是借用老年代的空间存储放不下的对象。 4.分代收集算法现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为几块，不同块采用适当的收集算法。 一般将堆分为新生代和老年代。 新生代使用：复制算法 老年代使用：标记 - 清除 或者 标记 - 整理 算法 5.总结 先Minor GC（Young GC），再Major GC（Full GC）。S0&#x2F;S1交换14次后晋升至老年代（Java8之后是元空间，位于本地内存），jvm默认值是15。 一般来说OOM是内存耗尽，也有超大内存（不多）的情况。 以上是我画的图，其中少了一步，当新生代晋升至老年代的时候失败怎么办？其实这里是执行Major GC，也就是走下面的那条流程。 垃圾收集器可以简单理解成新生代搞一个收集器，老年代搞一个收集器，Java8默认的就是Parallel + Parallel Old收集器 串行回收：Serial GC 并行回收：Parallel GC：吞吐量高（因为并行，花费GC的时间少，所以可以让出时间给其他非GC线程），适用于科学计算 并发回收：CMS（ConcMarkSweep，并发标记清除）：其实有STW，也有并行。后备方案是Serial Old。而且是标记清除，会有碎片，会导致提前Major GC；吞吐量低，但是适用是高并发、快速响应的场景。 Java9之后的：G1，Java11之后的：ZGC（在G1基础上），使命就是为了替换CMS。 JVM调优配了新生代，老年代会跟着配对应的垃圾收集器。 除了以上4种，主要还有以下3种： Serial Old（已废弃） ParNew ParOld 参数 新生代 新生代算法 老年代 老年代算法 -xx:+UseSerialGC Serial 复制 Serial old 标记整理 -xx:+UseParNewGC（已废弃） ParNew 复制 Serial old 标记整理 -xx:+UseParallelGC Parallel 复制 Parallel old 标记整理 -xx:+UseConcMarkSweepGC ParNew 复制 CMS &#x2F; Serial old 标记清除 -xx:+UseG1GC G1 复制（不区别新老年代） G1 Old Region 标记整理 -XX:+UseZGC ZGC 并发标记 + 并发重定位 不区分 并发压缩 G1和CMS的区别： G1分块设计，会移动不同的内存对象。G1虽然是标记清除算法，但是不会产生碎片 G1可以设置STW的时间，假如设置太小，就会频繁GC，降低吞吐量","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"GC","slug":"GC","permalink":"https://matthew-han.github.io/tags/GC/"},{"name":"JVM","slug":"JVM","permalink":"https://matthew-han.github.io/tags/JVM/"},{"name":"Java","slug":"Java","permalink":"https://matthew-han.github.io/tags/Java/"}]},{"title":"MySQL实战45讲（基础篇）","slug":"MySQL实战45讲-一","date":"2020-09-01T01:37:08.000Z","updated":"2025-09-04T09:22:32.317Z","comments":true,"path":"post/a6222fa0-ebf3-11ea-b9c4-17e39dadc010/","permalink":"https://matthew-han.github.io/post/a6222fa0-ebf3-11ea-b9c4-17e39dadc010/","excerpt":"","text":"（一）基础架构：一条SQL查询语句是如何执行的？ 连接器1mysql -h$ip -P$port -u$user -p 连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。 一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。 查询缓存MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。 有点类似Redis 但是大多数情况下建议不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。 需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。 分析器分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。 123mysql&gt; elect * from t where ID=1;ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#x27;elect * from t where ID=1&#x27; at line 1 优化器1mysql&gt; select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20; 优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。 执行器123mysql&gt; select * from T where ID=10;ERROR 1142 (42000): SELECT command denied to user &#x27;b&#x27;@&#x27;localhost&#x27; for table &#x27;T&#x27; 先判断有没有权限，如果有权限，就打开表继续执行。 打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的： 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中； 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行; 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。 Q&amp;AQuestion： 如果表 T 中没有字段 k，而你执行了这个语句 select * from T where k&#x3D;1, 那肯定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。这个错误是在我们上面提到的哪个阶段报出来的呢？ Answer： 在分析器阶段，其实很容易会让人误以为分析器阶段只做语法分析，其实是内建解析树，先from，再on，再join，再where，检查权限，生成新的解析树，语义检查（没有字段k在这里）等。 （二）日志系统：一条SQL更新语句是如何执行的？更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主角：redo log（重做日志）和 binlog（归档日志） 重要的日志模块：redo log一般来说，在古代的酒店客栈往往会有一本账本，账本记录着你的总账（赊账多少），而账本往往很厚，当有个B过来要赊账喝酒，你还要从账本上找下有没有这个B（上次赊账没），如果有，然后再划掉之前的赊账记录，加上这次的账款，重新生成一条新的纪录。当很忙的时候，掌柜根本没空干这些事，所以还需要一个粉板，就记录今天酒店的交易情况，还账赊账，等打烊了再回到账本上慢慢结算。 在MySQL中，磁盘的IO成本往往不低，所以先写日志，再写磁盘的操作就类似先写粉板，再写账本。 具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。 但是某一天生意太火爆了，粉板都写不下了，怎么办？那只能移除一部分的赊账记录，再更新到账本上，从粉板上擦掉，腾出新的空间。 与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。 write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。绿色的部分是还可以写的空间。 write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。 有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。 重要的日志模块：binlog和redo log的异同 redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID&#x3D;2 这一行的 c 字段加 1 ”。 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 有了对这两个日志的概念性理解，我们再来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。 执行器先找引擎取 ID&#x3D;2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID&#x3D;2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。 两段式提交：简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。 小结redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。 sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySql","slug":"MySql","permalink":"https://matthew-han.github.io/tags/MySql/"}]},{"title":"LeetCode #994 腐烂的橘子","slug":"LeetCode-994-腐烂的橘子","date":"2020-08-26T07:16:36.000Z","updated":"2025-09-03T02:52:50.971Z","comments":true,"path":"post/13dc2460-e76c-11ea-817c-17ab596ee38a/","permalink":"https://matthew-han.github.io/post/13dc2460-e76c-11ea-817c-17ab596ee38a/","excerpt":"","text":"Problem Description在给定的网格中，每个单元格可以有以下三个值之一： 值 0 代表空单元格； 值 1 代表新鲜橘子； 值 2 代表腐烂的橘子。 每分钟，任何与腐烂的橘子（在 4 个正方向上）相邻的新鲜橘子都会腐烂。 返回直到单元格中没有新鲜橘子为止所必须经过的最小分钟数。如果不可能，返回 -1。 note 1 &lt;= grid.length &lt;= 10 1 &lt;= grid[0].length &lt;= 10 grid[i][j] 仅为 0、1 或 2 e.g. 示例 1： 输入：[[2, 1, 1],[1, 1, 0],[0, 1, 1]] 输出：4 示例 2： 输入：[[2, 1, 1],[0, 1, 1],[1, 0, 1]] 输出：-1 示例 3： 输入：[[0, 2]] 输出：0 Solution网格、感染初一看就是深搜的题。 一分钟上下左右感染一个，感染的橘子又会上下左右感染邻近的新鲜的橘子，搁这生化危机呢。 每分钟感染周围（上下左右）的一排，那么用BFS走一走把所有的橘子感染一下（着色），求出最大深度max，然后正常遍历一下网格看还有没有新鲜橘子，有的话，return -1；没有的话return max。 一提交，GG了。 题目妹说只有一个「感染源」啊 如右边这种情况：[[2],[1],[1],[1],[2],[1],[1]]。它拥有2个「感染源」，最小分钟是2分钟，因为这2个「感染源」是同时作用邻近的新鲜橘子的。 那要怎么让多个起点同时遍历呢？ 脑子里的第一个笨办法，就是先列举出所有的烂橘子，将每个烂橘子可达的所有点都遍历一遍然后着色，着什么色呢？分钟数。一个初始烂橘子的第一围的新鲜橘子被感染了，花费的时间是1分钟，然后这一围被感染的橘子成为了新的感染源，去感染其周围的新鲜橘子，下一轮的花费的时间还是1分钟，一共2分钟，将这个分钟数写到网格中，为了加以区分用负数表示。如：第一分钟被感染的新鲜橘子grid[x][y] = -1;第二分钟被感染的新鲜橘子grid[x][y] = -2。因为存在一个新鲜的橘子会被多个「感染源」感染的情况，所以一个新鲜的橘子的这个「感染分钟数」是多个，我们比较一下选最小的那个即可（在代码里是赋值比较大的，因为是负数）。 这样就完成了所有的新鲜的橘子，最快被感染的着色时间。我们常规遍历一遍，求出最大的那个时间就是总共花费的时间。如果网格中还存在新鲜的橘子，就直接return -1。 Java代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public class Solution &#123; /** * 这题主要是一个新鲜橘子会被多个「源」传染，所以「最短路径」需要取最小的，也就是每个新鲜橘子被感染的是最近的烂橘子， * 最后只要找出网格中最大的最短路径就行了。 * * 1. 先找出所有的烂橘子（val = 2），每个烂橘子bfs遍历 * 2. 每个烂橘子bfs遍历能到达（传染）的所有新鲜橘子（val = 1）给他们赋路径值（负数用于区分），这批新鲜的橘子就变成「伪 - 新鲜橘子」 * 3. 「伪 - 新鲜橘子」被赋值后可能还会被「最近的烂橘子」感染，所以这里需要比较最近的烂橘子（最短路径），更新最短路径 * 4. 比较所有网格的新鲜橘子的val，理论上取一个最大值，因为赋值的是负值，所以是取最小值。 * * @param grid * @return */ public int orangesRotting(int[][] grid) &#123; for (int i = 0; i &lt; grid.length; i++) &#123; for (int j = 0; j &lt; grid[i].length; j++) &#123; if (grid[i][j] == 2) &#123; bfs(grid, i, j); &#125; &#125; &#125; for (int[] ints : grid) &#123; for (int anInt : ints) &#123; if (anInt == 1) &#123; return -1; &#125; &#125; &#125; int min = 0; for (int[] ints : grid) &#123; for (int anInt : ints) &#123; min = Math.min(min, anInt); &#125; &#125; return -min; &#125; public void bfs(int[][] grid, int i, int j) &#123; boolean[][] visited = new boolean[grid.length][grid[0].length]; Queue&lt;int[]&gt; queue = new LinkedList&lt;&gt;(); queue.offer(new int[]&#123;i, j&#125;); visited[i][j] = true; int depth = -1; while (!queue.isEmpty()) &#123; int limit = queue.size(); depth++; for (int k = 0; k &lt; limit; k++) &#123; int[] xy = queue.poll(); int x = xy[0]; int y = xy[1]; visited[x][y] = true; // 当橘子是好的，或者已经腐烂的（为负数）改成腐烂时间 // 如果已有腐烂时间的橘子，这判断更新（因为是负数，所以是max） if (grid[x][y] &lt; 0) &#123; grid[x][y] = Math.max(grid[x][y], -depth); &#125; else if (grid[x][y] == 1) &#123; grid[x][y] = -depth; &#125; if (x - 1 &gt;= 0 &amp;&amp; !visited[x - 1][y] &amp;&amp; grid[x - 1][y] != 2 &amp;&amp; grid[x - 1][y] != 0) &#123; queue.add(new int[]&#123;x - 1, y&#125;); &#125; if (x + 1 &lt; grid.length &amp;&amp; !visited[x + 1][y] &amp;&amp; grid[x + 1][y] != 2 &amp;&amp; grid[x + 1][y] != 0) &#123; queue.add(new int[]&#123;x + 1, y&#125;); &#125; if (y - 1 &gt;= 0 &amp;&amp; !visited[x][y - 1] &amp;&amp; grid[x][y - 1] != 2 &amp;&amp; grid[x][y - 1] != 0) &#123; queue.add(new int[]&#123;x, y - 1&#125;); &#125; if (y + 1 &lt; grid[0].length &amp;&amp; !visited[x][y + 1] &amp;&amp; grid[x][y + 1] != 2 &amp;&amp; grid[x][y + 1] != 0) &#123; queue.add(new int[]&#123;x, y + 1&#125;); &#125; &#125; &#125; &#125;&#125; 多源广度优先搜索上面的的那个思路虽然可行，但是性能有点拉胯，因为一个格子被多次访问了。回到上面说的 那要怎么让多个起点同时遍历呢？ 其实BFS模板一般只有一个初始节点，当把所有的烂橘子当做第一层，模拟同时感染周围的新鲜橘子，他的周围的新鲜的橘子就都是下一轮的目标了，都是同时的。所以事情就变得简单了起来。 其中特别注意一些特殊情况，例如只有烂橘子、只有好橘子；还有就是BFS图的遍历要特别注意visited访问标记要在加入到队列之后就要设置了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class Solution &#123; public int orangesRotting(int[][] grid) &#123; boolean[][] visited = new boolean[grid.length][grid[0].length]; Queue&lt;int[]&gt; queue = new LinkedList&lt;&gt;(); for (int i = 0; i &lt; grid.length; i++) &#123; for (int j = 0; j &lt; grid[i].length; j++) &#123; // 所有的烂橘子都加入队列 if (grid[i][j] == 2) &#123; queue.offer(new int[]&#123;i, j&#125;); visited[i][j] = true; &#125; &#125; &#125; int depth = 0; // flag是判断有没有烂橘子 boolean flag = false; while (!queue.isEmpty()) &#123; flag = true; depth++; int limit = queue.size(); for (int i = 0; i &lt; limit; i++) &#123; int[] xy = queue.poll(); int x = xy[0]; int y = xy[1]; visited[x][y] = true; if (grid[x][y] == 1) &#123; grid[x][y] = 2; &#125; if (x - 1 &gt;= 0 &amp;&amp; !visited[x - 1][y] &amp;&amp; grid[x - 1][y] == 1) &#123; queue.offer(new int[]&#123;x - 1, y&#125;); // 这里要先控制访问标记，防止被下个 if 代码逻辑重复加入了 visited[x - 1][y] = true; &#125; if (x + 1 &lt; grid.length &amp;&amp; !visited[x + 1][y] &amp;&amp; grid[x + 1][y] == 1) &#123; queue.offer(new int[]&#123;x + 1, y&#125;); visited[x + 1][y] = true; &#125; if (y - 1 &gt;= 0 &amp;&amp; !visited[x][y - 1] &amp;&amp; grid[x][y - 1] == 1) &#123; queue.offer(new int[]&#123;x, y - 1&#125;); visited[x][y - 1] = true; &#125; if (y + 1 &lt; grid[0].length &amp;&amp; !visited[x][y + 1] &amp;&amp; grid[x][y + 1] == 1) &#123; queue.offer(new int[]&#123;x, y + 1&#125;); visited[x][y + 1] = true; &#125; &#125; &#125; for (int[] ints : grid) &#123; for (int anInt : ints) &#123; if (anInt == 1) &#123; return -1; &#125; &#125; &#125; return flag ? depth - 1 : depth; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"},{"name":"广度优先搜索","slug":"广度优先搜索","permalink":"https://matthew-han.github.io/tags/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"}]},{"title":"LeetCode #378 有序矩阵中第K小的元素","slug":"LeetCode-378-有序矩阵中第K小的元素","date":"2020-08-15T19:58:03.000Z","updated":"2025-09-03T02:52:50.971Z","comments":true,"path":"post/a0c666d0-df31-11ea-a0a7-39ac104f8724/","permalink":"https://matthew-han.github.io/post/a0c666d0-df31-11ea-a0a7-39ac104f8724/","excerpt":"","text":"Problem Description给定一个 n x n 矩阵，其中每行和每列元素均按升序排序，找到矩阵中第 k 小的元素。请注意，它是排序后的第 k 小元素，而不是第 k 个不同的元素。 note你可以假设 k 的值永远是有效的，1 ≤ k ≤ n ^ 2 e.g. 示例： 12345678matrix = [ [1, 5, 9], [10, 11, 13], [12, 13, 15]],k = 8,返回 13。 Solution有一说一，被二维数组中的查找这道题整魔怔了。该题目的一种解法是将该矩阵模拟成一个二叉搜索树，利用其性质来做遍历方向的决策从而快速找到target。因为是模拟二叉搜索树，所以查找的时间复杂度是O(log(n ^ 2) )害挺快的。而这题也是同样的矩阵，但求的是第k个值（排序好的第K位）。 刚好晚上看了麻省理工公开课的其中一节课（二叉搜索树和快排）。认识到了二者相似性和奇妙之处。二叉搜索树的构建过程和快排的排序过程，二者在最坏的情况下时间复杂度都是O(n ^ 2) ，平均时间复杂度都是O(nlog(n) )，原理十分类似。BST在最差的情况是什么呢？就是像链表一样的情况，只有左节点或者右节点，这样它的高度就是节点数量（N），而在满二叉树下它的高度是（logN）。所以N个元素在构建BST的过程中，会先查找它应该在的位置（logN），N个元素就是O(nlog(n) )。但是在有序的数列（正、逆序）中会出现很糟糕的情况，这点和快排的pivot的选择很像。 所以这道题我就在想可不可以利用BST的中序遍历的结果来求第K个元素？该矩阵的特性很像BST，因为该矩阵的扁平成一维数组的结果对于构建BST应该是比较理想的，不可能出现上图的这种情况。 我的思路： 将矩阵遍历，添加到一个新数组中； 将该序列构建BST（新的序列对于构建BST是理想的）； 对该BST中序遍历，结果放在一个新数组中； 得到该新数组的第k个元素。 先将该矩阵的元素来构建一颗二叉搜索树。以下是二叉树模型： 12345678910111213141516171819public class TreeNode &#123; public int val; public TreeNode left; public TreeNode right; public TreeNode(int x) &#123; val = x; &#125; @Override public String toString() &#123; return &quot;TreeNode&#123;&quot; + &quot;val=&quot; + val + &quot;, left=&quot; + left + &quot;, right=&quot; + right + &#x27;&#125;&#x27;; &#125;&#125; 通过深度优先遍历的方式，对矩阵的右上角向左向下遍历，为了不出现重复访问，设置一个visited访问标记。类似先序遍历： 12345678public static void dfs2(int[][] matrix, int x, int y, boolean[][] visited, List&lt;Integer&gt; res) &#123; if (x &gt;= 0 &amp;&amp; y &gt;= 0 &amp;&amp; x &lt; matrix.length &amp;&amp; y &lt; matrix[0].length &amp;&amp; !visited[x][y]) &#123; visited[x][y] = true; res.add(matrix[x][y]); dfs2(matrix, x - 1, y, visited, res); dfs2(matrix, x, y + 1, visited, res); &#125;&#125; 接下来就是构建BST的过程代码辣： 123456789101112131415161718public static void buildBst(int n, TreeNode root) &#123; if (n &lt;= root.val) &#123; if (root.left == null) &#123; root.left = new TreeNode(n); &#125; else &#123; root = root.left; buildBst(n, root); &#125; &#125; else &#123; if (root.right == null) &#123; root.right = new TreeNode(n); &#125; else &#123; root = root.right; buildBst(n, root); &#125; &#125;&#125; 然后是对BST的中序遍历，BST的中序遍历打印的结果，一定是升序的。 1234567public static void dfs(TreeNode root, List&lt;Integer&gt; res) &#123; if (root != null) &#123; dfs(root.left, res); res.add(root.val); dfs(root.right, res); &#125;&#125; 其中要注意root节点在构建之前就已经创建了，所以第一个遍历的数组下标从1开始遍历，完整的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class KthSmallestElementInaSortedMatrix &#123; public static int kthSmallest(int[][] matrix, int k) &#123; List&lt;Integer&gt; tmp = new ArrayList&lt;&gt;(); List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); boolean[][] visited = new boolean[matrix.length][matrix[0].length]; dfs2(matrix, matrix.length - 1, 0, visited, tmp); TreeNode root = new TreeNode(tmp.get(0)); // 第一位是root节点，已经add了 for (int i = 1; i &lt; tmp.size(); i++) &#123; buildBst(tmp.get(i), root); &#125; dfs(root, res); return res.get(k - 1); &#125; public static void buildBst(int n, TreeNode root) &#123; if (n &lt;= root.val) &#123; if (root.left == null) &#123; root.left = new TreeNode(n); &#125; else &#123; root = root.left; buildBst(n, root); &#125; &#125; else &#123; if (root.right == null) &#123; root.right = new TreeNode(n); &#125; else &#123; root = root.right; buildBst(n, root); &#125; &#125; &#125; public static void dfs(TreeNode root, List&lt;Integer&gt; res) &#123; if (root != null) &#123; dfs(root.left, res); res.add(root.val); dfs(root.right, res); &#125; &#125; public static void dfs2(int[][] matrix, int x, int y, boolean[][] visited, List&lt;Integer&gt; res) &#123; if (x &gt;= 0 &amp;&amp; y &gt;= 0 &amp;&amp; x &lt; matrix.length &amp;&amp; y &lt; matrix[0].length &amp;&amp; !visited[x][y]) &#123; visited[x][y] = true; res.add(matrix[x][y]); dfs2(matrix, x - 1, y, visited, res); dfs2(matrix, x, y + 1, visited, res); &#125; &#125;&#125;class TreeNode &#123; public int val; public TreeNode left; public TreeNode right; public TreeNode(int x) &#123; val = x; &#125; @Override public String toString() &#123; return &quot;TreeNode&#123;&quot; + &quot;val=&quot; + val + &quot;, left=&quot; + left + &quot;, right=&quot; + right + &#x27;&#125;&#x27;; &#125;&#125; 最后，当然性能拉胯了。。这只是一种奇葩做法。。","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"},{"name":"二叉搜索树","slug":"二叉搜索树","permalink":"https://matthew-han.github.io/tags/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/"},{"name":"二叉树","slug":"二叉树","permalink":"https://matthew-han.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"}]},{"title":"LeetCode 剑指 Offer #04 二维数组中的查找","slug":"LeetCode-剑指-Offer-04-二维数组中的查找","date":"2020-08-14T08:20:19.000Z","updated":"2025-09-03T02:52:50.971Z","comments":true,"path":"post/fde16a80-de06-11ea-9d6c-0b86d1eb3e64/","permalink":"https://matthew-han.github.io/post/fde16a80-de06-11ea-9d6c-0b86d1eb3e64/","excerpt":"","text":"Problem Description在一个 n * m 的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 e.g.现有矩阵 matrix 如下： 1234567[ [1, 4, 7, 11, 15], [2, 5, 8, 12, 19], [3, 6, 9, 16, 22], [10, 13, 14, 17, 24], [18, 21, 23, 26, 30]] 给定 target &#x3D; 5，返回 true。 给定 target &#x3D; 20，返回 false。 note 0 &lt;= n &lt;= 1000 0 &lt;= m &lt;= 1000 Solution方法有很多，单纯双for循环暴力肯定太low。主要还是双指针、二分法这些。不过有个思路很好，站在该矩阵的右上角来看，这货就是一个「二叉搜索树」。 二叉搜索树的性质： 节点的左子树上的所有节点的值都小于等于节点的值； 节点的右子树上的所有节点的值都大于等于节点的值； 左子树和右子树也都是BST。 那就模拟一颗二叉搜索树来做咯： 12345678910111213141516171819202122232425262728293031public class LcOf04 &#123; boolean flag = false; /** * 当成二叉搜索树来做 * 执行用时： 0 ms , 在所有 Java 提交中击败了 100.00% 的用户 * 内存消耗： 45.5 MB , 在所有 Java 提交中击败了 65.46% 的用户 * * @param matrix * @param target * @return */ public boolean findNumberIn2DArray(int[][] matrix, int target) &#123; dfs(matrix, matrix.length - 1, 0, target); return flag; &#125; public void dfs(int[][] matrix, int i, int j, int target) &#123; if (i &gt;= 0 &amp;&amp; i &lt; matrix.length &amp;&amp; j &gt;= 0 &amp;&amp; j &lt; matrix[0].length) &#123; if (matrix[i][j] == target) &#123; flag = true; &#125; else if (matrix[i][j] &lt; target) &#123; dfs(matrix, i, j + 1, target); &#125; else &#123; dfs(matrix, i - 1, j, target); &#125; &#125; &#125;&#125; 其中注意下，如果用双指针、二分法最好从右上角为起点。","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"stack","slug":"stack","permalink":"https://matthew-han.github.io/tags/stack/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"},{"name":"二叉搜索树","slug":"二叉搜索树","permalink":"https://matthew-han.github.io/tags/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/"},{"name":"深度优先搜索","slug":"深度优先搜索","permalink":"https://matthew-han.github.io/tags/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"}]},{"title":"LeetCode #934 最短的桥","slug":"LeetCode-934-最短的桥","date":"2020-08-14T01:42:21.000Z","updated":"2025-09-03T02:52:50.971Z","comments":true,"path":"post/658c1730-ddcf-11ea-9e4c-d3e8698fdb4b/","permalink":"https://matthew-han.github.io/post/658c1730-ddcf-11ea-9e4c-d3e8698fdb4b/","excerpt":"","text":"Problem Description在给定的二维二进制数组 A 中，存在两座岛。（岛是由四面相连的 1 形成的一个最大组。） 现在，我们可以将 0 变为 1，以使两座岛连接起来，变成一座岛。 返回必须翻转的 0 的最小数目。（可以保证答案至少是 1。） note 1 &lt;= A.length = A[0].length &lt;= 100 A[i][j] == 0 或 A[i][j] == 1 e.g. 示例 1： 输入：[[0,1],[1,0]] 输出：1 示例 2： 输入：[[0,1,0],[0,0,0],[0,0,1]] 输出：2 示例 3： 输入：[[1,1,1,1,1],[1,0,0,0,1],[1,0,1,0,1],[1,0,0,0,1],[1,1,1,1,1]] 输出：1 Solution题目保证答案至少是1，那么一定是2个岛。岛的定义是上下左右相连所以斜着的不算。返回翻转0的最小值，这个最小值就是桥的长度，也就是「最短路径」。 一般看到「最短路径」我们会想到bfs、A*、Dijkstra算法，一般都是点对点的，这里是两个岛屿，所以只要将一个岛的所有边缘上的点都求一遍到第二个岛的路径，返回最小的路径就可以了。 所以问题就是怎么找出这两个岛？岛屿只有上下左右相连，所以可以根据深度优先搜索，将某坐标的上下左右进行搜索，如果是1则继续搜索，是0则终止。为了将两个岛区分开，我们需要将第一个找到的岛「涂色」，因为后面需要找第二个岛，如果都用1表示就没法区分开了。 注意的点： bfs去找第二个岛，因为是第一个岛的每个节点去广搜，所以visited访问标记每次循环需要初始化。 bfs周围的点如果是-1的话没必要入队，因为可能同是旁边的点（旁边的点会bfs一次，这里重复了），或者是第一个岛的非边缘的点，一定不是「最短路径」。 bfs一定能找到第二个岛的点，所以一定是在迭代里return的。 优化点也有，比如在该题其实不需要visited访问标记，每次初始化很浪费时间空间。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103public class ShortestBridge &#123; public static int shortestBridge(int[][] arr) &#123; List&lt;int[]&gt; firstLand = new ArrayList&lt;&gt;(); boolean[][] visited = new boolean[arr.length][arr[0].length]; boolean flag = false; for (int i = 0; i &lt; arr.length; i++) &#123; if (flag) &#123; break; &#125; // 设置一个flag，找到后需要继续遍历这个arr了。 for (int j = 0; j &lt; arr[i].length; j++) &#123; if (arr[i][j] == 1) &#123; dfs(arr, i, j, visited, firstLand); flag = true; break; &#125; &#125; &#125; int ans = Integer.MAX_VALUE; for (int[] xy : firstLand) &#123; // 【注意】每次初始化访问标记【注意】 visited = new boolean[arr.length][arr[0].length]; ans = Math.min(ans, bfs(arr, xy[0], xy[1], visited)); &#125; return ans; &#125; /** * * @param arr * @param x * @param y * @param visited * @param firstLand */ public static void dfs(int[][] arr, int x, int y, boolean[][] visited, List&lt;int[]&gt; firstLand) &#123; if (x &gt;= 0 &amp;&amp; y &gt;= 0 &amp;&amp; x &lt; arr.length &amp;&amp; y &lt; arr[0].length &amp;&amp; !visited[x][y]) &#123; visited[x][y] = true; if (arr[x][y] == 0) &#123; return; &#125; arr[x][y] = -1; firstLand.add(new int[]&#123;x, y&#125;); // 仅仅只有上下左右 dfs(arr, x - 1, y, visited, firstLand); dfs(arr, x + 1, y, visited, firstLand); dfs(arr, x, y - 1, visited, firstLand); dfs(arr, x, y + 1, visited, firstLand); &#125; &#125; /** * wcnd，写死我了 * * @param arr * @param x * @param y * @param visited * @return */ public static int bfs(int[][] arr, int x, int y, boolean[][] visited) &#123; // 最后要减一 int len = -1; Queue&lt;int[]&gt; queue = new LinkedList&lt;&gt;(); queue.offer(new int[]&#123;x, y&#125;); visited[x][y] = true; while (!queue.isEmpty()) &#123; int limit = queue.size(); for (int i = 0; i &lt; limit; i++) &#123; int[] curr = queue.poll(); x = curr[0]; y = curr[1]; // 找到了1 if (arr[x][y] == 1) &#123; return len; &#125; // 如果周围的节点是-1的话，没必要入队 if (x - 1 &gt;= 0 &amp;&amp; !visited[x - 1][y] &amp;&amp; arr[x - 1][y] != -1) &#123; queue.offer(new int[]&#123;x - 1, y&#125;); visited[x - 1][y] = true; &#125; if (x + 1 &lt; arr.length &amp;&amp; !visited[x + 1][y] &amp;&amp; arr[x + 1][y] != -1) &#123; queue.offer(new int[]&#123;x + 1, y&#125;); visited[x + 1][y] = true; &#125; if (y - 1 &gt;= 0 &amp;&amp; !visited[x][y - 1] &amp;&amp; arr[x][y - 1] != -1) &#123; queue.offer(new int[]&#123;x, y - 1&#125;); visited[x][y - 1] = true; &#125; if (y + 1 &lt; arr[0].length &amp;&amp; !visited[x][y + 1] &amp;&amp; arr[x][y + 1] != -1) &#123; queue.offer(new int[]&#123;x, y + 1&#125;); visited[x][y + 1] = true; &#125; &#125; len++; &#125; // 一定是可以找到最短路径的，所以这里返回的是错误的 return Integer.MAX_VALUE; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"},{"name":"深度优先搜索","slug":"深度优先搜索","permalink":"https://matthew-han.github.io/tags/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"广度优先搜索","slug":"广度优先搜索","permalink":"https://matthew-han.github.io/tags/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"}]},{"title":"LeetCode 面试题 03.01. 三合一","slug":"LeetCode-面试题-03-01-三合一","date":"2020-07-24T08:12:26.000Z","updated":"2025-09-03T02:52:50.971Z","comments":true,"path":"post/68f56ac0-cd85-11ea-a144-f7a4331a0642/","permalink":"https://matthew-han.github.io/post/68f56ac0-cd85-11ea-a144-f7a4331a0642/","excerpt":"","text":"Problem Description三合一。描述如何只用一个数组来实现三个栈。 你应该实现： push(stackNum, value) pop(stackNum) isEmpty(stackNum) peek(stackNum) stackNum表示栈下标，value表示压入的值。 构造函数会传入一个stackSize参数，代表每个栈的大小。 e.g. 示例 1: 输入：12[&quot;TripleInOne&quot;, &quot;push&quot;, &quot;push&quot;, &quot;pop&quot;, &quot;pop&quot;, &quot;pop&quot;, &quot;isEmpty&quot;][[1], [0, 1], [0, 2], [0], [0], [0], [0]] 输出：1[null, null, null, 1, -1, -1, true] 说明：当栈为空时pop, peek返回-1，当栈满时push不压入元素。 示例 2: 输入：12[&quot;TripleInOne&quot;, &quot;push&quot;, &quot;push&quot;, &quot;push&quot;, &quot;pop&quot;, &quot;pop&quot;, &quot;pop&quot;, &quot;peek&quot;][[2], [0, 1], [0, 2], [0, 3], [0], [0], [0], [0]] 输出：1[null, null, null, null, 2, 1, -1, -1] Solution用数组来实现栈是非常简单的，不过这里需要实现3个栈且只能用一个数组。那肯定是需要将这个数组分段利用指针去管理了。 pop方法只要操作head指针的size即可：大于0，自减；小于等于0，return -1； peek方法类似pop方法； push方法，判断head指针的size，有空余，则移动指针去塞入新数据； isEmpty方法，判断head指针的size，为0则为空。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public class ThreeInOne &#123; private final int[] data; private final int size; private final int capacity; /** * 执行用时： 13 ms , 在所有 Java 提交中击败了 56.62% 的用户 * 内存消耗： 49.1 MB , 在所有 Java 提交中击败了 100.00% 的用户 * * @param stackSize */ public ThreeInOne(int stackSize) &#123; capacity = stackSize * 3; size = capacity + 3; data = new int[size]; &#125; public void push(int stackNum, int value) &#123; int index = headIndex(stackNum); System.out.println(&quot;index = &quot; + index); // 头指针，容量计数功能，如果超过容量，就塞不了 if (data[index] &lt; capacity / 3) &#123; data[index]++; // 剩余位置塞入数据 data[index + data[index]] = value; &#125; &#125; public int pop(int stackNum) &#123; int index = headIndex(stackNum); // stack为空 if (data[index] == 0) &#123; return -1; &#125; else &#123; int temp = data[index + data[index]]; data[index]--; // 这里并不需要真的删除这个元素 return temp; &#125; &#125; public int peek(int stackNum) &#123; int index = headIndex(stackNum); if (data[index] == 0) &#123; return -1; &#125; else &#123; return data[index + data[index]]; &#125; &#125; public boolean isEmpty(int stackNum) &#123; return data[headIndex(stackNum)] == 0; &#125; /** * 根据stack下标取头指针 * @param stackNum * @return */ public int headIndex(int stackNum) &#123; int index = 0; switch (stackNum) &#123; case 1: index = capacity / 3 + 1; break; case 2: index = size - 1 - capacity / 3; break; default: &#125; return index; &#125; @Override public String toString() &#123; return &quot;ThreeInOne&#123;&quot; + &quot;data=&quot; + Arrays.toString(data) + &quot;, size=&quot; + size + &quot;, capacity=&quot; + capacity + &#x27;&#125;&#x27;; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"数组","slug":"数组","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"栈","slug":"栈","permalink":"https://matthew-han.github.io/tags/%E6%A0%88/"},{"name":"stack","slug":"stack","permalink":"https://matthew-han.github.io/tags/stack/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"}]},{"title":"LeetCode #540 有序数组中的单一元素","slug":"LeetCode-540-有序数组中的单一元素","date":"2020-07-03T02:30:32.000Z","updated":"2025-09-03T02:52:50.971Z","comments":true,"path":"post/2ad612f0-bcd5-11ea-8844-eba35fffe767/","permalink":"https://matthew-han.github.io/post/2ad612f0-bcd5-11ea-8844-eba35fffe767/","excerpt":"","text":"Problem Description给定一个只包含整数的有序数组，每个元素都会出现两次，唯有一个数只会出现一次，找出这个数。 note您的方案应该在 $O(log n)$ 时间复杂度和 $O(1)$ 空间复杂度中运行。 e.g. 示例 1: 12输入: [1,1,2,3,3,4,4,8,8]输出: 2 示例 2: 12输入: [3,3,7,7,10,11,11]输出: 10 Solution题目简单非常简单，但其中题干中重点强调了O(logn)的时间复杂度和O(1)空间复杂度，所以一切会伴随输入数组大小变化的额外空间和遍历也不行哦，即使是用双指针优化到O(logn&#x2F;4)也是不满足的。一眼看到O(logn)的时间复杂度就想到了题目的本意应该是让我们利用二分法来解。 因为是有序数组，并且每个元素都是出现两次，除了唯一的一个元素。所以相同的元素一定是连续的并且长度为奇数，所以我们可以每次取中间的元素，和左右两边比较（注意边界），找出相邻元素相同的情况，将整个数组分隔开，左边的子串和右边子串一定有一个是奇数长度（该数组一定有个唯一元素），单个元素就一定藏在这个子串里。 1234567891011121314151617181920212223242526272829public static int singleNonDuplicate(int[] nums) &#123; int left = 0; int right = nums.length - 1; while (left &lt;= right) &#123; int mid = left + (right - left) / 2; if (mid - 1 &gt;= 0 &amp;&amp; nums[mid] == nums[mid - 1]) &#123; // 奇数在左边 if (((mid - 1) &amp; 1) == 1) &#123; right = mid - 2; &#125; else &#123; left = mid + 1; &#125; &#125; else if (mid + 1 &lt; nums.length &amp;&amp; nums[mid] == nums[mid + 1]) &#123; // 奇数在左边 if ((mid &amp; 1) == 1) &#123; right = mid - 1; &#125; else &#123; left = mid + 2; &#125; &#125; else &#123; return nums[mid]; &#125; System.out.println(&quot;left = &quot; + left); System.out.println(&quot;right = &quot; + right); &#125; return 0;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"},{"name":"二分法","slug":"二分法","permalink":"https://matthew-han.github.io/tags/%E4%BA%8C%E5%88%86%E6%B3%95/"}]},{"title":"LeetCode #892 三维形体的表面积","slug":"LeetCode-892-三维形体的表面积","date":"2020-06-22T06:50:30.000Z","updated":"2025-09-03T02:52:50.971Z","comments":true,"path":"post/a984b2c0-b454-11ea-bd3f-9d082b6cabfa/","permalink":"https://matthew-han.github.io/post/a984b2c0-b454-11ea-bd3f-9d082b6cabfa/","excerpt":"","text":"Problem Description在 N * N 的网格上，我们放置一些 1 * 1 * 1 的立方体。 每个值 v = grid[i][j] 表示 v 个正方体叠放在对应单元格 (i, j) 上。 请你返回最终形体的表面积。 note 1 &lt;= N &lt;= 50 0 &lt;= grid[i][j] &lt;= 50 e.g. 示例 1： 输入：[[2]] 输出：10 示例 2： 输入：[[1,2],[3,4]] 输出：34 示例 3： 输入：[[1,0],[0,2]] 输出：16 示例 4： 输入：[[1,1,1],[1,0,1],[1,1,1]] 输出：32 示例 5： 输入：[[2, 2, 2], [2, 1, 2], [2, 2, 2]] 输出：46 Solution这题是#883 三维形体投影面积的升级版几何题目，883这题描述的利用一个二维数组的元素代表单个单元格的高度按照从左向右的顺序在xy平面上从上到下堆叠，求xy、yz、xz三个投影面积。 883这题相对简单，投影面积就是求最大值，因为矮的会被高的「覆盖」，只要求三个面即可。 示例图： 但是889这题就复杂了很多，他需要的是整个形体的表面积，而非投影面积。于是就带来了一个问题，被挡住的柱状形体可能存在表面积。 一开始我思考的是按照883的方式，还是先求出6个面（整个形体）的投影面积，再加上「凹陷」的表面积即可。因为只有存在「凹陷」情况，才会多出一部分表面积，但是所谓的“正证法”，会遇到的情况就十分多样了。 比如： [[1, 0, 1]]和[1, 0, 0, 1] [[1, 0], [0, 2]] 当凹陷是2个单位时或者0的情况等等这些情况就比较复杂，凹陷的判断十分的纷繁凌乱，感觉这个办法就很蠢。 在题解中看到了一个“阿姨”的方法，属实8错。他的思路是把所有柱子作为一个单位，求出所有柱子的表面积，如：1的表面积是1 * 4 + 2为6，2的表面积是2 * 4 + 2为10，再减去柱子与柱子之间相贴的面积。 给阿姨倒一杯卡布奇诺。 所以，当我们遍历整个形体时，只要判断该柱子与「上面」和「左边」是否有接触，有接触且不为0（为0，即柱子不存在，也不会出现遮挡的情况）的话，就减去较矮的那个柱子的高度 * 2，因为是两面相贴，所以要乘以2。 Java代码如下： 12345678910111213141516171819public static int surfaceAreaPro(int[][] grid) &#123; int fucker = 0; for (int i = 0; i &lt; grid.length; i++) &#123; for (int j = 0; j &lt; grid[i].length; j++) &#123; // ① 柱子为0，则整个为0 fucker += (4 * grid[i][j] == 0 ? -2 : 4 * grid[i][j]) + 2; // ② if (i - 1 &gt;= 0 &amp;&amp; grid[i - 1][j] != 0 &amp;&amp; grid[i][j] != 0) &#123; fucker -= Math.min(grid[i][j], grid[i - 1][j]) * 2; &#125; // ③ if (j - 1 &gt;= 0 &amp;&amp; grid[i][j - 1] != 0 &amp;&amp; grid[i][j] != 0) &#123; fucker -= Math.min(grid[i][j], grid[i][j - 1]) * 2; &#125; &#125; &#125; return fucker;&#125; 另外说明一点，这样写更简洁，但是效率还可以提升，提升在哪呢？因为当前柱子高度为0的时候，直接跳过即可。可是如上这样写即使当前柱子高度为0，①②③这三步都会走一遍会影响效率，但是看起来更简洁就vans了。","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"},{"name":"几何","slug":"几何","permalink":"https://matthew-han.github.io/tags/%E5%87%A0%E4%BD%95/"},{"name":"数学","slug":"数学","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E5%AD%A6/"}]},{"title":"LeetCode #703 数据流中的第K大元素","slug":"LeetCode-703-数据流中的第K大元素","date":"2020-05-29T18:36:14.000Z","updated":"2025-09-03T02:52:50.971Z","comments":true,"path":"post/46834820-a1db-11ea-bfec-d3212239dc2e/","permalink":"https://matthew-han.github.io/post/46834820-a1db-11ea-bfec-d3212239dc2e/","excerpt":"","text":"Problem Description设计一个找到数据流中第K大元素的类（class）。注意是排序后的第K大元素，不是第K个不同的元素。 你的 KthLargest 类需要一个同时接收整数 k 和整数数组nums 的构造器，它包含数据流中的初始元素。每次调用 KthLargest.add，返回当前数据流中第K大的元素。 note你可以假设 nums 的长度≥ k-1 且k ≥ 1。 e.g.12345678int k = 3;int[] arr = [4,5,8,2];KthLargest kthLargest = new KthLargest(3, arr);kthLargest.add(3); // returns 4kthLargest.add(5); // returns 5kthLargest.add(10); // returns 5kthLargest.add(9); // returns 8kthLargest.add(4); // returns 8 Solution1. 额外数组空间12345678910111213141516171819202122class KthLargest &#123; private int len; private final int index; private final List&lt;Integer&gt; newData; public KthLargest(int k, int[] nums) &#123; index = k; len = nums.length; newData = new ArrayList&lt;&gt;(nums.length); for (int num : nums) &#123; newData.add(num); &#125; &#125; public int add(int val) &#123; len++; newData.add(val); Collections.sort(newData); return newData.get(len - index); &#125;&#125; 不过还是用原始数组，更底层更快一点： 1234567891011121314151617181920212223class KthLargest &#123; private int len; private int[] data; private final int index; public KthLargest(int k, int[] nums) &#123; index = k; len = nums.length; data = nums; &#125; public int add(int val) &#123; len++; int[] temp = new int[len]; System.arraycopy(data, 0, temp, 0, data.length); temp[len - 1] = val; Arrays.sort(temp); data = new int[len]; System.arraycopy(temp, 0, data, 0, temp.length); return data[len - index]; &#125;&#125; 2. 小顶堆题目中表述了add方法返回第K大元素即可，所以其实我们不必维护整个数组，只需要维护K个从大到小的元素即可。表面add方法而已，不是真的新增。 什么是堆？堆是一种非线性结构，可以把堆看作一个数组，也可以被看作一个完全二叉树，通俗来讲堆其实就是利用完全二叉树的结构来维护的一维数组。 按照堆的特点可以把堆分为大顶堆和小顶堆： 大顶堆：每个结点的值都大于或等于其左右孩子结点的值 小顶堆：每个结点的值都小于或等于其左右孩子结点的值 直接说用法： 升序：使用大顶堆 降序：使用小顶堆 我们这边每次add方法需要返回第K个从大到小元素，所以每次执行add方法需要保留K个降序的元素，这里就是采用了小顶堆。我们可以用优先队列PriorityQueue&lt;Integer&gt;来做（大顶堆的话需要重写排序方法，默认是升序）。优先队列的作用是保证每次取出的元素都是队列中权值最小的。 当堆内元素的个数小于等于K时，调用add方法入队；当第K+1个元素想入队时，和队首比较大小（队首是最小的）。比队首大，队首元素出队，新元素入队；比队首小，不作任何操作。这样就能保证队列的元素个数是K个，并且是队首是最小的（不一定是从小到大排序，但是队首一定是整个队列里最小的）。 所以就是两步： 控制队列大小为K 保证队首的元素比新加入的元素大 所以整个数组的第K大元素就是队列的队首peek()方法。 123456789101112131415161718192021222324class KthLargest &#123; // 小顶堆 private PriorityQueue&lt;Integer&gt; q; private int k; public KthLargestElementInaStream(int k, int[] nums) &#123; this.k = k; q = new PriorityQueue&lt;Integer&gt;(k); for (int i : nums) &#123; add(i); &#125; &#125; public int add(int val) &#123; if (q.size() &lt; k) &#123; q.offer(val); &#125; else if (q.peek() &lt; val) &#123; q.poll(); q.offer(val); &#125; return q.peek(); &#125;&#125; 补充PriorityQueue&lt;Integer&gt; queue = new PriorityQueue&lt;&gt;(1);这样一个优先队列，将数组[8, 5, 4, 12, 3]按顺序执行offer(element)方法，打印的结果是[3, 4, 5, 12, 8]，在执行offer(1)，打印的结果是[1, 4, 3, 12, 8, 5]。排序就是在二叉树的基础上，叶子节点和父节点比大小，比父节点大，交换位置，直到比父节点小或到根节点。","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"},{"name":"小顶堆","slug":"小顶堆","permalink":"https://matthew-han.github.io/tags/%E5%B0%8F%E9%A1%B6%E5%A0%86/"}]},{"title":"LeetCode #367 有效的完全平方数","slug":"LeetCode-367-有效的完全平方数","date":"2020-05-11T03:32:20.000Z","updated":"2025-09-03T02:52:50.971Z","comments":true,"path":"post/6d8c47a0-9353-11ea-9bbb-9b051857d619/","permalink":"https://matthew-han.github.io/post/6d8c47a0-9353-11ea-9bbb-9b051857d619/","excerpt":"","text":"Problem Description给定一个正整数 num，编写一个函数，如果 num 是一个完全平方数，则返回 True，否则返回 False。 note不要使用任何内置的库函数，如：sqrt。 e.g. 示例1： 输入：16 输出：True 示例2： 输入：14 输出：False Solution1. 暴力法可以无限优化的方法，其优化的核心就在于循环的起始和终止，效率很低不考虑。 2. 根区间&amp;二分法 Java里int的最大值是0x7fffffff，也就是132-1（2147483647），大约21亿。最大值的平方根约等于46340。那我不是根据整数的位数来得到一个计算的区间，这样不是能有效缩小循环的次数了吗？ 比如1位数和2位数[10, 99]，平方根一定是落在[1, 10)，比如3位数[100, 999]，平方根一定是落在[10, 32)，比如4位数[1000, 9999]，平方根一定是落在[31, 100)； 当这个数很大的话（最大为2147483647），相应的区间也会变大，但是区间最大的反而是9位数，因为10位数最大只到2147483647； 我们根据整数的长度取得平方根的区间后可以根据二分查找法，将平均时间复杂度降低。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768class Solution &#123; public static boolean isPerfectSquare(int num) &#123; int[] se = interval(String.valueOf(num).length()); int left = se[0]; int right = se[1]; while (true) &#123; int mid = left + (right - left) / 2; if (mid * mid &lt; num) &#123; if (right - left == 1) &#123; return false; &#125; else &#123; left = mid; &#125; &#125; else if (mid * mid == num) &#123; return true; &#125; else &#123; if (right - left == 1) &#123; return false; &#125; else &#123; right = mid; &#125; &#125; &#125; &#125; public static int[] interval(int len) &#123; int start; int end; switch (len) &#123; case 3: start = 10; end = 32; break; case 4: start = 31; end = 100; break; case 5: start = 100; end = 317; break; case 6: start = 316; end = 1000; break; case 7: start = 1000; end = 3163; break; case 8: start = 3162; end = 10000; break; case 9: start = 10000; end = 31623; break; case 10: start = 31622; end = 46341; break; default: start = 1; end = 10; &#125; return new int[]&#123;start, end&#125;; &#125;&#125; 注意：二分法有一个很需要注意的点，就是求中间值mid的计算公式。一般最好不要直接这样做：(left + right) / 2，因为很有可能在left + right的过程中就溢出了，算出来是负数的。改成long类型或者这样算：left + (right - left) / 2。 两个点优化之后，即使一个很大的数字也不需要经过几次的查找便可知道是否是完全平方数。以上算法的时间复杂度为O(1) + O(log2n) &#x3D; O(log2n)。","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"},{"name":"二分法","slug":"二分法","permalink":"https://matthew-han.github.io/tags/%E4%BA%8C%E5%88%86%E6%B3%95/"}]},{"title":"LeetCode #225 用队列实现栈","slug":"LeetCode-225-用队列实现栈","date":"2020-04-29T02:35:51.000Z","updated":"2025-09-03T02:52:50.971Z","comments":true,"path":"post/24861850-89c2-11ea-9ae2-d515fd713cdf/","permalink":"https://matthew-han.github.io/post/24861850-89c2-11ea-9ae2-d515fd713cdf/","excerpt":"","text":"Problem Description 使用队列实现栈的下列操作： push(x) – 元素 x 入栈 pop() – 移除栈顶元素 top() – 获取栈顶元素 empty() – 返回栈是否为空 note 你只能使用队列的基本操作– 也就是 push to back, peek&#x2F;pop from front, size, 和 is empty 这些操作是合法的。 你所使用的语言也许不支持队列。 你可以使用 list 或者 deque（双端队列）来模拟一个队列 , 只要是标准的队列操作即可。 你可以假设所有操作都是有效的（例如, 对一个空的栈不会调用 pop 或者 top 操作）。 Solution1. 双向队列Deque实现利用双端队列Deque接口的实现类LinkedList可以很简洁的完成，Deque拥有一个boolean offerFirst(E e);方法。因为底层是双向链表，prev和next指针可以很好帮你实现头尾乱♂插。 12345678910111213141516171819202122232425class MyStack &#123; Deque&lt;Integer&gt; deque; public MyStack() &#123; deque = new LinkedList&lt;&gt;(); &#125; public void push(int x) &#123; deque.offerFirst(x); &#125; public int pop() &#123; return deque.remove() ; &#125; public int top() &#123; return deque.element(); &#125; public boolean empty() &#123; return deque.isEmpty(); &#125;&#125; 2. 双队列形成一个闭环 2个单向队列queue和reverseQueue； queue初次push时，判断是否为空，为空直接调用offer方法； 当queue不为空时，将所有的元素从头部出队，入队到reverseQueue。queue入队新的元素； 这时两个队列，queue只有新的元素在队列中，reverseQueue拥有queue刚刚出队的元素； 再次将reverseQueue的元素循环出队到queue，保证每次调用push方法时，该队列是空的； 两个单项队列变成闭环。 12345678910111213141516171819202122232425262728293031323334353637class MyStack &#123; Queue&lt;Integer&gt; queue; Queue&lt;Integer&gt; reverseQueue; public MyStack() &#123; queue = new LinkedList&lt;&gt;(); reverseQueue = new LinkedList&lt;&gt;(); &#125; public void push(int x) &#123; /** * 利用两个单向队列 */ if (queue.isEmpty()) &#123; queue.offer(x); &#125; else &#123; reverseQueue.addAll(queue); queue.clear(); queue.offer(x); queue.addAll(reverseQueue); reverseQueue.clear(); &#125; &#125; public int pop() &#123; return queue.remove(); &#125; public int top() &#123; return queue.element(); &#125; public boolean empty() &#123; return queue.isEmpty(); &#125;&#125; 3. 单个单向队列其中注意：不要使用自身的forEach方法，根据队列的长度搞个循环即可。 push方法核心代码： 123456789/* * 单个单向队列 */public void push(int x) &#123; singleQueue.add(x); for (int i = 0; i &lt; singleQueue.size() - 1; i++) &#123; singleQueue.add(singleQueue.poll()); &#125;&#125; 注意是size - 1。因为最新add的那个元素不需要执行poll方法。","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"栈","slug":"栈","permalink":"https://matthew-han.github.io/tags/%E6%A0%88/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"},{"name":"队列","slug":"队列","permalink":"https://matthew-han.github.io/tags/%E9%98%9F%E5%88%97/"}]},{"title":"数据结构：Queue","slug":"数据结构：Queue","date":"2020-04-28T09:03:50.000Z","updated":"2025-09-03T02:52:50.978Z","comments":true,"path":"post/2d52f0e0-892f-11ea-8e9a-97d863cbb17c/","permalink":"https://matthew-han.github.io/post/2d52f0e0-892f-11ea-8e9a-97d863cbb17c/","excerpt":"","text":"介绍先进先出，一种特殊的线性表，只允许表在一端进行获取操作，在另一端进行插入操作。当不存在元素时，则为空队列。自从 BlockingQueue（阻塞队列）问世以来，队列的地位得到极大地提升，在各种高并发编程的场景，经常被作为 Buffer（数据缓冲区）使用。 通常我们把LinkedList当成Queue来用，Queue类自身的一些方法： 方法 方法描述 boolean add(E e) 入队一个元素至队尾 boolean offer(E e); 入队一个元素至队尾 E remove() 从头部出队一个元素 E poll() 从头部出队一个元素 E element() 查询头元素 E peek() 查询头元素 以下摘自菜鸟教程： offer，add 区别： 一些队列有大小限制，因此如果想在一个满的队列中加入一个新项，多出的项就会被拒绝。 这时新的offer()方法就可以起作用了。它不是对调用add()方法抛出一个unchecked异常，而只是得到由offer()返回的false。 poll，remove 区别： remove()和poll()方法都是从队列中删除第一个元素。remove()的行为与Collection接口的版本相似， 但是新的poll()方法在用空集合调用时不是抛出异常，只是返回null。因此新的方法更适合容易出现异常条件的情况。 peek，element区别： element()和peek()用于在队列的头部查询元素。与 remove() 方法类似，在队列为空时，element()抛出一个异常，而peek()返回null。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"},{"name":"数据结构","slug":"Java技术/数据结构","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"队列","slug":"队列","permalink":"https://matthew-han.github.io/tags/%E9%98%9F%E5%88%97/"},{"name":"Queue","slug":"Queue","permalink":"https://matthew-han.github.io/tags/Queue/"}]},{"title":"LeetCode #169 多数元素","slug":"LeetCode-169-多数元素","date":"2020-04-23T04:32:46.000Z","updated":"2025-09-03T02:52:50.970Z","comments":true,"path":"post/7b2e8940-851b-11ea-95ec-5b4f96ed301b/","permalink":"https://matthew-han.github.io/post/7b2e8940-851b-11ea-95ec-5b4f96ed301b/","excerpt":"","text":"Problem Description给定一个大小为 n 的数组，找到其中的多数元素。多数元素是指在数组中出现次数大于 ⌊ n/2 ⌋ 的元素。 你可以假设数组是非空的，并且给定的数组总是存在多数元素。 e.g. 示例 1: 输入: [3,2,3] 输出: 3 示例 2: 输入: [2,2,1,1,1,2,2] 输出: 2 Solution1. Hash表首先最容易想到的，利用Hash表： 1234567891011121314public static int majorityElement(int[] nums) &#123; Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(nums.length / 3 * 4 + 1); int max = nums.length / 2; AtomicInteger result = new AtomicInteger(); for (int num : nums) &#123; map.put(num, map.getOrDefault(num, 0) + 1); &#125; map.forEach((k, v) -&gt; &#123; if (v &gt; max) &#123; result.set(k); &#125; &#125;); return result.get();&#125; key来保存数组的元素，value来保存出现的次数。 因为众数的个数一定是大于n&#x2F;2的，所以只要取出value大于n&#x2F;2的key即可。 2. 随机流&amp;暴力流12345678910111213141516171819public static int thirdMethod(int[] nums) &#123; int count = 0; int index = (int) (Math.random() * nums.length); int fuck = nums[index]; for (int i = 0; i &lt; nums.length; i++) &#123; if (nums[i] == fuck) &#123; count++; &#125; if (count &gt; nums.length / 2) &#123; return nums[index]; &#125; else if (i == (nums.length - 1)) &#123; count = 0; i = -1; index = (int) (Math.random() * nums.length); fuck = nums[index]; &#125; &#125; return 0;&#125; 众数在题干中明确说明了个数是n&#x2F;2，一定是占据一半以上的，所以随机抽取一个元素，较大可能性是众数。统计该元素的个数，符合个数大于n&#x2F;2即可。一开始设置第一个元素为众数统计个数，全部遍历后如果不符合，则设置第二个元素为基准继续遍历。这样其实就和双for循环没什么区别了，不具随机性。 我一开始做法就是设置第一个元素为基准，这样写的最大时间复杂度是平方级 O(n2)，一旦众数全部位于数组的后半段，那么时间会超久，所以我这样提交，系统判定超出时间限制。 官方题解是随机设置一个基准，理想情况是众数较多，很容易抽中，较少的次数可以完成推断，但是存在一种极限情况，就是每次随机基准都抽不到众数，那么会变成无穷尽的计算。最坏情况的时间复杂度为 O(∞)。 3. 排序流1234public static int secondMethod(int[] nums) &#123; Arrays.sort(nums); return nums[nums.length / 2];&#125; 充分利用了n&#x2F;2的特性，将数组排序后，无论数组的长度是奇数还是偶数，第nums.length / 2 一定是众数。 4. 投票流该方法个人认为最有意思和最有拓展性。假设这样一个数组： [7, 7, 5, 7, 5, 1 | 5, 7 | 5, 5, 7, 7 | 7, 7, 7, 7] 初始化被选举人（elector）为第一个数，设定count &#x3D; 1，然后开始遍历； 当nextValue &#x3D;&#x3D; elector，count + 1，反之 - 1； 当count &#x3D;&#x3D; 0时，且存在nextValue时，nextValue成为下一个elector，count &#x3D; 1； 最终的选举人一定是那个众数 因为众数的个数一定是大于其它数字的和，所以相减一定大于0，最后剩下的被投票的那个元素一定是众数。 所以上述的数组，票数就是[1, 2, 1, 2, 1, 0 | 1, 0 | 1, 2, 1, 0 | 1, 2, 3, 4 遍历到数组的最后阶段，elector是7，后面票数越来越多，也不会被更换elector了。即使是众数都在前面 [7, 7, 7, 7, 7, 1, 5, 5 ]，众数的和也够减去后半段的其他元素的总和而保证elector不被更换。 该思想不复杂实现起来非常简单： 12345678910111213141516171819public static int boyerMoore(int[] nums) &#123; int count = 1; int elector = nums[0]; for (int i = 1; i &lt; nums.length; i++) &#123; if (nums[i] == elector) &#123; count++; &#125; else &#123; count--; &#125; /* * 上面的if-else可以改成这样 * count += (nums[i] == elector) ? 1 : -1; */ if (i + 1 &lt; nums.length &amp;&amp; count == 0) &#123; elector = nums[i + 1]; &#125; &#125; return elector;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"数组","slug":"数组","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"}]},{"title":"LeetCode #155 最小栈","slug":"LeetCode-155-最小栈","date":"2020-04-21T06:57:08.000Z","updated":"2025-09-03T02:52:50.970Z","comments":true,"path":"post/51044580-839d-11ea-a80d-c79a78360d60/","permalink":"https://matthew-han.github.io/post/51044580-839d-11ea-a80d-c79a78360d60/","excerpt":"","text":"Problem Description设计一个支持 push ，pop ，top 操作，并能在常数时间内检索到最小元素的栈。 push(x) —— 将元素 x 推入栈中。 pop() —— 删除栈顶的元素。 top() —— 获取栈顶元素。 getMin() —— 检索栈中的最小元素。 e.g.123456781. MinStack minStack = new MinStack();2. minStack.push(-2);3. minStack.push(0);4. minStack.push(-3);5. minStack.getMin(); ==&gt; 返回 -3.6. minStack.pop();7. minStack.top(); ==&gt; 返回 0.8. minStack.getMin(); ==&gt;返回 -2. Solution该题很简单，但是有意思的是，我的解法也算通过了，虽然题目说 在常数时间内检索到最小元素的栈。 但是这里应该指的是getMin()这个方法，所以即使我的push(Object obj)方法复杂度比较高也没关系。。 因为有删除元素（pop方法）的存在，所以最小值在push完之后还是会随时变。所以单纯使用一个变量来保存最小值是不可能的。 我使用了双栈来实现，实际不用双栈用其他的数据结构也可以。大概原理就是在push的过程中，一个标准stack正常push，另一个辅助栈从栈底到栈顶从小到大排序的插入，利用了Stack的父类（Vector）方法insertElementAt(Object obj, int i)，这里注意index是第二个参数。pop时，标准stack正常pop，辅助stack只需要remove标准stack刚刚pop返回的对象即可minStack.remove(stack.pop());。这样确保两栈移除的元素是相同的。 代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class MinStack &#123; private Stack&lt;Integer&gt; stack; private Stack&lt;Integer&gt; minStack; /** * 执行用时 : 6 ms , 在所有 Java 提交中击败了 97.91% 的用户 * 内存消耗 : 41.7 MB , 在所有 Java 提交中击败了 14.46% 的用户 */ public MinStack() &#123; stack = new Stack&lt;&gt;(); minStack = new Stack&lt;&gt;(); &#125; public void push(int x) &#123; stack.push(x); if (minStack.empty()) &#123; minStack.push(x); &#125; else if (x &gt;= minStack.peek()) &#123; minStack.push(x); &#125; else &#123; for (int i = 0; i &lt;= minStack.size(); i++) &#123; if (x &lt; minStack.get(i)) &#123; minStack.insertElementAt(x, i); break; &#125; &#125; &#125; &#125; public void pop() &#123; minStack.remove(stack.pop()); &#125; public int top() &#123; return stack.peek(); &#125; public int getMin() &#123; return minStack.firstElement(); &#125; @Override public String toString() &#123; return &quot;MinStack&#123;&quot; + &quot;stack=&quot; + stack + &quot;, minStack=&quot; + minStack + &#x27;&#125;&#x27;; &#125; public static void main(String[] args) &#123; MinStack minStack = new MinStack(); minStack.push(-2); minStack.push(0); minStack.push(-3); minStack.push(-11); minStack.push(-1); System.out.println(minStack.toString()); System.out.println(minStack.getMin()); minStack.pop(); minStack.top(); System.out.println(minStack.getMin()); &#125;&#125; Feature虽然我这样做是通过的，但其实我想的不够多，看了高赞的题解，即使是利用辅助栈push方法时间复杂度也可以不到线性级 O(n)。 因为题目是说了设计的该栈对于移除元素只有pop方法，就是从栈顶移除，也就是说next元素比当前顶部元素大的话，就没必要保留了，因为在只有pop方法的情况下，该元素一定是先被移除的。所以在条件下辅助栈可以不需要把所有元素保存。 除非题目加一个删除中间某个元素的方法的条件。 当然还有不用辅助栈的做法，利用压栈。","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"数组","slug":"数组","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"栈","slug":"栈","permalink":"https://matthew-han.github.io/tags/%E6%A0%88/"},{"name":"stack","slug":"stack","permalink":"https://matthew-han.github.io/tags/stack/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"}]},{"title":"数据结构：栈","slug":"数据结构：栈","date":"2020-04-21T06:13:37.000Z","updated":"2025-09-03T02:52:50.978Z","comments":true,"path":"post/3d28b600-8397-11ea-bfe6-d727069c8da8/","permalink":"https://matthew-han.github.io/post/3d28b600-8397-11ea-bfe6-d727069c8da8/","excerpt":"","text":"介绍last-in-first-out，后进先出是它最大的特点。class Stack&lt;E&gt; extends Vector&lt;E&gt; 作为Vector的子类。 Vector底层使用数组存储数据，所以Stack也是如此。 Stack类自身的一些方法： 方法 方法描述 boolean empty() 测试堆栈是否为空。 Object peek() 查看堆栈顶部的对象，但不从堆栈中移除它。 Object pop() 移除堆栈顶部的对象，并作为此函数的值返回该对象。 Object push(E item) 把项压入堆栈顶部。 int search(Object o) 返回距离栈顶最近的相同元素的距离，返回对象在堆栈中的位置，以 1 为基数。 其中search方法比较特殊，返回的是该元素的位置，但是从1开始的，这个不是数组下标。源码里是这样写的： 1234567public synchronized int search(Object o) &#123; int i = lastIndexOf(o); if (i &gt;= 0) &#123; return size() - i; &#125; return -1;&#125; 如果该栈不存在任何元素，使用pop和peek方法会报NPE。 以上方法都是用了synchronized进行修饰，确保线程同步。 父类方法（未完待续…）","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"},{"name":"数据结构","slug":"Java技术/数据结构","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"数组","slug":"数组","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"栈","slug":"栈","permalink":"https://matthew-han.github.io/tags/%E6%A0%88/"},{"name":"stack","slug":"stack","permalink":"https://matthew-han.github.io/tags/stack/"}]},{"title":"虐猫事件思考「虐」的定义","slug":"虐猫事件思考「虐」的定义","date":"2020-04-13T06:23:14.000Z","updated":"2025-09-03T02:52:50.979Z","comments":true,"path":"post/41de2f70-7d4f-11ea-b18b-ad951eb7124e/","permalink":"https://matthew-han.github.io/post/41de2f70-7d4f-11ea-b18b-ad951eb7124e/","excerpt":"","text":"我们需要一个上帝吗？ 自我解释小时候会觉得虐待动物是不道德错误的、或者说是心理问题、性格缺陷。长大后慢慢的看待问题不会在只关注事件本身，局限的从一两个点出发，开始学会多角度切入会去思考，怎么样算「虐待」呢？我们可以假定动物本身是抗拒这种被「虐待」的行为，那么绝育、关笼子、指令教学为什么就不能算「虐待」呢？人们会说我们还是给了他一定的自由、给了它充足的食物和安全的环境，至少比在野外流浪好吧！我们不懂动物的语言交流方式，暂时无法得到这些动物的真实想法。所谓的一切说辞都不过是人给的定义罢和自我解释罢了。 现代汉语词典里，「虐待」一词指的是： 用残暴的手段对待。 当然也是人定义的。 每一个人都有对事物的行为都有自己的理解 他认为将动物绝育是比失去生命更罪大恶极的，即使绝育有他万千的好处和理由； 他认为猫狗不如人类，没有道德荣辱价值观，有个舒适安全的生存环境便是上天对它最好的馈赠； 他认为用残忍手段虐杀动物是非常具有道德问题的，对生命没有敬畏之心，缺少共情能力； 他认为养宠物和虐杀完全是两种态度，一种出发点是为了宠物好（当然也有自己的私欲），另一种是单纯的恶（完完全全是为了满足自己的私欲）； 他认为网络上也有不少利用各种手段（电击、火烤）折磨蟑螂水蛭蚂蚁的，它们也是生命，它们不过也是用一种方式活着而已。它们并不会得到人类的同情一是相貌问题二是因为部分害虫与人类利益冲突，对人类有害。 各执一词，谁都说服不了谁。因为谁都可以给「虐待」再附加上定义。 范源庆此次的虐猫事件来说，首先在法律上，目前还未成立虐待动物罪，学生本身通过拍摄相关的视频牟利是否存在问题不予置评。 人与人之间出现虐待、伤害事件不会像人与动物一样难以定性，法治社会里法律是服务于人本身的，为人的行为而制定，以人为本，维持一个社会的基本稳定。在人类统治陆地上的这段时间里，永远是人凌驾于万物之上的，吃人杀人犯法吗？除了正当防卫肯定犯法。我们想好好活着都得遵守这个规则。 想到一个搞笑gif图形容不会做饭：一个人将活鱼直接丢入烧锅，鱼下锅后随即发疯似的乱跳，油飞溅了整个厨房。本身是一个搞笑的gif图，但是我看到的第一感觉是残忍。以前有个传闻（大概率编造，网络上鲜有相关资料），在德国爱吃鱼的家庭常被一种药丸，在杀鱼之前往往会先让鱼服下这种药丸，待鱼昏迷之后在进行宰杀。每个人都有着自己的三观，带着自己的思维和理解在做人做事。 人类需要有一个上帝吗…","categories":[{"name":"点滴","slug":"点滴","permalink":"https://matthew-han.github.io/categories/%E7%82%B9%E6%BB%B4/"}],"tags":[{"name":"虐猫","slug":"虐猫","permalink":"https://matthew-han.github.io/tags/%E8%99%90%E7%8C%AB/"},{"name":"虐待","slug":"虐待","permalink":"https://matthew-han.github.io/tags/%E8%99%90%E5%BE%85/"}]},{"title":"Shiro与分布式Session与Redis的那些坑","slug":"Shiro与分布式Session与Redis的那些坑","date":"2020-03-27T06:47:17.000Z","updated":"2025-09-03T02:52:50.974Z","comments":true,"path":"post/cc8d9450-6ff6-11ea-a44c-898e22d16291/","permalink":"https://matthew-han.github.io/post/cc8d9450-6ff6-11ea-a44c-898e22d16291/","excerpt":"","text":"需要知道的点Shiro的Session支持企业级的特性，例如分布式缓存。我们在Spring Data Redis + Shiro的方案中需要注意下以下几点： 无论Redis服务是单机还是集群模式，都需要注意Session对象的序列化与反序列化的问题； Shiro的Session：定义好的一个接口；Simple Session：一个它的简单实现，我们想要实现持久化就需要对它进行维护； EnterpriseCacheSessionDAO：Session对象的增删改查，可以对Session对象进行下一步的定制化操作（个人理解），所以我们可以通过覆写它的方法来达到我们想要的持久化效果。以下4个方法是对Session的持久化处理： doCreate doUpdate doReadSession doDelete SessionManager：对EnterpriseCacheSessionDAO创建好的Session对象交给SessionManager。它管理着Session的创建、操作以及清除等；DefaultSessionManager：具体实现，默认的web应用Session管理器，主要是涉及到Session和Cookies，涉及到的行为：添加、删除SessionId到Cookie、读取Cookie获得SessionId； SessionId：得到Session的关键 securityManager：这是Shiro框架的核心组件，可以把他看做是一个Shiro框架的全局管理组件，用于调度各种Shiro框架的服务。我们需要将自定义的sessionManager交给它 Session持久化上面写到如果想定制化我们的持久化效果，就必须覆写它的方法，所以我们需要新创建一个类SessionRedisDao来继承EnterpriseCacheSessionDAO类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111@Componentpublic class SessionRedisDao extends EnterpriseCacheSessionDAO &#123; /** * 注入的是byteRedisTemplate，只用于byte[]类型的序列化存储在redis中 */ private final RedisTemplate&lt;String, byte[]&gt; redisTemplate; public SessionRedisDao(@Qualifier(&quot;byteRedisTemplate&quot;) RedisTemplate&lt;String, byte[]&gt; redisTemplate) &#123; this.redisTemplate = redisTemplate; &#125; /** * 创建session，保存到数据库 * @param session * @return */ @Override protected Serializable doCreate(Session session) &#123; Serializable sessionId = super.doCreate(session); System.out.println(&quot;===============【 &quot; + sessionId + &quot; 】 创建了session！================&quot;); BoundValueOperations&lt;String, byte[]&gt; boundValueOperations = redisTemplate.boundValueOps(SHIRO_SESSION + sessionId.toString()); boundValueOperations.set(sessionToByte(session), 240, TimeUnit.MINUTES); return sessionId; &#125; /** * 获取session * @param sessionId * @return */ @Override protected Session doReadSession(Serializable sessionId) &#123; // 先从缓存中获取session，如果没有再去数据库中获取 Session session = super.doReadSession(sessionId); //System.out.println(&quot;===============【 &quot; + sessionId + &quot; 】 获取了session！================&quot;); if(session == null)&#123; BoundValueOperations&lt;String, byte[]&gt; boundValueOperations = redisTemplate.boundValueOps(SHIRO_SESSION + sessionId.toString()); byte[] bytes = (boundValueOperations.get()); if(bytes != null &amp;&amp; bytes.length &gt; 0)&#123; session = byteToSession(bytes); &#125; &#125; return session; &#125; /** * 更新session的最后一次访问时间 * @param session */ @Override protected void doUpdate(Session session) &#123; super.doUpdate(session); System.out.println(&quot;===============【 &quot; + session.getId() + &quot; 】 更新了session！================&quot;); BoundValueOperations&lt;String, byte[]&gt; boundValueOperations = redisTemplate.boundValueOps(SHIRO_SESSION + session.getId().toString()); boundValueOperations.set(sessionToByte(session), 240, TimeUnit.MINUTES); &#125; /** * 删除session * @param session */ @Override protected void doDelete(Session session) &#123; System.out.println(&quot;===============【 &quot; + session.getId() + &quot; 】 删除了session！================&quot;); super.doDelete(session); redisTemplate.delete(SHIRO_SESSION + session.getId().toString()); &#125; /** * 把session对象转化为byte保存到redis中 * @param session * @return */ public byte[] sessionToByte(Session session)&#123; ByteArrayOutputStream bo = new ByteArrayOutputStream(); byte[] bytes = null; try &#123; ObjectOutputStream oo = new ObjectOutputStream(bo); oo.writeObject(session); bytes = bo.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return bytes; &#125; /** * 把byte还原为session * @param bytes * @return */ public Session byteToSession(byte[] bytes)&#123; ByteArrayInputStream bi = new ByteArrayInputStream(bytes); ObjectInputStream in; SimpleSession session = null; try &#123; in = new ObjectInputStream(bi); session = (SimpleSession) in.readObject(); &#125; catch (ClassNotFoundException | IOException e) &#123; e.printStackTrace(); &#125; return session; &#125;&#125; 好像看起来和网上的其他技术文章的实现差不多，但是还有差啦（迷之台湾腔？） 首先是关于RedisTemplate客户端的注入使用： 1234private final RedisTemplate&lt;String, byte[]&gt; redisTemplate;public SessionRedisDao(@Qualifier(&quot;byteRedisTemplate&quot;) RedisTemplate&lt;String, byte[]&gt; redisTemplate) &#123; this.redisTemplate = redisTemplate;&#125; 在这里看到key和value的类型&lt;String, byte[]&gt;，不是常规的&lt;String, Object&gt;，因为我在以下序列化工具中以json字符串的形式存储在Redis： FastJsonRedisSerializer GenericJackson2JsonRedisSerializer Jackson2JsonRedisSerializer 发现在执行doUpdate方法后，Redis当中会增加一些Simple Session没有字段，比如&quot;valid&quot;:true等等，所以在反序列化获取Session对象的过程中会抛出如下异常： 1&quot;Could not read JSON: Cannot construct instance of`org.apache.shiro.web.util.SavedRequest` (no Creators, like default construct, exist): cannot deserialize from Object value (no delegate- or property-based Creator)↵ at [Source: (byte[])&quot;[&quot;org.apache.shiro.session.mgt.SimpleSession&quot; 我突然就想到了《码出高效》里面，有说过POJO类不要使用isXxx作为变量的形式 当然这里也没发现存在 isXxx的成员变量，只看到了 isValid()方法，以及 isStoped()方法也没有对应的 stoped 成员属性。可能是在反序列化的过程中，通过Redis里的键值对发现，SimpleSession并没有这个 boolean 类型的 valid变量而导致错误。不知道是不是算Shiro的Simple Session一个Bug。 解决手段目前个人找到的解决的方法是使用byte[]字节流存储，且用默认的JDK序列化工具JdkSerializationRedisSerializer。 Redis配置序列化工具因为可能在代码其他处已经使用了其他序列化工具操作Redis了，所以这里建议重新写一个Bean的方法专门用于Shiro安全框架的Session操作： 12345678910111213141516171819202122@Bean(name = &quot;byteRedisTemplate&quot;)public RedisTemplate&lt;String, byte[]&gt; byteRedisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; RedisTemplate&lt;String, byte[]&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory); JdkSerializationRedisSerializer jdkSerializationRedisSerializer = new JdkSerializationRedisSerializer(); // 全局开启AutoType，不建议使用 // ParserConfig.getGlobalInstance().setAutoTypeSupport(true); // 建议使用这种方式，小范围指定白名单 ParserConfig.getGlobalInstance().addAccept(&quot;com.zrtg.&quot;); // 设置值（value）的序列化采用jdkSerializationRedisSerializer。 redisTemplate.setValueSerializer(jdkSerializationRedisSerializer); redisTemplate.setHashValueSerializer(jdkSerializationRedisSerializer); // 设置键（key）的序列化采用StringRedisSerializer。 redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setHashKeySerializer(new StringRedisSerializer()); redisTemplate.afterPropertiesSet(); log.info(&quot;MatthewHan: [ byteRedisTemplate启动，鸡你实在是太美! ] &quot;); return redisTemplate;&#125; 然后在需要注入的地方，加入@Qualifier注解即可，像这样：@Qualifier(&quot;byteRedisTemplate&quot;) RedisTemplate&lt;String, byte[]&gt; redisTemplate。 并入管理1234567891011121314151617181920212223242526272829303132@Beanpublic DefaultWebSessionManager sessionManager(SessionRedisDao sessionRedisDao) &#123; DefaultWebSessionManager sessionManager = new DefaultWebSessionManager(); sessionManager.setSessionIdCookie(remeberMeCookie()); sessionManager.setGlobalSessionTimeout(14400000L); sessionManager.setDeleteInvalidSessions(true); // 将写好的缓存sessionDao注入 sessionManager.setSessionDAO(sessionRedisDao); sessionManager.setSessionValidationSchedulerEnabled(true); return sessionManager;&#125;/** * 注入 securityManager * 将写好的缓存sessionDao注入 * @param sessionRedisDao * @param customRealmConfig * @return */@Beanpublic SecurityManager securityManager(SessionRedisDao sessionRedisDao, CustomRealmConfig customRealmConfig) &#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); // 设置realm securityManager.setRealm(customRealmConfig); // 注入Cookie记住我管理器 securityManager.setRememberMeManager(null); securityManager.setSessionManager(sessionManager(sessionRedisDao)); return securityManager;&#125; 这里注意rememberMe的Cookies管理，以及sessionManager.setGlobalSessionTimeout(14400000L);和Redis设置的过期时间保持一致即可。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://matthew-han.github.io/tags/Redis/"},{"name":"Shiro","slug":"Shiro","permalink":"https://matthew-han.github.io/tags/Shiro/"},{"name":"Session","slug":"Session","permalink":"https://matthew-han.github.io/tags/Session/"},{"name":"分布式","slug":"分布式","permalink":"https://matthew-han.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"序列化","slug":"序列化","permalink":"https://matthew-han.github.io/tags/%E5%BA%8F%E5%88%97%E5%8C%96/"}]},{"title":"《码出高效》系列笔记（四）：元素的比较","slug":"《码出高效》系列笔记（四）：元素的比较","date":"2020-03-19T06:59:36.000Z","updated":"2025-09-03T02:52:50.976Z","comments":true,"path":"post/31c8add0-69af-11ea-ad58-59a2dd622848/","permalink":"https://matthew-han.github.io/post/31c8add0-69af-11ea-ad58-59a2dd622848/","excerpt":"","text":"良好的编码风格和完善统一的规约是最高效的方式。 前言本篇汲取了本书中较为精华的知识要点和实践经验加上读者整理，作为本系列里的第四篇章第三节：数据结构与集合的元素的比较篇。 本系列目录： 《码出高效》系列笔记（一）：面向对象中的类 《码出高效》系列笔记（一）：面向对象中的方法 《码出高效》系列笔记（一）：面向对象中的其他知识点 《码出高效》系列笔记（二）：代码风格 《码出高效》系列笔记（三）：异常与日志 《码出高效》系列笔记（四）：数据结构与集合的框架 《码出高效》系列笔记（四）：数据结构与集合的数组和泛型 《码出高效》系列笔记（四）：元素的比较 走进JVM之内部布局 走进JVM之字节码与类加载 走进JVM之GC 元素的比较ComparableJava中两个对象相比较的方法通常用在元素排序中，常用的两个几口分别是Comparable和Comparator，前者是自己和自己比；后者是第三方比较器，类似于平台性质的比较器。 我们熟知的Integer和String实现的就是Comparable的自然排序。 假设在一个搜索列表中进行排序时，先根据相关度排序，然后再根据浏览数排序，那么可以利用Comparable这样写： 12345678910111213141516171819202122232425262728293031public class SearchResult implements Comparable&lt;EzCodingTest&gt;&#123; // 相关度 int relativeRatio; long count; int recentOrders; public SearchResult(int relativeRatio, long count) &#123; this.relativeRatio = relativeRatio; this.count = count; &#125; @Override public int compareTo(EzCodingTest o) &#123; if (this.relativeRatio != o.relativeRatio) &#123; return this.relativeRatio &gt; o.relativeRatio ? 1 : -1; &#125; if (this.count != o.count) &#123; return this.count &gt; o.count ? 1 : -1; &#125; return 0; &#125; public static void main(String[] args) &#123; EzCodingTest result1 = new EzCodingTest(10, 100); EzCodingTest result2 = new EzCodingTest(20, 1); System.out.println(result1.compareTo(result2)); &#125;&#125; 在实现Comparable时，我们发现了需要加上泛型限定，public class EzCodingTest implements Comparable&lt;EzCodingTest&gt;，这样的话，可以在编译阶段就判断是否符合该定义的对象。当排序方法不符合当前的业务要求，重写该比较方法compareTo，因为开闭原则的关系，已交付的类进行修改是有很大风险的。所以我们需要在外部定义比较器：Comparator。 Comparator假如你写完上面的代码准备下班去食堂吃阿姨做的🦆鸭头时，产品狗过来和宁说：现在搜索的权重改辣！现在最近的订单数的权重最高，抓紧改吧，加班搞完半夜上线~！ 这时候你应该怎么做呢，继续修改刚才的代码？不，正确的做法是： 对产品狗使用神の救♂济。 vans之后我们害是得van成任务，所以俺们可以搞个外部比较器SearchResultComparator剥离出来。 123456789101112131415161718192021222324252627282930313233343536public class SearchResultComparator implements Comparator&lt;EzCodingTest&gt;&#123; // 相关度 int relativeRatio; long count; int recentOrders; public SearchResultComparator(int relativeRatio, long count) &#123; this.relativeRatio = relativeRatio; this.count = count; &#125; @Override public int compare(EzCodingTest o1, EzCodingTest o2) &#123; if (o1.recentOrders != o2.recentOrders) &#123; return o1.recentOrders &gt; o2.recentOrders ? 1 : -1; &#125; if (o1.relativeRatio != o2.relativeRatio) &#123; return o1.relativeRatio &gt; o2.relativeRatio ? 1 : -1; &#125; if (o1.count != o2.count) &#123; return o1.count &gt; o2.count ? 1 : -1; &#125; return 0; &#125; public static void main(String[] args) &#123; EzCodingTest result1 = new EzCodingTest(70, 100); EzCodingTest result2 = new EzCodingTest(20, 1); System.out.println(result1.compare(result1, result2)); &#125;&#125; 约定俗成，不管是Comparable还是Comparator，小于的情况返回-1，等于的情况返回0，大于的情况返回1。 排序既然是比较，那么比较完了之后肯定有个排序工作，例如二维数组、一维数组的倒序、String类型的数组在Arrays.sort()中常常使用。 12345678910public static &lt;T&gt; void sort(T[] a, Comparator&lt;? super T&gt; c) &#123; if (c == null) &#123; sort(a); &#125; else &#123; if (LegacyMergeSort.userRequested) legacyMergeSort(a, c); else TimSort.sort(a, 0, a.length, c, null, 0, 0); &#125;&#125; 上面的代码是sort方法，比较器参数的&lt;? super T&gt;为下限通配。但是基本类型的数组不能用包装类型的比较器，例如以下想实现数组的倒序排序是不行的。 1234567int[] tmp = new int[]&#123;1, 2, 3, 4, 5, 6&#125;;Arrays.sort(tmp, new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return Integer.compare(o2, o1); &#125;&#125;); TimSortsort()方法中用的TimSort算法是一种混合算法，归并和插入优化过的缝合怪。JDK7之后就取代了原来的归并排序。 部分排序的数组，时间复杂度最优为 $O(n)$ 随机排序的数组，时间复杂度为 $O(nlogn)$ hashCode和equalshashCode和equals用来标识对象，两个方法协同工作可用来判断两个对象是否相等。 利用Object.hashCode()生成哈希值，分散在各地； 既然用哈希算法，就会有哈希冲突的情况，所以需要调用equals方法进行一次值的比较。 Object类定义中对hashCode和equals的要求如下 如果两个对象的equals的结果是相同的，那么这两个对象hashCode的返回结果也必须是相同的； 任何时候覆写equals，都必须同时覆写hashCode。 很经典的HashMap，内部数据结构是数组 + 链表（当链表长度大于8时，会变成红黑树）。当调用get方法时，会先判断hashCode的值，如果没有，直接return null，如果有的话，则执行equals方法，去比较值再返回。 因为哈希冲突的缘故，可能存在值不相同但是hashCode相同的情况，这时候就需要红黑树出场了。 假如有一个Set&lt;Object&gt;集合，集合的类型是一个拥有N多属性的类，但是我们仅仅将这些对象添加到HashSet中，并不能实现「去重」的效果。我们必须要覆写这个类「相同」的代码逻辑（hashCode和equals方法）。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"笔记","slug":"笔记","permalink":"https://matthew-han.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Easy Coding","slug":"Easy-Coding","permalink":"https://matthew-han.github.io/tags/Easy-Coding/"},{"name":"集合","slug":"集合","permalink":"https://matthew-han.github.io/tags/%E9%9B%86%E5%90%88/"},{"name":"元素","slug":"元素","permalink":"https://matthew-han.github.io/tags/%E5%85%83%E7%B4%A0/"}]},{"title":"《码出高效》系列笔记（四）：数据结构与集合的数组和泛型","slug":"《码出高效》系列笔记（四）：数据结构与集合的数组和泛型","date":"2020-03-13T01:42:03.000Z","updated":"2025-09-03T02:52:50.976Z","comments":true,"path":"post/d6e37130-64cb-11ea-a19c-b3eaacf8ea9d/","permalink":"https://matthew-han.github.io/post/d6e37130-64cb-11ea-a19c-b3eaacf8ea9d/","excerpt":"","text":"良好的编码风格和完善统一的规约是最高效的方式。 前言本篇汲取了本书中较为精华的知识要点和实践经验加上读者整理，作为本系列里的第四篇章第二节：数据结构与集合的数组和泛型篇。 本系列目录： 《码出高效》系列笔记（一）：面向对象中的类 《码出高效》系列笔记（一）：面向对象中的方法 《码出高效》系列笔记（一）：面向对象中的其他知识点 《码出高效》系列笔记（二）：代码风格 《码出高效》系列笔记（三）：异常与日志 《码出高效》系列笔记（四）：数据结构与集合的框架 《码出高效》系列笔记（四）：数据结构与集合的数组和泛型 《码出高效》系列笔记（四）：元素的比较 走进JVM之内部布局 走进JVM之字节码与类加载 走进JVM之GC 数组与集合数组是一种顺序表，可以使用索引下标进行快速定位并获取指定位置的元素。 为什么下标从0开始？ 因为这样需要计算偏移量需要从当前下标减1的操作，加减法运算对CPU是一种双数运算，在数组下标使用频率很高的场景下，该运算方式十分耗时。在Java的体系中，数组一旦分配内存后无法扩容。 1234String[] args1 = &#123;&quot;a&quot;, &quot;b&quot;&#125;;String[] args2 = new String[2];args2[0] = &quot;a&quot;;args2[1] = &quot;b&quot;; 以上代码一般是数组的两种初始化方式，第一种是静态初始化，第二种是动态初始化。数组的容量大小随着数组对象的创建就固定了。 数组的遍历优先推荐JDK5引进的foreach方式，即for(e : obj);JDK8以上可以使用stream操作 12Arrays.stream(args1).forEach(str -&gt; System.out.println(str));Arrays.stream(args1).forEach(System.out::println); 数组转集合将数组转集合后，不能使用集合的某些方法，以Arrays.asList()为例，不能使用其修改集合add、remove、clear方法，但是可以使用set方法。 12345678String[] args1 = &#123;&quot;a&quot;, &quot;b&quot;&#125;;List&lt;String&gt; asList = Arrays.asList(args1);asList.set(1, &quot;c&quot;);System.out.println(asList);asList.add(&quot;c&quot;);asList.remove(0);asList.clear();System.out.println(asList); 后面会输出UnsupportedOperationException异常。 Arrays.asList()体现的是适配器模式，其实是Arrays的一个名为ArrayList的内部类（阉割版），继承自AbstractList类，实现了set和get方法。但是其他部分方法未实现所以会抛出该父类AbstractList的异常。 123456789String[] args1 = &#123;&quot;a&quot;, &quot;b&quot;&#125;;List&lt;String&gt; e1 = Arrays.asList(args1);List&lt;String&gt; e2 = new ArrayList&lt;&gt;(2);e2.add(&quot;a&quot;);e2.add(&quot;b&quot;);// 第一处System.out.println(e1.getClass().getName());// 第二处System.out.println(e2.getClass().getName()); 实际控制台打印情况： java.util.Arrays$ArrayList java.util.ArrayList 数组转集合在需要添加元素的情况下，利用java.util.ArrayList创建一个新集合。 12String[] args = &#123;&quot;a&quot;, &quot;b&quot;&#125;;List&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(args)); 集合转数组集合转数组更加的可控。 1234567891011List&lt;String&gt; e1 = new ArrayList&lt;&gt;(2);e1.add(&quot;c&quot;);e1.add(&quot;d&quot;);String[] args = new String[1];String[] args2 = new String[2];e1.toArray(args);// 第一处System.out.println(Arrays.asList(args));e1.toArray(args2);// 第二处System.out.println(Arrays.asList(args2)); 实际控制台打印情况： [null] [c, d] 不同的区别在于即将复制进去的数组容量是否足够，如果容量不等，则弃用该数组，另起炉灶。 集合与泛型泛型与集合的联合使用，可以把泛型的功能发挥到极致。 1234567891011121314151617181920212223List list1 = new ArrayList(3);list1.add(new Integer(666));list1.add(new Object());list1.add(&quot;666&quot;);List&lt;Object&gt; list2 = new ArrayList&lt;&gt;(3);list2.add(new Integer(666));list2.add(new Object());list2.add(&quot;666&quot;);List&lt;Integer&gt; list3 = new ArrayList&lt;&gt;(3);list3.add(new Integer(666));// 以下都是编译出错list3.add(new Object());list3.add(&quot;666&quot;);List&lt;?&gt; list4 = new ArrayList&lt;&gt;(3);list4.remove(0);list4.clear();// 以下都是编译出错list4.add(new Integer(666));list4.add(new Object());list4.add(&quot;666&quot;); List&lt;?&gt;是一个泛型，在没有赋值之前，表示它可以接收任何类型的集合赋值，赋值之后就不能随便往里面添加元素了，但可以remove和clear。 而List&lt;T&gt;最大的问题就是只能放置一种类型，如果要实现多种受泛型约束的类型，可以使用&lt;? extends T&gt;与&lt;? super T&gt;两种语法，但是两者的区别非常微妙。 &lt;? extends T&gt;是Get First，适用于生产集合元素为主的场景； &lt;? super T&gt;是Put First，适用于消费集合元素为主的场景。 &lt;? extends T&gt;可以赋值给任何T以及T子类的集合，上界为T。取出来的类型带有泛型限制，向上转型为T。null可以表示任何类型，所以除了null外，任何元素都不得添加进&lt;? extends T&gt;集合内。 &lt;? super T&gt;可以赋值给任何T以及T的父类集合，下界为T。在生活中，投票选举类似&lt;? super T&gt;的操作。选举代表时，你只能往里投票，取数据时，根本不知道是谁的票，相遇泛型丢失。 extends的场景是put功能受限，而super的场景是get功能受限。 extends与super的差异假设有一个斗鱼TV平台，拥有一个DOTA2板块，其下有一个恶心人的D能儿主播：谢彬DD。 那我们从代码里可以这样写： 12345678910111213141516171819202122@Testpublic void main() &#123; List&lt;DouYu&gt; douYu = new ArrayList&lt;&gt;(); List&lt;DotA2&gt; dotA2 = new ArrayList&lt;&gt;(); List&lt;DD&gt; dd = new ArrayList&lt;&gt;(); douYu.add(new DouYu()); dotA2.add(new DotA2()); dd.add(new DD()); // 第一处，编译出错 List&lt;? extends DotA2&gt; extendsDotA2FromDouYu = douYu; List&lt;? super DotA2&gt; superDotA2FromDouYu = douYu; List&lt;? extends DotA2&gt; extendsDotA2FromDotA2 = dotA2; List&lt;? super DotA2&gt; superDotA2FromDotA2 = dotA2; List&lt;? extends DotA2&gt; extendsDotA2FromDD = dd; // 第二处，编译出错 List&lt;? super DotA2&gt; superDotA2FromDD = dd;&#125; 三个类的继承关系说明DD &lt; DotA2 &lt; DouYu &lt; Object。 第一处编译出错，因为只能赋值给T以及T的子类，上界是DotA2类。DouYu类明显不符合extendsDotA2类的情况。不能把douYu对象赋值给&lt;? extends DotA2&gt;，因为List&lt;DouYu&gt;不只只有DotA2板块，还有吃♂鸡、颜♂值区、舞♂蹈区这些板块。 第二处编译出错，因为只能赋值给T以及T的父类，DD类属于DotA2的子类，下界只能DotA2类的对象。 123456789// 以下&lt;? extends DotA2&gt;类型的对象无法进行add操作，编译出错extendsDotA2FromDotA2.add(new DD());extendsDotA2FromDotA2.add(new DotA2());extendsDotA2FromDotA2.add(new DouYu());superDotA2FromDotA2.add(new DD());superDotA2FromDotA2.add(new DotA2());// 该处编译出错，无法添加superDotA2FromDotA2.add(new DouYu()); 除了null以外，任何元素都不能添加进&lt;? extends T&gt;集合内。&lt;? super T&gt;可以放，但是只能放进去自身以及子类。 123456Object obj1 = extendsDotA2FromDotA2.get(0);DotA2 obj2 = extendsDotA2FromDotA2.get(0);Object obj3 = extendsDotA2FromDD.get(0);// 该处编译出错，无法添加DD obj4 = extendsDotA2FromDD.get(0); 首先&lt;? super T&gt;可以进行Get操作返回元素，但是类型会丢失。&lt;? extends T&gt;可以返回带类型的元素，仅限自身及父类，子类会被擦除。 小总结对于一个笼子，只取不放，属于Get First，应采用&lt;? extends T&gt;；只放不取，属于Put First，应采用&lt;? super T&gt;。 2021.03.31 新阶段的新总结 以前对泛型的上下限老是会忘记，现在总结了一个例子： 在 Java 中Integer --继承--&gt; Number --实现--&gt; Serializable 例如这样一个方法： 123private static void func(List&lt;? extends Number&gt; producer, List&lt;? super Number&gt; consumer) &#123; &#125; 想成功调用这个方法的参数的类型可以是： 12345678private static void ex(List&lt;Number&gt; numbers) &#123; // Integer extends Number List&lt;Integer&gt; producer = new ArrayList&lt;&gt;(); // Serializable super Number List&lt;Serializable&gt; consumer = new ArrayList&lt;&gt;(); func(producer, consumer);&#125; 但是对集合的操作是相反的： 12345678910111213private static void lowerBoundedWildcardsDemo(List&lt;? extends Number&gt; producer, List&lt;? super Number&gt; consumer) &#123; // PECS stands for producer-extends, consumer-super. // 读取数据（生产者）使用 extends // 操作输出（消费者）使用 super Serializable p1 = 1L; Integer p2 = 1; // 这里不行，编译不通过 producer.add(p1); // 这里编译可以通过 consumer.add(p2);&#125;","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"数组","slug":"数组","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"笔记","slug":"笔记","permalink":"https://matthew-han.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Easy Coding","slug":"Easy-Coding","permalink":"https://matthew-han.github.io/tags/Easy-Coding/"},{"name":"集合","slug":"集合","permalink":"https://matthew-han.github.io/tags/%E9%9B%86%E5%90%88/"},{"name":"泛型","slug":"泛型","permalink":"https://matthew-han.github.io/tags/%E6%B3%9B%E5%9E%8B/"}]},{"title":"《码出高效》系列笔记（四）：数据结构与集合的框架篇","slug":"《码出高效》系列笔记（四）：数据结构与集合","date":"2020-03-10T01:32:30.000Z","updated":"2025-09-03T02:52:50.976Z","comments":true,"path":"post/025b9630-626f-11ea-8f75-554d885c423a/","permalink":"https://matthew-han.github.io/post/025b9630-626f-11ea-8f75-554d885c423a/","excerpt":"","text":"良好的编码风格和完善统一的规约是最高效的方式。 前言本篇汲取了本书中较为精华的知识要点和实践经验加上读者整理，作为本系列里的第四篇章第一节：数据结构与集合的框架篇。 本系列目录： 《码出高效》系列笔记（一）：面向对象中的类 《码出高效》系列笔记（一）：面向对象中的方法 《码出高效》系列笔记（一）：面向对象中的其他知识点 《码出高效》系列笔记（二）：代码风格 《码出高效》系列笔记（三）：异常与日志 《码出高效》系列笔记（四）：数据结构与集合的框架 《码出高效》系列笔记（四）：数据结构与集合的数组和泛型 《码出高效》系列笔记（四）：元素的比较 走进JVM之内部布局 走进JVM之字节码与类加载 走进JVM之GC 数据结构Java中的集合不同于数学概念，可以是有序的，也可以是重复的。而集合作为数据结构的载体，同时也作为程序的主要构成，是所有编程语言的基础。 数据结构的分类： 线性结构：0至1个直接前继和直接后继。当线性非空时，有唯一的首元素和尾元素，除两者外，所有的元素都有唯一的直接前继和直接后继。该类结构一般有：顺序表、链表、栈、队列等，其中栈、队列是访问受限的结构。 树结构：0至1个直接前继和0至n个直接后继（n大于等于2）。具有层次、稳定的特性，类似大自然的树木。 图结构：0至n个直接前继和直接后继（n大于等于2）。该类结构一般有：简单图、多重图、有向图、无向图等。 哈希结构：没有直接前继和直接后继。该结构是通过某种特定的哈希函数将索引与存储的值关联起来，是一种查找效率非常非常高的数据结构。 复杂度： 数据结构的复杂度分为时间复杂度和空间复杂度两种，因为目前存储设备的技术进步，时间复杂度成为了重点考量的因素。 时间复杂度是一种衡量计算性能的指标。通常用大写的O和一个函数描述，比如O(n3)表示程序执行时间随输入规模呈现三次方倍的增长，这是比较差的算法实现。 从好到坏的常用算法复杂度排序如下：常数级 O(1)、对数级 O(logn)、线性级 O(n)、线性对数级 O(nlogn)、平方级 O(n2)、立方级 O(n3)、指数级 O(2n)。 集合框架Java中的集合是用于存储对象的工具类容器，实现了我们上述所说的这些的数据结构，提供了一系列的公开方法用于增删改查以及遍历数据，让宁⑧用自己写轮子辣！ 这里本来应该有一张Java结合框架图的，不过都应该烂熟于心了⑧。除了Map没有直接继承collection接口，Queue、List、Set均是直接继承collection接口。 List集合List集合是线性数据结构的主要实现，所以集合的元素通常明确上一个和下一个元素，也存在第一个和最后一个元素。 ArrayList是容量可变的非线程安全集合。内部使用数组进行存储，扩容时会创建更大的数组空间，然后再把原来的数据复制到新的数组中。该集合支持对元素的随机访问，插入与删除速度通常很慢，因为涉及到移动元素（数组）。 LinkedList的本质是双向链表。与ArrayList相比，插入和删除的速度更快，但是随机访问的速度很慢。LinkedList包含了3个重要的成员：size、first、last。size是双向链表中节点的个数。first和last分别指向第一个和最后一个节点的应用。 Queue集合先进先出，一种特殊的线性表，只允许表在一端进行获取操作，在另一端进行插入操作。当不存在元素时，则为空队列。自从BlockingQueue（阻塞队列）问世以来，队列的地位得到极大地提升，在各种高并发编程的场景，经常被作为Buffer（数据缓冲区）使用。 Map集合Map集合是以Key-Value键值对作为存储元素实现的哈希结构，Key安某种哈希函数计算后是唯一的，Value是可以重复的。 可以使用keySet()方法查看所有的Key； 使用values()方法查看所有的Value； 使用entrySet()方法查看所有的键值对。 Hashtable因为性能瓶颈原因已被淘汰，如今广泛使用HashMap，但是是线程不安全的，底层也就是数组 + 链表。ConcurrentHashMap是线程是安全的，在JDK8中进行了锁的大幅度优化，体现了8错的性能。 在多线程并发的场景中，优先推荐使用ConcurrentHashMap，而不是HashMap。 TreeMap是Key有序的Map类集合，树结构保证有序，Key⑧能为null。 LinkedHashMap底层是链表结构，较与HashMap可以保元素的有序。 Set集合Set是不允许出现重复元素的集合类型。Set体系最常用的是HashSet、TreeSet和LinkedHashSet三个集合类。 HashSet与HashMap较为类似，只是Value固定为一个静态对象，使用Key保证集合元素的唯一性，但它不保证集合元素的顺序。 TreeSet也是如此，与TreeMap类似，同样底层是树结构，保证有序，元素不能为null。 LinkedHashSet继承自HashSet，具有HashSet的优点，使用链表维护了元素插入顺序。 集合初始化集合初始化通常进行分配容量、设置特定参数等相关工作。 该书中特别强调例如ArrayList在初始化的过程中，需要显式地设定集合容量大小。 ArrayList部分源码解析 本书分析的底层源码基本来源于较新的JDK11，而在我本地的源码是JDK8，下面分析的是本地的JDK8源码。 1234567891011121314151617181920212223242526/** * Increases the capacity to ensure that it can hold at least the * number of elements specified by the minimum capacity argument. * * @param minCapacity the desired minimum capacity */private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // ① if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // ② if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; 上述代码是JDK8中的源码，扩容在grow()方法里完成。而在JDK11中，扩容的具体实现则是由newCapacity()方法实现。 首先我们明确几个概念： oldCapacity：当前容量，由于要扩容了所以是老的容量数值； newCapacity：扩容后的容量大小； minCapacity：扩容的必须满足最小的要求！源码是size + 1，也就是当前的容量 + 1。 什么时候扩容？ JDK8的源码部分没贴上来，调用的方法太多了占内容空间。如果原始容量为10，当第11个元素即将调用add()方法时会启动grow()方法启动扩容机制，JDK11同理。 默认的容量大小是什么？ 如果没有显式的初始化容量大小，那么在最开始，容量大小其实是0而不是默认的10哦。当显式的设定了容量大小，那么容量大小会赋设定的值。只有当调用add()方法时才会启动扩容，变成默认DEFAULT_CAPACITY = 10，大小为10。所以不显式的初始化容量大小，调用add()方法的话时必定会扩容一次的。 123456List&lt;String&gt; list = new ArrayList&lt;&gt;();Class&lt;?&gt; listClazz = list.getClass();Field elementData = listClazz.getDeclaredField(&quot;elementData&quot;);elementData.setAccessible(true);Object[] objects1 = (Object[])elementData.get(list);System.out.println(&quot;不显式的初始化，容量大小为：&quot; + objects1.length); 上述代码输出不显式的初始化，容量大小为：0 1234// add一个元素list.add(&quot;回家做80个俯卧撑！&quot;);Object[] objects2 = (Object[])elementData.get(list);System.out.println(&quot;添加一个元素，现在容量大小为：&quot; + objects2.length); 接着添加一个元素，运行输出添加一个元素，现在容量大小为：10 123456List&lt;String&gt; list2 = new ArrayList&lt;&gt;(666);Class&lt;?&gt; newListClazz = list2.getClass();Field elementData2 = newListClazz.getDeclaredField(&quot;elementData&quot;);elementData2.setAccessible(true);Object[] objects3 = (Object[])elementData.get(list2);System.out.println(&quot;显式初始化容量大小为666，容量大小为：&quot; + objects3.length); 显式初始化容量大小为666，运行输出显式初始化容量大小为666，容量大小为：666 如何扩容？ JDK8之前的扩容算法与JDK8有所不同，源码中上述方法里，int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);扩容后的容量大小算法是通过右移一位再加上老容量大小得到。 位移运算：JDK8中采用了（有符号）位运算符计算，位移的过程中采用补码的形式。假设原始容量为13，二进制数是1101，其中反码也是1101，整数的反码、补码都是本身。补码右移一位这是110，得到十进制为6，所以新的容量大小为6 + 13 &#x3D; 19。JDK7之前的公式则是oldCapacity * 1.5 + 1； ①：如果新的容量大小比最小要求要小的话，则按照最小要求设定（size + 1）； ②：如果新的容量大小比MAX_ARRAY_SIZE还大的话，其中该变量的大小为Integer.MAX_VALUE - 8也就是231-1再减8。在走hugeCapacity(int minCapacity)方法判断最后设定一个容量大小或者OOM了。 之所以本手册中明确强调需要显式的初始化容量大小，是因为假设有1000个元素需要放置在ArrayList中，则需要被动扩容13次才可以完成，在这过程中数组不断地复制原有的数据再到新的数组中，若能够提前给定一个合适的容量大小，就是性能的提升，也避免了一些OOM的风险。OS：这过程更像是调优，实际开发中很难对每个ArrayList清晰的定义和认识吧，属于经验学的范畴。 嗯？！感觉关于ArrayList的可以单独出一篇啊。 HashMap部分源码解析 本书分析的底层源码基本来源于较新的JDK11，而在我本地的源码是JDK8，下面分析的是本地的JDK8源码。 12345678910111213141516171819202122232425/** * The default initial capacity - MUST be a power of two. */static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16/** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. */static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;/** * The load factor used when none specified in constructor. */static final float DEFAULT_LOAD_FACTOR = 0.75f;/* ---------------- Fields -------------- *//** * The table, initialized on first use, and resized as * necessary. When allocated, length is always a power of two. * (We also tolerate length zero in some operations to allow * bootstrapping mechanics that are currently not needed.) */transient Node&lt;K,V&gt;[] table; DEFAULT_INITIAL_CAPACITY：默认初始容量1 &lt;&lt; 4，aka 16，必须是2n幂，注解里很直白的写着，所以你即使在初始化的过程这样写new HashMap&lt;&gt;(3);，实际上也会被改成22，比3大且最近的一个2的幂次方； MAXIMUM_CAPACITY：最大容量大小，默认1 &lt;&lt; 30，相当于230； DEFAULT_LOAD_FACTOR：负载因子，也叫填充比例，默认0.75，可在初始化过程中自定一个float类型的数值。 table： HashMap和ArrayList一样，容量不是在new的时候分配，而是在第一次put的时候。 put、putVal()、reszie()方法有些晦涩复杂就不贴上来了。很多细节，👴属实有点看不明白。这里有个概念threshold作为临界值就是loadfactory（负载因子）和capacity（容量）的乘积。也就是说默认情况下，当HashMap中元素个数达到了容量的3&#x2F;4的时候就会进行自动扩容。 为什么负载因子是0.75？ JDK源码里这样写，一定有它的道理，这里不太想去探究。查阅网上的资料，和哈希冲突有很大关系，以及一些数学计算、log2、对数之类的有一定关系，反正一般不要去自己去设定就vans了。 什么时候扩容？ 和ArrayList一样，到了某个临界值才会被动扩容，而且扩容的过程中会重新计算所有元素的哈希值。扩容的条件是达到了threshold这个参数，而它是capacity和loadfactory的乘积，所以我们可以通过代码来验证一下： Map&lt;String, String&gt; map = new HashMap&lt;&gt;(0); Class&lt;?&gt; mapClazz = map.getClass(); Method capacity = mapClazz.getDeclaredMethod(&quot;capacity&quot;); capacity.setAccessible(true); System.out.println(&quot;容量大小为：&quot; + capacity.invoke(map)); 123456- 输出`容量大小为：1`，因为是2&lt;sup&gt;0&lt;/sup&gt;- ```java map.put(&quot;MatthewHan&quot;, &quot;developer&quot;); System.out.println(&quot;添加一个元素后，容量大小为：&quot; + capacity.invoke(map)); put一个元素之后，查看capacity大的大小，输出添加一个元素后，容量大小为：2。为什么不是1呢，因为capacity和loadfactory的乘积是0.75 * 1 &lt; 1，满足扩容的条件。所以从20扩容成了21。当然你这样写new HashMap&lt;&gt;(0, 1f);输出的就是1了。 以前看到过的一道美团笔试题：如果一个HashMap要装载100个元素，那么初始化容量大小是设定最佳？ 最佳的大小，一定是满足不会多次扩容调用resize()方法的。所以就是一定要大于100 ÷ 0.75 = 133.333...，比该数大且最接近的2n的是28 &#x3D; 256。而27 &#x3D; 128看起来比100大，但是需要多扩容一次，全部重新计算哈希算法，属实⑧行。上面写了目前对时间性能的要求远远大于空间，用空间换时间。 或者可以这样new HashMap&lt;&gt;(128, 0.79f);但是一般不会改变负载因子的值，该方法实际表现未知。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"笔记","slug":"笔记","permalink":"https://matthew-han.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Easy Coding","slug":"Easy-Coding","permalink":"https://matthew-han.github.io/tags/Easy-Coding/"},{"name":"集合","slug":"集合","permalink":"https://matthew-han.github.io/tags/%E9%9B%86%E5%90%88/"},{"name":"HashMap","slug":"HashMap","permalink":"https://matthew-han.github.io/tags/HashMap/"},{"name":"ArrayList","slug":"ArrayList","permalink":"https://matthew-han.github.io/tags/ArrayList/"}]},{"title":"看不到的角落","slug":"看不到的角落","date":"2020-03-04T04:41:18.000Z","updated":"2025-09-03T02:52:50.979Z","comments":true,"path":"post/638b4b90-5dd2-11ea-aec4-43cfa9e11df6/","permalink":"https://matthew-han.github.io/post/638b4b90-5dd2-11ea-aec4-43cfa9e11df6/","excerpt":"","text":"# 1今天在看《睡前消息》第84期的结尾，有这么一个新闻事件： 河南邓州一贫困户女儿因无法正常在家上网课，吞下药物自杀。 初步了解这个事情，感到十分痛心和无奈。 在全国各地正如火如荼的进行网课教育并且还催生出一堆捧腹的段子的时候，我就时常会想到那些非常贫困的学生们。虽然是2020年了，几乎是人人都应该有一部智能手机的时候。他们可能没有条件做到能够全天按照学校安排的课程进行网络学习。更可能的情况是家里没有有线宽带，无法支撑他们持续数个月的高强度直播、视频学习。即使是数据流量对于一个贫困的家庭来说是一个不小的负担。全班一起上直播的网课，同时他们还要考虑很多关于同学之间的面子问题。 对于他们在心理上的关心和引导我觉得才是真真正正最需要关注的点。 古话教导我们「儿不嫌母丑，狗不嫌家贫。」正确的思想观念是应该从小灌输的，我们不可能剥离需要面对的现实而单独生长在只有超我的世界。未出社会的小孩子很难真正体会父母的辛酸与艰难，什么狗屁人生道理靠别人总结好送给你的永远记不住，而是根据自己的经验一点点悟出来的。如果平时父母没有定期和孩子交流双方的心里话的习惯，非常不好，尤其是一些外出打工的家庭。相对这类家庭来说父母对子女的关注度不够或者是十分片面的，仅仅只是学习和吃饱穿暖其实完全不够。在孩子成长初期应该多去深入交流，多了解孩子的内心世界，是缺少了什么渴望着什么还是有什么不满，双方都能无保留的表达出想法才可以让家长进一步判断这个阶段忽略了什么，孩子又陷入了什么走不开的死胡同。许多影响极度恶劣的重案的犯罪者，有相当多的比例都拥有了一个不太美好的童年，所以造成的一些比较奇怪性格品行往往会伴随其一生。 学校和老师也要担责，作为网课的具体实行者，不确定有没有事先调查好其下的学生的上网课的具备条件（估计学校也应该是让老师发表格之类的调查过，小女孩出于自尊心之类的传达了可以接受网课的形式教学），不确定任课教师有没有因为学生落下的进度问题而过分苛责。老师班主任对于学生的家庭条件和心理情况了解程度还是不够，可能还是需要人民教师再心细敏感一些吧（教师当然也不好当）。 出现这种问题一方面确实是我国区域发展不均衡以及经济差距过大，很多人忽略了那些人的生活条件真的比你想象的艰难。 # 2 河南邓州一女孩赌气服药，当地调查回应事件经过 最新的新闻显示调查组已经全面调查完毕，真实情况有新的进展，所幸女孩无大碍。调查提到女孩家中装有宽带，有两部手机，其中一部智能手机为其父于去年9月份购买，另一部可以拍照；姐弟三人轮流使用智能手机观看直播、录播上网课，用另一部拍照记录作业。李某某任课教师称，李某某网课此前一直正常进行。且女孩曾经因为家庭琐事也有过赌气服药的行为。说明小女孩现在阶段确实有点任性，和父母之间的关系不是很良好。家庭教育确实存在问题，希望有相关人员能够妥善处理这件事，不然对小女孩的心理又是一次打击。","categories":[{"name":"点滴","slug":"点滴","permalink":"https://matthew-han.github.io/categories/%E7%82%B9%E6%BB%B4/"}],"tags":[{"name":"百态","slug":"百态","permalink":"https://matthew-han.github.io/tags/%E7%99%BE%E6%80%81/"}]},{"title":"多线程之竞争与锁","slug":"多线程之竞争与锁","date":"2020-01-14T03:15:41.000Z","updated":"2025-09-03T02:52:50.978Z","comments":true,"path":"post/24ffa600-367c-11ea-ba8c-fb7580846ffa/","permalink":"https://matthew-han.github.io/post/24ffa600-367c-11ea-ba8c-fb7580846ffa/","excerpt":"","text":"示例123456789101112131415161718192021222324252627282930313233public class TestThread &#123; public static void main(String[] args) &#123; // new 出一个新的对象 t ThreadFuck t1 = new ThreadFuck(); ThreadFuck t2 = new ThreadFuck(); // 两个线程 Thread thread1 = new Thread(t1, &quot;Thread-1&quot;); Thread thread2 = new Thread(t1, &quot;Thread-2&quot;); thread1.start(); thread2.start(); // t1.run(); &#125;&#125;class ThreadFuck implements Runnable &#123; int temp = 10; // private Lock lock = new ReentrantLock(); @Override public void run() &#123; // lock.lock(); for (int i = 0; i &lt; 5; i++) &#123; temp -= 1; try &#123; Thread.sleep(1); &#125; catch (InterruptedException ignored) &#123;&#125; System.out.println(Thread.currentThread().getName() + &quot;-temp = &quot; + temp); &#125; // lock.unlock(); &#125;&#125;","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://matthew-han.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"并发","slug":"并发","permalink":"https://matthew-han.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"锁","slug":"锁","permalink":"https://matthew-han.github.io/tags/%E9%94%81/"}]},{"title":"张小龙的微信公开课","slug":"张小龙的微信公开课","date":"2020-01-09T06:45:25.000Z","updated":"2025-09-03T02:52:50.978Z","comments":true,"path":"post/9dca78f0-32ab-11ea-a0c0-0fee95c51c98/","permalink":"https://matthew-han.github.io/post/9dca78f0-32ab-11ea-a0c0-0fee95c51c98/","excerpt":"","text":"公开课的内容 张小龙的演讲内容个人概括（怎么感觉像和领导开会记笔记一样。。） 微信是人们花时间最多的信息传递工具&#x2F;平台，看到的听到的都是远方的信息，宽广度早已远远超过以往任何的一个时代，也是微信一直要解决的一个问题。也引发了一些隐私问题，比如广告服务推送，倡导同行一起重视。 信息获取的被动。互联网让信息唾手可得。目前大多数人都是被动获取信息，人们也倾向于这种模式，不愿意主动地获取信息。微信完全是基于推送的模式。 社会关系的扩大的和复杂，各种同学、同事群、朋友圈的关联 ，微信之前限定好友上限5000，目前已经有100万人已经接近5000个好友，促使要扩大好友数目。附近的人刚上线时，感到不安。不确定是好是坏、带来的影响难以控制。 信息传播的快速。事件传播的速度爆炸，并且事件的影响力和传播速度和事件本身的夸张型、趣味性、新鲜性有强关联性。 技术手段无法衡量内容的质量标准，需要更多的参与者帮助平台作出仲裁。 信息选择的困难。看到的内容总是局部。在「看一看」中实践了社交推荐，效果还不错。 信息的多样性。人人皆可创作的年代，希望更多的「小号」也有自己的生存空间。 搜索的困难。与Web互联网相比，移动互联网的各个app之间更加割裂，信息难以打通。做「小程序」的便是因为一个梦想：希望通过搜索能进入到每一个「小程序」内部，海量的小程序可以支撑起长尾的搜索需求。「小程序」目前是团队一直需要不断改进的领域。 微信的起步阶段基于移动端来做，而非PC，PC只是辅助。因为这样做的好处是，产品可以更好地普及到每一个人都能用。但是有2个小小的失误： 公众平台很长时间都只有PC Web版，限制了内容创作者的范围。 公众平台的原始想法是取代短信，成为一种基于连接品牌和订户的群发工具，内容应该是多元且丰富的，但是不小心做成了文章为主的载体，是的其他的短内容的形式没有呈现出来，而形成短内容的缺失。 朋友圈之所以默认是发照片视频的，是因为当时的认识是，让十几亿人发文字是不容易的，但是发照片是每个人都可以做到的。 新版本的小预告：微信的发力方向是指是短内容为主，近期可能会与大家见面；由于春节到来，红包上也有了新的创造，希望你能够发挥创造力。 个人的看法很多人不懂为什么有了QQ，为什么还会诞生出微信，感觉两者完全是重合冗余的。很多曾经将QQ作为主力信息交流工具的人来说，可能微信放在今天在他们眼里依然不算是一个「好用」的产品： 朋友圈只能看共同好友的评论 群聊不保存到通讯录可能会再也找不到了 文件传输、协作能力很弱，没有QQ强大 QQ空间的保留的那份感动… 看起来好像就是微信的内容丰富度不如QQ及其衍生品，但事实上果真如此吗？仅是一个「公众号」便开辟出了一种新的模式，它的诞生是在4G普及、移动互联网爆发的前两年，虽然之初具有一定门槛和复杂度，但是给了很多有想法、想表达的人一个渠道，所拓展出来的业务繁荣程度是令人难以想象的。包括后面的「小程序」，在公开课中张小龙也叙述到移动互联网的背景下，微信作为载体的「小程序」之间的信息数据交流的会更加无碍且高效，海量数据更好地用于服务用户。 公开课中思考 第一点： 服务商利用隐私虽然会带来更高效、更精准的服务，但就像一把双刃剑同时也会带来隐私泄露、垃圾营销等问题。而如今天网系统、各种人脸智能化识别、数据流通的当代社会，个人的隐私空间已经压缩到了最小。解决这一类问题，其实和一个「度」有关。需要保证海量数据哪一部分数据只能被谁利用，哪一部分只能生产在什么领域，是一个需要多领域一起长期摸索的过程。 第二点： 尤其是在移动互联网的今天，虽然互联网上的信息唾手可得，但是有相当一部分流量是被动获取的，供应商根据你的浏览记录、兴趣点、标签、行为操作等等属性来编织一张属于你的用户画像，为了尽可能的保证你在他们的服务上多「逗留」一会儿，为你推送的内容往往是算法+人气、热度精心筛选的。有些人说这是一种不好的模式，因为它不但局限你的思维，让你无法从其他的切入点切入，而且还会恶性循环，需要我们自身打破这种被动获取的方式，尽可能地主动地搜寻探索我们感兴趣的领域。我无法完全赞同这种观点，首先未免小看或者说不了解该推送算法。这类算法应用不仅仅是简单的只会推送给用户感兴趣的东西，它背后的处理逻辑是极其复杂且繁琐的，这种类似人工智能的应用会不断试探你，不停的修正、重构一个真正的你，即使你在YouTube、Bilibili这些视频网站上只看游戏视频，suggest to you也绝不会蠢到单纯的以为你只是一个狂热到生命中只有游戏的玩家。人们都应该有自己独立思考的能力和主观能动性，不要轻易的被煽动和相信，理性中夹杂着辩证的思维去分析事物，会让这个世界更美好:) 第三点： 「附近的人」刚上线时，张小龙有着隐隐的不安，觉得打破了和附近的人的界限，可能会引发一系列的问题。当然可能有些人已经尝试或成功把这一功能当做约*来用。扩大5000个好友数目限定同样也会让张小龙感到担忧，说实话我比较好奇这个的上限5000数字到底是如何定下来的，好友数目的增长会带来哪些不可控的影响？好友位的增多提高了不法分子的效率，一个账号的能力得到了提升，节省了多账号的成本；「对不起，好友满了，加不了了。」变得难以说出口了（笑 第四点： 人们往往只会对“魔幻“、“耸人听闻”、“搞笑”的新闻产生更大的兴趣，所以捏造虚假、标题党等内容屡见不鲜。技术手段本身不具备像人对艺术的感知、评判能力，它的评判是模式化、标准化的。按照一定的算法加上抽象模板去打分。所以微信本身对内容的质量的把控是离不开众多参与者的，这也正是目前人工智能的一个很大的窘境——没那么智能，却想要干“人”都需要学习一段时间才能做的活。 第五点： 微信尝试了利用好友之间的互相推荐来扩大你的选择范围，自从打开了「看一看」功能后，看到小红点我也习惯性的会点开看看最近大家都看了什么。其实和把文章分享到朋友圈是相类似的，但是这个过程显得更简便更随意，少了那么一点「刻意感」，会让人更容易去分享。 第七点： 张小龙说移动互联网各个App更加割裂。其实我觉得和第一点隐私问题相似，虽然App之间是相互割裂，但是每当你在微信上交流过数码产品，浏览器浏览、搜索过什么内容，电商网站便会向你推荐相关产品。但微信这边不满足于与其他应用交流数据，而是想自己做成一个全能的平台，利用小程序掌握所有的数据，来支撑长尾的搜索需求，野心蓬勃。 第八点： 微信最初便是以移动端作为出发点，PC端仅仅只是作为替补，这点确实很妙，微信项目的诞生到推出，也是智能手机的发展史，马化腾也说过当时处境其实不算太明朗。微信利用手机通讯录的社交属性，实用的懒人专属语音功能，加上手机的随身携带不离身的特质，让微信很好地发展普及起来。 马化腾：确实是有3个团队报名。当时解决了一个很大的问题，从PC到移动怎么打？当年诺基亚从前一年市场份额70%、80%规模一下子掉下来，安卓、苹果这类智能手机迅速替代了传统功能机，互联网企业反应过来的才能活下来，没反应过来就死掉了。我们是最早拿到这张船票的，没上船的再也过不来了，这是最大的一个危机。 另外，从这次视频中明显可以看出「短内容」是个高频词汇，应该是微信接下来要布局和发力的重点。如今好像很多内容都从大而全转变成了精而短，是人们都变懒了吗？还是当今工作负担较大，大家时间都不多？个人觉得有以下几点： 创作者的门槛：长内容的创作是需要花费大量时间、精力的，并且很有可能远远低于预期收益。例如哔哩哔哩的纪录片、科普视频，甚至是鬼畜视频，一旦收益不好便会大大打击创作者的积极性。降低门槛很早就成为了趋势，不但可以扩大创作者的人群，还可以使得内容生产的可持续性。 获取者的精力：会议、吃饭、通勤、等待的过程中有太多碎片化的时间。一旦你无所事事时，低头抬头把玩手机早已经是一种常见的生活习惯。这个时间点，精简的短内容一定是更好的表达方式，较于长内容不会有那种“割裂感”。用户往往会把长内容的优先级放到最后或者是有时间之后，总是会把简单的会先消化掉。这就造成了长内容的劣势。 传播速率不同，阅读这部分内容效率显然高很多。Facebook就是Facebook，Twitter就是Twitter。新浪微博之初也考虑过成为一种Facebook，最后还是以140个字数作为特色的内容产品，避免了和博客&#x2F;论坛&#x2F;资讯门户正面竞争。短内容也会让feed流一气呵成，让微博、抖音用户产生一种一直刷不累的错觉。 公开课视频","categories":[{"name":"点滴","slug":"点滴","permalink":"https://matthew-han.github.io/categories/%E7%82%B9%E6%BB%B4/"}],"tags":[{"name":"张小龙","slug":"张小龙","permalink":"https://matthew-han.github.io/tags/%E5%BC%A0%E5%B0%8F%E9%BE%99/"},{"name":"公开课","slug":"公开课","permalink":"https://matthew-han.github.io/tags/%E5%85%AC%E5%BC%80%E8%AF%BE/"},{"name":"微信","slug":"微信","permalink":"https://matthew-han.github.io/tags/%E5%BE%AE%E4%BF%A1/"}]},{"title":"Mybatis 多对多映射的小问题","slug":"Mybatis-一对多映射的小问题","date":"2019-12-26T02:52:21.000Z","updated":"2025-09-03T02:52:50.972Z","comments":true,"path":"post/bce6bdb0-278a-11ea-9afb-77b212895fb9/","permalink":"https://matthew-han.github.io/post/bce6bdb0-278a-11ea-9afb-77b212895fb9/","excerpt":"","text":"问题ORM映射中，一对多，多对多是非常常见的方式。但是由于场景使用没有这么多，到今天我才发现这个问题。 配置映射关系，使字段与DO类解耦，方便维护。但是为了方便管理和控制，我就在一个.java文件中写了两个VO类。 1234567891011121314151617181920212223242526272829303132333435@ToString@Setter(value = AccessLevel.PUBLIC)@Getter(value = AccessLevel.PUBLIC)@NoArgsConstructor@AllArgsConstructor@JsonInclude(value = JsonInclude.Include.NON_NULL)public class CategoryVO &#123; private Long cid; private Long pid; private Integer level; private Integer sortNo; private String cname; private java.sql.Timestamp created; private java.sql.Timestamp updated; private List&lt;Word&gt; words;&#125;@ToString@Setter(value = AccessLevel.PUBLIC)@Getter(value = AccessLevel.PUBLIC)@NoArgsConstructor@AllArgsConstructor@JsonInclude(value = JsonInclude.Include.NON_NULL)class Word &#123; private Long id; private Long hotWordId; private Long categoryId; private String keyword; private Integer source; private Integer sortNo; private Integer isDeleted; private java.sql.Timestamp created; private java.sql.Timestamp updated;&#125; 它们的关系也非常简单，可以直接看出，一个类目（分类）对应多组HotWord（热词）。所以在resultMap中为了图快我就直接把属性一个个映射数据库的column了。 1234567891011121314151617181920&lt;resultMap id=&quot;result&quot; type=&quot;&#123;hape&#125;.common.orm.model.vo.CategoryVO&quot;&gt; &lt;!-- 相同的列名id --&gt; &lt;id column=&quot;id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;cid&quot;/&gt; &lt;result column=&quot;parent_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;pid&quot;/&gt; &lt;result column=&quot;name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;cname&quot;/&gt; &lt;result column=&quot;level&quot; jdbcType=&quot;INTEGER&quot; property=&quot;level&quot;/&gt; &lt;result column=&quot;sort_no&quot; jdbcType=&quot;INTEGER&quot; property=&quot;sortNo&quot;/&gt; &lt;collection property=&quot;words&quot; ofType=&quot;&#123;hape&#125;.common.orm.model.vo.Word&quot;&gt; &lt;!-- 相同的列名id --&gt; &lt;id column=&quot;id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;id&quot;/&gt; &lt;result column=&quot;hotword_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;hotWordId&quot;/&gt; &lt;result column=&quot;category_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;categoryId&quot;/&gt; &lt;result column=&quot;keyword&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;keyword&quot;/&gt; &lt;result column=&quot;source&quot; jdbcType=&quot;TINYINT&quot; property=&quot;source&quot;/&gt; &lt;result column=&quot;sort_no&quot; jdbcType=&quot;INTEGER&quot; property=&quot;sortNo&quot;/&gt; &lt;result column=&quot;is_deleted&quot; jdbcType=&quot;TINYINT&quot; property=&quot;isDeleted&quot;/&gt; &lt;result column=&quot;created&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;created&quot;/&gt; &lt;result column=&quot;updated&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;updated&quot;/&gt; &lt;/collection&gt;&lt;/resultMap&gt; 但是实际结果却并不是一个包含了多个子结构的对象，而是只有一个words对象，究其原因，原来是因为colum列名有重复，都存在一个相同的id。 解决办法你可以选择干掉其中一个id，或者在使用SQL语句中加入别名加以区分，当字段较多的时候就会比较麻烦。我这里把字段都加上了w_区分。 12345678910111213141516171819202122&lt;select id=&quot;selectHotWordByCategoryId&quot; parameterType=&quot;int&quot; resultMap=&quot;result&quot;&gt; select &lt;!--为什么要as &quot;w_&quot;呢？--&gt; &lt;!--因为两张表的colum有相同的名称会出现问题，不然就只能查出子表的一条而不是多条了--&gt; t1.*, t2.id as w_id, t2.hotword_id as w_hotword_id, t2.keyword as w_keyword, t2.source as w_source, t2.sort_no as w_sort_no, t2.created as w_created, t2.updated as w_updated from xunfei_category t1 left join xunfei_hotword t2 on t1.id = t2.category_id where t1.id = #&#123;id&#125; and t2.is_deleted = 0 order by t2.sort_no, t2.updated desc&lt;/select&gt; 然后在resultMap中修改成改后的别名就OK啦。 123456789101112131415161718&lt;resultMap id=&quot;result&quot; type=&quot;&#123;hape&#125;.common.orm.model.vo.CategoryVO&quot;&gt; &lt;id column=&quot;id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;cid&quot;/&gt; &lt;result column=&quot;parent_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;pid&quot;/&gt; &lt;result column=&quot;name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;cname&quot;/&gt; &lt;result column=&quot;level&quot; jdbcType=&quot;INTEGER&quot; property=&quot;level&quot;/&gt; &lt;result column=&quot;sort_no&quot; jdbcType=&quot;INTEGER&quot; property=&quot;sortNo&quot;/&gt; &lt;collection property=&quot;words&quot; ofType=&quot;&#123;hape&#125;.common.orm.model.vo.Word&quot;&gt; &lt;id column=&quot;w_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;id&quot;/&gt; &lt;result column=&quot;w_hotword_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;hotWordId&quot;/&gt; &lt;result column=&quot;w_category_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;categoryId&quot;/&gt; &lt;result column=&quot;w_keyword&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;keyword&quot;/&gt; &lt;result column=&quot;w_source&quot; jdbcType=&quot;TINYINT&quot; property=&quot;source&quot;/&gt; &lt;result column=&quot;w_sort_no&quot; jdbcType=&quot;INTEGER&quot; property=&quot;sortNo&quot;/&gt; &lt;result column=&quot;w_is_deleted&quot; jdbcType=&quot;TINYINT&quot; property=&quot;isDeleted&quot;/&gt; &lt;result column=&quot;w_created&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;created&quot;/&gt; &lt;result column=&quot;w_updated&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;updated&quot;/&gt; &lt;/collection&gt;&lt;/resultMap&gt;","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://matthew-han.github.io/tags/Mybatis/"},{"name":"数据库映射","slug":"数据库映射","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%A0%E5%B0%84/"},{"name":"笔记","slug":"笔记","permalink":"https://matthew-han.github.io/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"多线程之线程池小纪","slug":"多线程之线程池小纪","date":"2019-12-18T09:03:25.000Z","updated":"2025-09-03T02:52:50.978Z","comments":true,"path":"post/3ff45990-2175-11ea-bda8-b1e815e5e40d/","permalink":"https://matthew-han.github.io/post/3ff45990-2175-11ea-bda8-b1e815e5e40d/","excerpt":"","text":"关于线程池并发总是离不开多线程，多线程的应用能够更好地帮助我们协调利用CPU、Memory、Net、I&#x2F;O等系统资源。频繁的创建、销毁线程会浪费大量的系统资源，增加并发编程的风险。利用线程池可以实现类似主次线程隔离、定时执行、定时执行、周期执行等任务。作用包括： 利用线程池管理并复用线程、控制最大并发数等。 实现某些与时间相关的功能，如定时执行、周期执行等。 隔离线程环境。比如交易服务和搜索服务在同一台服务器上，分别开启两个线程池，交易线程的资源消耗明显要更大；因此，通过配置读的线程池，将两者隔开，避免个服务线程相互影响。 关于线程池的基础概念和一些简单场景，可以看看这篇文章：线程池开门营业招聘开发人员的一天 迷思如下是我定义的一个线程工具类，我定义了核心线程数量大小为4；最大核心线程数量大小为8，LinkedBlockingQueue容量大小未初始化，也未定义一个handle，当我在利用这个线程池生产线程的过程中发现，当创建速度大于它的处理速度时，核心线程数量依旧是4个。 嗯？说好的，最大核心线程数不是BUG，8个吗？难道当前不应该是8个？ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class ThreadPoolUtils &#123; private static final Logger logger = LoggerFactory.getLogger(ThreadPoolUtils.class); /** * 线程池维护线程的最少数量 */ private static final int SIZE_CORE_POOL = 4; /** * 线程池维护线程的最大数量 */ private static final int SIZE_MAX_POOL = 8; /** * 禁止手动初始化 */ private ThreadPoolUtils() &#123;&#125; public static void printPoolInfo() &#123; logger.info(&quot;当前线程Pool的数量 = [&#123;&#125;]&quot;,Singleton.SINGLETON.getThreadPool().getPoolSize()); logger.info(&quot;当前task的数量 = [&#123;&#125;]&quot;,Singleton.SINGLETON.getThreadPool().getTaskCount()); logger.info(&quot;当前执行task的数量 = [&#123;&#125;]&quot;,Singleton.SINGLETON.getThreadPool().getActiveCount()); logger.info(&quot;当前完成task的数量 = [&#123;&#125;]&quot;,Singleton.SINGLETON.getThreadPool().getCompletedTaskCount()); &#125; /** * 通过枚举创建单例对象 */ private enum Singleton &#123; /** * 线程池单例 */ SINGLETON; private ThreadPoolExecutor threadPool; private ScheduledExecutorService service; Singleton() &#123; // 为线程命名 ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat(&quot;线程池工具类-pool-%d&quot;).build(); // 创建线程池1 threadPool = new ThreadPoolExecutor( SIZE_CORE_POOL, SIZE_MAX_POOL, 10L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), namedThreadFactory); // 创建线程池2 service = Executors.newScheduledThreadPool(4); &#125; /** * 返回单例对象 */ public ThreadPoolExecutor getThreadPool() &#123; return threadPool; &#125; public ScheduledExecutorService getScheduledThreadPool() &#123; return service; &#125; &#125; /** * 向池中添加任务 * 单次执行 * @param task */ public static void addExecuteTask(Runnable task) &#123; if (task != null) &#123; ThreadPoolExecutor threadPoolExecutor = Singleton.SINGLETON.getThreadPool(); threadPoolExecutor.execute(task); &#125; &#125; public static void addScheduleTask(Runnable task) &#123; Singleton.SINGLETON.getScheduledThreadPool().scheduleWithFixedDelay(task, 5, 3, TimeUnit.SECONDS); &#125;&#125; 探究看来还是basic不够扎实啊，学的是个JB！我们看一下ThreadPoolExecutor的源码，查看下的他的4个构造方法如下图，我们来看看比较难懂的几个参数： 第5个参数：workQueue表示缓存队列。当请求的线程大于maximumPoolSize时，线程进入BlockingQueue阻塞队列。是一个生产消费模型队列。 第7个参数：handle表示执行拒绝策略的对象。当超过第5个参数workQueue的任务缓存区上限的时候，就可以通过该策略处理请求，是一种简单的限流保护。 那么，我们上面的实例化是怎么写的？ 12345678// 创建线程池1threadPool = new ThreadPoolExecutor( SIZE_CORE_POOL, SIZE_MAX_POOL, 10L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), namedThreadFactory); 我们把LinkedBlockingQueue&lt;Runnable&gt;()作为缓存队列，我们不关心的它内部实现，通过源码可以知道它是一种无限队列，构造器容量默认值大小是Integer.MAX_VALUE，往往在生产场景中很难达到这个值，所以像我上面这样写是极其不科学的，应该根据实际场景设置一个可承载容量大小，并配合handle做出拒绝策略，才是一个完整的流程。 我们稍微熟悉了它的构造方法之后，怎么知道它是如何工作的呢？另外我之前的迷思，为什么核心线程数始终等于4呢？ 原因首先我们可以通过源码查看execute方法： 123456789101112131415161718192021222324252627282930313233343536373839404142public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn&#x27;t, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); // 1. 如果当前线程数 小于 corePoolSize，则尝试添加新线程 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; // 2. 尝试向workQueue添加队列（offer方法在workQueue没有容量时，添加失败），线程已经存在不会创建新的线程，如果不存在则创建新的线程。 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 3. 添加新线程，此处会比较maximumPoolSize，如果大于maximumPoolSize，则会使用饱和策略 else if (!addWorker(command, false)) reject(command);&#125; 而addWorker方法主要是动态的调整线程池的线程数量。从execute方法和addWorker方法可以看出，当前线程数优先与corePoolSize 比较，大于corePoolSize ，则与workQueue容量比较；如果当前线程数大于workQueue容量，则与maximumPoolSize比较；如果当前线程数大于maximumPoolSize，则执行饱和策略；最后，根据饱和策略做出相应的处理。 所以我粗略的总结下当corePoolSize（核心线程数）满了，接下来的线程先进入workQueue（任务队列），当队列也满了之后，创建新线程，直到达到maximumPoolSize（最大线程数），之后再尝试创建线程时，会进入拒绝rejectedExecution。 所以为什么线程池的核心线程数一直是4个，因为多余的都处在任务队列阻塞中，由于未设置一个容量大小，所以这个容量非常的大，其实是超出我们的处理能力的，我们程序始终就也没能够达到最大线程数。或者可以这么理解，这个maximumPoolSize算是一种比较坏（极限）的情况，很少情况并不会真的按照这个数量处理任务，只有当任务队列都不够时，才会继续创建线程，直到达到最大线程数，超过了之后就必须要handle来处理拒绝策略了。 饱和拒绝策略 好吧，面试被问到了有哪些策略，2020.11.4 更新一下。 默认的AbortPolicy： ThreadPoolExecutor.AbortPolicy：丢弃任务并抛出RejectedExecutionException异常。 1A handler for rejected tasks that throws a &#123;@code RejectedExecutionException&#125;. 这是线程池默认的拒绝策略，在任务不能再提交的时候，抛出异常，及时反馈程序运行状态。如果是比较关键的业务，推荐使用此拒绝策略，这样子在系统不能承载更大的并发量的时候，能够及时的通过异常发现。 DiscardPolicy ThreadPoolExecutor.DiscardPolicy：丢弃任务，但是不抛出异常。如果线程队列已满，则后续提交的任务都会被丢弃，且是静默丢弃。 1A handler for rejected tasks that silently discards therejected task. 使用此策略，可能会使我们无法发现系统的异常状态。建议是一些无关紧要的业务采用此策略。例如，本人的博客网站统计阅读量就是采用的这种拒绝策略。 DiscardOldestPolicy ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新提交被拒绝的任务。 1A handler for rejected tasks that discards the oldest unhandled request and then retries &#123;@code execute&#125;, unless the executor is shut down, in which case the task is discarded. 此拒绝策略，是一种喜新厌旧的拒绝策略。是否要采用此种拒绝策略，还得根据实际业务是否允许丢弃老任务来认真衡量。 CallerRunsPolicy ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 1A handler for rejected tasks that runs the rejected task directly in the calling thread of the &#123;@code execute&#125; method, unless the executor has been shut down, in which case the task is discarded. 如果任务被拒绝了，则由调用线程（提交任务的线程）直接执行此任务。 自定义一个Policy 实际开发中，我们还是会自定义一个Policy策略，比如写入日志、数据库等等。 测试好了，既然大致了解了线程池的工作原理之后，可以进行一个测试来验证以下是否符合： 123456789101112131415161718192021222324252627282930313233public class TestThreadPool &#123; private static ThreadFactory tf = new ThreadFactoryBuilder() .setNameFormat(&quot;factory-pool-%d&quot;).build(); private static ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(4, 8, 10L, TimeUnit.MINUTES, new LinkedBlockingQueue&lt;&gt;(50), tf); public static void main(String[] args) throws InterruptedException &#123; System.out.println(&quot;================start================&quot;); for (int i = 0; i&lt;100; i++) &#123; threadPoolExecutor.execute(new Task(String.valueOf(i))); &#125; System.out.println(&quot;================end================&quot;); &#125;&#125;class Task implements Runnable &#123; private static final Logger logger = LoggerFactory.getLogger(TestThreadPool.class); private String name; public Task(String name) &#123; this.name = &quot;[ &quot; + name + &quot; ]&quot;; &#125; @Override public void run() &#123; logger.info(name + &quot;只要干不死，就往死里干，奥利干！！&quot;); // System.out.println(name + &quot;奥利给！！&quot;); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 一个线程类Task，在run方法中打印一句「正能量」，然后sleep2秒来模拟处理这个任务。我们创建一个核心线程数为4，最大线程数8，容量大小为50的LinkedBlockingQueue队列，然后在循环中持续创建线程。当成功创建完这100个线程之后，应该会有====================end====================打印出来。 我们可以期待一下结果是什么？ 按照上面的工作流程来说，有几种情况： 线程处理的速度远远大于线程创建的速度，可能4个核心数都完全够用，甚至用不到workQueue，最后打印了end。emmm，当然从我们写的测试代码来说几乎是不可能的，for循环表示：烙呢？中国🇨🇳速度嗷！ 线程创建的速度大于回收速度，但是workQueue和maximumPoolSize完全可以支撑，100个线程创建成功并完成任务。 当corePoolSize和workQueue以及maximumPoolSize都过载，丢弃任务并抛出RejectedExecutionException异常了。 其实可以很明显知道，sleep2秒加上logger.info()方法，线程的创建的速度一定是大大于执行的。按照4、8、50的配置，当地58个创建被创建成功之后，要是目前没有任何一个线程被释放的话，第59个线程会因为上限问题而被拒绝，这时候就会抛出异常了。当然这是个for循环，产生的速度足够快，基本上100次循环完成，第一个线程都没完成，所以可以大胆猜测，logger一共会打印58行日志，并伴随着RejectedExecutionException的出现。 我们看一下运行的结果： 果然第58个线程被创建之后，后续第59个线程想被创建就抛出了异常，如图刚好是58行（0 ~ 57），也没有====================end====================的出现。 奥利给当我们把这个线程类的run方法分别改成如下： 12345@Overridepublic void run() &#123; // logger.info(name + &quot;只要干不死，就往死里干，奥利干！！&quot;); System.out.println(name + &quot;奥利给！！&quot;);&#125; 123456@Overridepublic void run() &#123; // logger.info(name + &quot;只要干不死，就往死里干，奥利干！！&quot;); // System.out.println(name + &quot;奥利给！！&quot;); logger.info(name + &quot;奥利给！！&quot;);&#125; 分别看下结果： 看来org.slf4j.Logger.info()的耗时不是一般的长，比System.out.println() 还长。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://matthew-han.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"并发","slug":"并发","permalink":"https://matthew-han.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"线程池","slug":"线程池","permalink":"https://matthew-han.github.io/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"}]},{"title":"我的2019","slug":"2019年年终总结","date":"2019-12-16T02:49:34.000Z","updated":"2025-09-03T02:52:50.970Z","comments":true,"path":"post/b11fe710-1fae-11ea-9d8a-c3eaf7e57853/","permalink":"https://matthew-han.github.io/post/b11fe710-1fae-11ea-9d8a-c3eaf7e57853/","excerpt":"","text":"心态这一年心态上的起伏，2019年算是完全正式工作的一年，这一年感觉大家好像都不怎么满意，资本寒冬，每况愈下，但是自己状态不能拉胯。 身体从3月份起计划在家简单健身维持运动量和塑形（主要是为了能增肌身材匀称些长胖点，现在实在是太瘦了），购置了哑铃、哑铃凳、瑜伽垫等器具。训练的动作也不多，按照keep上来实行哑铃复合动作、哑铃卧推、俯卧撑和深蹲。但是坚持不到2、3个月便吃灰了。 究其原因，一是个人意志力过于薄弱；二是没有按照日期制定实际的执行计划。第二点其实很关键，如果只是脑袋里有个一周几次的想法，很容易因为太累、其他事情等原因被自我说服从而无限推迟。有个每周训练表格，硬性规定那天一定做够训练量相对会好多。 看牙一次、胃镜一次、体检一次，倒是没什么毛病。 消费今年没什么理财投资计划，目前也没有什么存钱计划，该用用该花花。 大概回想了下估计和往年一样很大一部分花费在服饰上（哈哈，完全不是程序员的作风）。自从去年重回了虎扑潮流区，就开启我的时装学习之旅。抛弃掉原来的工装裤、运动鞋、大LOGO的憨憨大学生套装，将眼光望向Greg Lauren、 Song for the Mute、Guidi、Maison Margiela、Amiri、Fear of God、Raf Simons、Yohij Yamamoto、Balenciaga、Dsquared2、Jil Sander这些偏时装、奢侈品的牌子。 上一年还在读带学的我还穿着Uniqlo U系列、Converse 1970s、Nike Air Force1这些学生爆款，憨憨的认为Supreme、Palace才是潮人的时候，突然就接触到了更高阶的东西，就像一个人在犹豫选择思域还是马自达昂克塞拉的时候，突然被邀请去试驾AMG-GT。可能这辈子以后永远都不会再穿AJ这些了吧。 慢慢认识到剪裁和面料带来的内味儿和高级感是一些「钱不到位」的东西无法比拟的，说白了钱不够是永远穿不到「真正好看」的服装的。 到今年才终于意识到了T恤的好看的精髓，既不是oversize的落肩也不是阳光干净的窄领口，而是廓形的胸围。 开始尝试破洞紧身牛，但是由于人瘦腿长，没有一条紧身牛能穿出裤脚堆叠高街的内味儿，反而容易变成精神boy（是真难买裤子啊）。 想尝试切尔西靴，但是选择高不成低不就的那种感受属实难受。现在真是一个尴尬的节点啊，眼界上来了，钱包没跟上，反而更加不容易满足。 想买的东西 今年本来想买一只Seiko千米罐头，价格也比较合适，但是质量比较重并且冬天感觉过厚不宜佩戴，还在观望中。 一台27寸iMac。虽然不是144hz，但是优质的5K屏幕还是让人赏心悦目。从单位的macOS到家里的Windows会让工作流很容易断（不是加班），并且Windows没有那种容易让人产生学习的欲望。 工作2019年对我的思想上有着不小的提升。 学会对任何事情提出质疑；思考问题相比之前会更加多维度的切入；工作上做一件事会考虑它的责任划分、职能问题、带来的影响；与人交际更加谨慎了（也不知道是好是坏）。 我一直是一个很理性的人，很少会被舆论煽动情绪。很讨厌跟风，但是这种讨厌不是狭义上的对事物本质上的「讨厌」，而是讨厌大众的东西，更倾向于差异化的标签。 今年的工作依然很杂乱：项目管理、软件开发、业务测试、系统运维。我知道现在的情况不可能允许我全身投入开发中，所以会有所计划了。 2018年我还是个讨厌写代码的臭弟弟，还在思考实习毕业之后如何逃离编程苦海，但是在正式入职后，由于广电工作的杂，居然慢慢的培养了写代码的兴趣。2019年是个快速成长的一年，犹如一个婴童开始爬爬走走，拥有了思想，也侧面强调了大学时期的我是多么的废物。也让我明白了兴趣和热爱才是真正能做事的根本，什么信念、意志都是狗屁。 接下去想干的事情 去日本感受下童年的记忆，Shopping； 打个耳洞？（想走艺术路线了嗷）； 留个长发？（想走艺术路线了嗷）； 学一下游泳，觉得游泳好处实在多，小学的时候半途而废了； 想系统地学习下声乐，想当年还是艺术表演队的。变声期之后，音域异常的窄，估计其实是长期发声位置的问题。","categories":[{"name":"点滴","slug":"点滴","permalink":"https://matthew-han.github.io/categories/%E7%82%B9%E6%BB%B4/"}],"tags":[{"name":"生活","slug":"生活","permalink":"https://matthew-han.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"轨迹","slug":"轨迹","permalink":"https://matthew-han.github.io/tags/%E8%BD%A8%E8%BF%B9/"},{"name":"日记","slug":"日记","permalink":"https://matthew-han.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"Redis搭配生产者消费者模型","slug":"消费消息通过线程池开启多线程任务","date":"2019-11-29T03:27:14.000Z","updated":"2025-09-03T02:52:50.979Z","comments":true,"path":"post/237a2190-1258-11ea-a4fe-c7eac48cbd2c/","permalink":"https://matthew-han.github.io/post/237a2190-1258-11ea-a4fe-c7eac48cbd2c/","excerpt":"","text":"前言Redis作为一款优秀的缓存中间件，人们总是寄予他新的厚望。其列表类型的阻塞操作可以实现消息队列。 在场景中使用可以牢记以下口诀： lpush + lpop &#x3D; Stack(栈) lpush + rpop &#x3D; Queue(队列) lpsh + ltrim &#x3D; Capped Collection(有限集合) lpush + brpop &#x3D; Message Queue(消息队列) 背景假如有这样的一个需求，现有一套「较老」的公共服务可供你的系统使用，但是目前还有其他业务单位正在使用。每次请求调用下发一个任务，接着服务会响应一个回调接口，通过这个回调接口，你可以查询这个任务的执行状态，到了什么阶段，是否完成之类的。任务从下发到结束需要一定的时间，并且任务结束总是以两种状态出现：Completed或者Error。 假设这套公共服务分配给你了N个容量可以同时进行任务的调度，也就是说你系统调用下发的任务只能是N，当超过N时，就需要自定义一个队列来进行排队。当有任务完成时，任务执行池就可以释放一个空位，队列就可以pop出一个消息用于处理调用公共服务。 分析为了充分深入Redis的列表的使用，我打算把所有的需求点和场景都交给Redis去完成。 所以这个需求看起来比较简单，就变成了也有麻烦的地方，主要是四个： 由于其他业务单位的存在，本系统需要有一个缓冲池和任务执行池Running Pool，容量为可分配的N。 业务量增加超过N时，需要有个等待队列维护出入：当目前任务执行池Running Pool满载时，入队；当任务Running Pool中的任务执行完成释放空位时，则出队进入Running Pool。 「实际处理」的任务并不是执行在本系统而是在公共服务上，也就是说任何状态只能被动地通过公共服务的回调接口去查。 当存在N个正在执行的任务时，单线程肯定是效率不够的。需要开启多线程去回调公共服务的接口判断任务状态是否完成&#x2F;失败，用于下一步操作出入队列。 设计 我们可以在Redis中规划一块任务执行池Running Pool，可以是Set类型也可以是List类型，容量为N。设计这样的一个队列有个好处是如果单纯的PUSH/POP的话，当出队之后处理这个消息的过程中发生不可抗力、宕机，消息出队之后就会永远的丢失掉，而这样做则是消息始终持久化在Redis中，是任务结束之后出队； 有一个等待队列Pending Queue用于缓冲，消费者需要处理上面和这一块的业务逻辑； 一个Completed Queue用于完成消息的推送； 一个Error Queue用于任务失败消息的推送（这两者其实可以合并，作为任务结束的消息便可，具体内容可以放在value中，也通过读写DataBase。） 为了不出现当任务队列中没有任务时，消费者每秒都会调用一次POP命令查看是否有新任务这种情况，需要在消费者中同时处理业务逻辑，当任务执行缓冲池出队时，把Pending Queue的消息出队，入队到Running Pool。 所以我们需要一个生产者RedisProducer（部分代码） 123456789101112131415161718192021222324252627282930313233@Transactional(rollbackFor = Exception.class)public ProduceDTO produceTask(String orderId) &#123; /* * 数据处理代码段... * 部分业务逻辑... */ // 判断running queue是否还有空位 boolean condition = !redisBase.hasKey(RUNNING_QUEUE) || redisBase.lGetListSize(RUNNING_QUEUE) &lt; RUNNING_QUEUE_SIZE; // 如果有空位 if (condition) &#123; redisBase.lSet(RUNNING_QUEUE, orderId, -1, TimeUnit.DAYS); // 开启服务 logger.info(&quot;================================开启转码服务================================&quot;); /* * 任务订单持久化代码段... * 部分业务逻辑... */ boolean isUpdate = iTaskInfoService.modifyTaskByOrderId(produceDTO); if (isUpdate) &#123; // 调用消费者 redisConsumer.consumerMessageThread(produceDTO); &#125; else &#123; throw new MatthewHanException(ServiceEnum.FIRST_UPDATE_TRANS_TASK_ERROR.getCode(), ServiceEnum.FIRST_UPDATE_TRANS_TASK_ERROR.getMessage()); &#125; return produceDTO; &#125; else &#123; // 没空位，则消息先进入pending queue redisBase.lSet(PENDING_QUEUE, orderId, -1, TimeUnit.DAYS); &#125; return produceDTO;&#125; 此部分主要是先判断Redis的Running Pool是否还有空余，无空余则进入Pending Queue等待。进入了Running Pool的消息做DataBase的持久化业务逻辑。这一句redisConsumer.consumerMessageThread(produceDTO);则是主动调用消费者。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://matthew-han.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"消息","slug":"消息","permalink":"https://matthew-han.github.io/tags/%E6%B6%88%E6%81%AF/"},{"name":"消息队列","slug":"消息队列","permalink":"https://matthew-han.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]},{"title":"谜の生产力插件/工具推荐（一）","slug":"谜の生产力插件-工具推荐（一）","date":"2019-11-27T01:25:23.000Z","updated":"2025-09-03T02:52:50.979Z","comments":true,"path":"post/c875c320-10b4-11ea-b56b-c33ebe3aaf5c/","permalink":"https://matthew-han.github.io/post/c875c320-10b4-11ea-b56b-c33ebe3aaf5c/","excerpt":"","text":"说明以下推荐的工具都是个人挖掘和网友介绍得来，相对于程序开发者来说较为友好。 Chrome插件相关 过多的插件会影响使用体验。 Octotree过去我们在GayHub上预览代码时，常常需要不停地前进下一页和回退上一页操作来更全面的获取想要的信息。虽然GayHub有着不错的搜索功能，但是对于一个陌生的项目来说，它的结构没有很清晰直观地展示出来，我们无法快速定位到任何一处来浏览我们想要的信息。 Octotree字如其名可以将代码的结构以树形展示，可以实现对工程项目结构的大致了解，快速定位到我们想去的任何地方。另外可以固定在每一个repository的左侧或者右侧。 Octotree拥有账号服务，当你注册了账号之后： 可以在repository页面上的仓库名称右边有一个加入bookmark的按钮，可以将你的repository收藏到bookmarks中，方便直接查找，非Pro版本拥有20个仓库的容量。 可以切换代码高亮的主题，例如dark♂主题之类的。 支持Chrome、Firefox、Opera、Safari。 获取方式 Chrome Web Store GitHub Vimium怀念Vim？害怕鼠标手（👴大二左手有过腱鞘炎，诶？为什么是左手）？Vimium都可以满足你。Vimium通过全键盘操作，可以暂时脱离鼠标，高效完成一系列动作。需要一定学习成本，但是只需学习高频操作的快捷键即可熟练地高效操作了。 如果忘记了快捷键，只需要调用？即可呼出Vimium Help查看所有快捷键指令。 常用指令j，k控制scroll的上下滚动；大小o可以选择是否以新标签页的形式打开地址栏，不过不如直接按T，呼出新标签页再键入地址好用。 其中f快捷键是个重点，它帮你筛选出当前页面的所有可跳转链接，并用字符高亮显示，只需对应页面上的高亮字符用键盘键入相应的字符，即可进入链接地址。其中f是覆盖当前页面，F以新标签页的形式打开链接。 获取方式 Chrome Web Store GitHub 新浪微博图床需要运营静态网站的人来说，把部分媒资素材分离并持久化是一个必要的选择。当然，稳定快速的读取并渲染展示也是支撑用户群的关键。普遍对象存储OSS都拥有直链+CDN的模式，对于访问量不高的情况下，直链的效果即可。8️⃣过目前CDN处理的比较好的有七牛和又拍云CDN，当然如果我们只是玩玩，我们还可以选择免费的新浪微博图床插件。 这款名叫Weibo-Picture-Store的扩展插件由Neko Atsume组织开发并开源在GayHub上。其原理就是利用新浪微博的微相册变成可支持外链的图床，在微相册中会创建一个新的相册，并且设置成为「仅自己可见」。 可以手动通过扩展插件的窗口手动上传图片，并得到4种形式的地址，Markdown的形式对于博客编写者来说十分友好。 除了可以手动传图到微相册以外，该扩展还支持互联网上的图片，鼠标右键选择把这张图片上传到微相册。所有的上传记录都可以在扩展插件中浏览。 获取方式 Chrome Web Store GitHub Saladict 沙拉查词作为一名程序员不可避免的要查阅各种官方、非官方的英文文档。有些核心语句和专业词汇十分需要一个翻译工具来做第一步：让你知道这个大概是什么意思，至于具体是什么含义需要自己去理解。 很多人说为什么不用Chrome自带的翻译？呃，自带的翻译确实够用了，但是往往只有中翻英，沙拉查词可以在后台配置多本词典，必应、柯林斯高阶、有道、剑桥等等，根据不同的词典可以翻译成多种语言，并且划词可以直接朗读。 获取方式 Chrome Web Store GitHub Adblock-For-YouTube拥有5,919,658名用户的爆款去广告扩展插件，专为YouTube打造。喜欢看YouTube视频的朋友都知道虽然YouTube视频的片头广告可以跳过，但是在一定程度上会割裂观看体验。 👴在用了4年时间里经常在想这么出名并且有效的插件，为什么YouTube一直没有采用应对措施呢？难不成就是YouTube自己的产品。 获取方式 Chrome Web Store Mac软件 我也想当正版侠 uTools为什么这个要放在第一个呢？ 因为， 它有、东西。 可以这么说，有了这么一个工具平台之后，上下文中的某些工具可能完全被uTools中的工具替代。 世界这么复杂 一个 就够了 获取方式 官网地址 Downie3互联网视频的下载怪，只需要在窗口输入视频地址即可下载，支持后期处理。 支持的网站众多，可在偏好设置中查看。目前国内网站大部分被收录（大概吧），17173、bilibili、163等等。 安装完之后还需要按照官网的指示在Chrome扩展程序中加载解压好的Downie3扩展程序。 Downie3是收费的，具体的「使用方法」就因人而异了。 获取方式 官方地址 FinalShell一款ssh工具，开发者也活跃在v2ex。据说是Java编写的，点个赞嗷！ macOS中的ssh工具本来就不多，之前使用的SSH Shell会出现多节点闪退的问题，FinalShell不但稳定运行，并且还将x-ftp和xshell的功能结合，十分好用了。 获取方式 官方地址 Xnip非常好用的一款截图，功能性和美观性上基本取代微信、QQ、macOS系统截图。 主要有以下几点： 滚动截图 非常好用，长截图必备，再也不用截多张图了，一气呵成，内容直观呈现。 窗口截图 可支持屏幕多窗口截图，效果就像上面几张图，边缘自带阴影，效果就像浮在纸面一样，非常好看，逼格满满。 步骤模式 贴图 这个也超好用，因为很多时候朋友、同事发给你一张图片，你需要边看图片提取内容信息边工作，这时候就像Photoshop的图层一样可以使用截图「钉」在桌面最上层，使截图置顶，再干别的工作也不会把截图覆盖了。 获取方式 官网地址 iPic &amp; iPic Mover以下两款工具比较嗯，不支持Windows。 iPic 实际还是图床工具，可以拖拽上传图片，自动生成Markdown链接，对于图床的云服务自行选择配置（支持新浪微博、七牛、又拍云、阿里腾讯、亚马逊等等），非Pro版只能使用默认的新浪微博的云服务，必须订阅之后才能全部解锁。如果这方面需求不大的话，没必要嗯冲，因为uTools就有官网开发的图床工具了，只不过iPic在使用交互体验上来说算是最方便的，因为他可以搭配Typora ，Typora集成了 iPicUploader，可以调用 iPic 上传。 iPic Mover 字如其名，文件迁移，支持文件夹下的Markdowm内的图片，iPic Mover 是通过调用 iPicUploader，将图片上传至 iPic 当前选中的图床。由于需要调用 iPic 来上传图片，iPic Mover 在运行时会检测 iPic 是否安装。如果未安装，会提示在 Mac App Store 下载。 获取方式 iPic Apple Store iPic Mover Apple Store","categories":[{"name":"其他技术","slug":"其他技术","permalink":"https://matthew-han.github.io/categories/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"工具推荐","slug":"工具推荐","permalink":"https://matthew-han.github.io/tags/%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90/"},{"name":"生产力","slug":"生产力","permalink":"https://matthew-han.github.io/tags/%E7%94%9F%E4%BA%A7%E5%8A%9B/"},{"name":"教程","slug":"教程","permalink":"https://matthew-han.github.io/tags/%E6%95%99%E7%A8%8B/"}]},{"title":"Windows平台Redis Cluster集群模式的坑","slug":"Windows平台redis-cluster集群模式的坑","date":"2019-11-18T09:38:38.000Z","updated":"2025-09-03T02:52:50.975Z","comments":true,"path":"post/32c6b4c0-09e7-11ea-8010-7bbe2de22c19/","permalink":"https://matthew-han.github.io/post/32c6b4c0-09e7-11ea-8010-7bbe2de22c19/","excerpt":"","text":"前言在一台迷のWindows机器上搭建了一个单节点模拟的三主三从redis集群，过程中有一些坑记录下。 cluster模式Redis的Cluster模式工作至少需要三个主节点，所以一般采用三主三从实现负载。 较理想的环境是一个实例单节点部署主从，多个实例实现集群。 由于Redis Cluster采用哈希分区规则，哈希分区一般有以下几种方式： 节点取余分区 一致性哈希分区 虚拟槽分区 其中Redis Cluster就是采用虚拟槽分区，虚拟分区也是利用哈希空间，使用分散使用分散度良好的哈希函数把所有 数据映射到一个固定范围的整数集合中，整数定义为槽(slot)。这个范围一般远远大于节点数，比如Redis Cluster槽范围是0~16383。槽是集群内数据 管理和迁移的基本单位。采用大范围槽的主要目的是为了方便数据拆分和集群扩展。每个节点会负责一定数量的槽。 假设当前集群有5个节点，每个节点平均大约负责3276个槽。由于采用高质量的哈希算法，每个槽所映射的数据通常比较均匀，将数据平均划分到5个节点进行数据分区。 修改集群的配置文件一般redis.windows.conf中有以下需要修改： port：端口号，三主三从的集群，由于是一台机器，需要6个进程模拟，所以端口号也需要6个，可以从7001~7006； cluster-enabled：yes表示开启集群模式，存储方式aof，会将写操作记录到日志中。 cluster-config-file：定义一个文件，节点配置的一些信息，节点握手🤝、连接时间戳这些都保存在一个配置文件中，由redis创建和更新。每个集群节点都需要不用饿集群配置文件。 cluster-node-timeout：集群超时时间，单位毫秒，节点超过这个时间，依然无法建议通讯就可以判断是宕机了，如果可以的话需要启动从节点选举成主节点的机制。 bind：绑定本机网卡的ip地址，这个比较重要，如果bind127.0.0.1的话，即使集群所在的ip可达，外部服务不在同一ip下的话，是无法建立连接的。所以一般可以使用ipconfig或者ifconfig查看网卡的情况，选择合适的可达ip进行绑定。 遇到的坑 用redis-trib.rb搭建集群 redis-trib.rb是采用Ruby实现的Redis集群管理工具。内部通过Cluster相 关命令帮我们简化集群创建、检查、槽迁移和均衡等常见运维操作，使用之前需要安装Ruby依赖环境。但是网上的很多教程redis-trib.rb已经失效的，版本和Ruby环境不匹配。如果发现无法使用的话，请去GitHub的这个地址。Linux环境在安装完rubygem redis依赖之后可以执行以下命令来安装redis-trib.rb。 1sudo cp /&#123;redis_home&#125;/src/redis-trib.rb /usr/local/bin 登陆到集群上之后执行set key value命令之后可能会提示“Redirected to solt [xxxx] located at ip:port”并且跳转到其他节点 因为分片的机制，这个提示的意思是该key根据哈希算法得到slot是xxxx，这个slot应该分配在xxxx的所属区间，而不是当前节点，或者当前登陆的是salve节点，所以可能就会跳转到对应的master节点上。 You should use redis-cli instead 如果出现这个提示，表明原本的命令失效了，可以使用redis-cli命令 1./redis-cli --cluster create masterIp:masterPort ... can’t connect to redis-server 首先先确认你的Redis集群服务开启了没，然后判断是否是密码的问题，最可能的还是配置文件bind填写的问题，假如没有部署在一个ip下的话，是否写成了bind 127.0.0.1。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://matthew-han.github.io/tags/redis/"},{"name":"集群","slug":"集群","permalink":"https://matthew-han.github.io/tags/%E9%9B%86%E7%BE%A4/"}]},{"title":"Shiro在跨域请求中会遇到的302重定向问题","slug":"Shiro在跨域请求中会遇到的302重定向问题","date":"2019-11-04T01:42:48.000Z","updated":"2025-09-03T02:52:50.974Z","comments":true,"path":"post/67db7cc0-fea4-11e9-834c-4d127eed9f1a/","permalink":"https://matthew-han.github.io/post/67db7cc0-fea4-11e9-834c-4d127eed9f1a/","excerpt":"","text":"背景这边要开发一套带有权限认证的平台，懒得自己写拦截器，于是还是打算利用Shiro安全框架，由于采用的还是Cookie-Session那老一套，并没有封装成token暂时也不用考虑集群多实例共享session的问题，所以其实前端的每次请求报文都是需要携带cookie的，cookie里面的jsessionid就是验证对应服务端中的session-data能否匹配。但是这次联调处理并不顺利，还是在开发阶段就问题频出。 在CORS协议中，前端如果需要每次携带cookie，就得把withCredentials设置成true。所以在开发阶段我将配置类的Access-Control-Allow-Origin设置成*，Access-Control-Allow-Credentials设置成true。 但是在遇到PUT方法的接口（非预检请求）时，由于options类型的预检请求不带cookie所以被拦截在外。 非简单请求请求分为非简单请求和简单请求，其中预检请求就是导致我们联调发生的问题的原因。 非简单请求是那种对服务器有特殊要求的请求，比如请求方法是PUT或DELETE，或者Content-Type字段的类型是application/json。 非简单请求的CORS请求，会在正式通信之前，增加一次HTTP查询请求，称为”预检”请求（preflight）。 浏览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的XMLHttpRequest请求，否则就报错。 这里引用阮一峰的网络日志的一篇名为《跨域资源共享CORS详解》解释。当请求方法是PUT或DELETE，或者Content-Type字段的类型是application/json就会触发询问服务器的回应，要求服务器确认可以这样请求。 之前的配置类由于服务端未放行，导致触发错误。 解决方法我们将需要预检请求的方法&quot;OPTIONS&quot;.equals(request.getMethod())放行，同时把Access-Control-Allow-Headers和Access-Control-Allow-Origin设置成请求的HTTP头信息，这样可以保证都放行。实际的配置就是如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * @ClassName CorsFilterConfiguration * @Description 跨域资源共享 * @Author MatthewHan * @Date 2019/10/15 10:48 * @Version 1.0 **/@WebFilter(filterName = &quot;CorsFilterConfig &quot;)@Order(-100)@Component@ServletComponentScanpublic class CorsFilterConfig implements Filter &#123; private static final Logger logger = LoggerFactory.getLogger(CorsFilterConfig.class); private static String[] allowDomains = &#123;&quot;http://localhost:8080&quot;, &quot;http://localhost:80&quot;, &quot;http://ip:8080&quot;, &quot;http://ip:80&quot;&#125;; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; @Override public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; response.setHeader(&quot;Access-Control-Allow-Origin&quot;, request.getHeader(&quot;Origin&quot;)); response.setHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;); response.setHeader(&quot;Access-Control-Allow-Methods&quot;, &quot;POST,GET,PATCH,DELETE,PUT,OPTIONS&quot;); /* * 该字段可选，用来指定本次预检请求的有效期，单位为秒。上面结果中，有效期是1小时（3600秒）， * 即允许缓存该条回应3600秒（即1小时），在此期间，不用发出另一条预检请求。 */ response.setHeader(&quot;Access-Control-Max-Age&quot;, &quot;3600&quot;); response.setHeader(&quot;Access-Control-Allow-Headers&quot;, request.getHeader(&quot;Access-Control-Request-Headers&quot;)); response.setHeader(&quot;Content-Type&quot;,&quot;application/json;charset=UTF-8&quot;); // prefight请求 if (&quot;OPTIONS&quot;.equals(request.getMethod())) &#123; response.setStatus( 200 ); return; &#125; chain.doFilter(req, res); &#125; @Override public void destroy() &#123; &#125;&#125;","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Shiro","slug":"Shiro","permalink":"https://matthew-han.github.io/tags/Shiro/"},{"name":"CORS","slug":"CORS","permalink":"https://matthew-han.github.io/tags/CORS/"}]},{"title":"@CurrentUser注解新配方","slug":"CurrentUser注解新配方","date":"2019-10-29T09:13:19.000Z","updated":"2025-09-03T02:52:50.970Z","comments":true,"path":"post/592e1c90-fa2c-11e9-9168-d51acd3a11fc/","permalink":"https://matthew-han.github.io/post/592e1c90-fa2c-11e9-9168-d51acd3a11fc/","excerpt":"","text":"背景自定义@CurrentUser注解想实现当前已登录的用户对象在各层之间进行数据交互，在简书上有一篇比较出名的解决方法：通过自定义@CurrentUser获取当前登录用户 但是在安全框架Shiro中，通过webRequest.getAttribute(&quot;currentUser&quot;, RequestAttributes.SCOPE_REQUEST)却并不可行，👴也不⑧知道什么原因，也是按照该篇文章通过在登陆的业务中通过HttpServletRequest的request.setAttribute()方法存入需要的信息。 分析通过对下面的一段覆写代码，可以看出： 12345678910111213141516171819/** * 增加方法注入，将含有 @CurrentUser 注解的方法参数注入当前登录用户 */public class CurrentUserMethodArgumentResolver implements HandlerMethodArgumentResolver &#123; @Override public boolean supportsParameter(MethodParameter parameter) &#123; return parameter.getParameterType().isAssignableFrom(User.class) &amp;&amp; parameter.hasParameterAnnotation(CurrentUser.class); &#125; @Override public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception &#123; User user = (User) webRequest.getAttribute(&quot;currentUser&quot;, RequestAttributes.SCOPE_REQUEST); if (user != null) &#123; return user; &#125; throw new MissingServletRequestPartException(&quot;currentUser&quot;); &#125;&#125; 绑定了该注解@CurrentUser的解析器是通过实现HandlerMethodArgumentResolver接口，然后通过webRequest对象获取之前在request作用域中的currentUser。 那么这个NativeWebRequest是如何得到这个值的呢？我们打开它的源码，发现WebRequest是Spring框架提供的统一请求访问接口，不仅仅可以访问请求相关数据（如参数区数据、请求头数据，但访问不到Cookie区数据），还可以访问会话和上下文中的数据；NativeWebRequest继承了WebRequest，并提供访问本地Servlet API的方法。 12345678public interface RequestAttributes &#123; int SCOPE_REQUEST = 0; int SCOPE_SESSION = 1; String REFERENCE_REQUEST = &quot;request&quot;; String REFERENCE_SESSION = &quot;session&quot;; @Nullable Object getAttribute(String var1, int var2); 而ServletRequestAttributes的方法则是getAttribute()的实现，通过对scope的不同来控制作用域。 12345678910111213141516171819202122232425262728293031private final HttpServletRequest request;@Nullableprivate volatile HttpSession session;private final Map&lt;String, Object&gt; sessionAttributesToUpdate;// ...public Object getAttribute(String name, int scope) &#123; if (scope == 0) &#123; if (!this.isRequestActive()) &#123; throw new IllegalStateException(&quot;Cannot ask for request attribute - request is not active anymore!&quot;); &#125; else &#123; return this.request.getAttribute(name); &#125; &#125; else &#123; HttpSession session = this.getSession(false); if (session != null) &#123; try &#123; Object value = session.getAttribute(name); if (value != null) &#123; this.sessionAttributesToUpdate.put(name, value); &#125; return value; &#125; catch (IllegalStateException var5) &#123; &#125; &#125; return null; &#125;&#125; 当scope为RequestAttributes.SCOPE_REQUEST的时候getAttribute(name)方法会返回当前线程的HttpServletRequest的对象的getAttribute(name)的值。 当scope为RequestAttributes.SCOPE_REQUEST时会把session对象的getAttribute(name)的value存入Map&lt;String, Object&gt; sessionAttributesToUpdate中。 既然我之前没有从HttpServletRequest作用域中得到我想要的结果，那么为什么不试试利用session呢。我们可以在登陆的业务中将当前已登录的用户的信息存入session中。 1session.setAttribute(&quot;currentUser&quot;, currentUserDTO/token/id); 可以是当前登录对象的数据传输对象，也可以是token或者id。 1234@Overridepublic Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) &#123; return webRequest.getAttribute(&quot;currentUser&quot;, RequestAttributes.SCOPE_SESSION);&#125;","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://matthew-han.github.io/tags/Spring/"},{"name":"CurrentUser","slug":"CurrentUser","permalink":"https://matthew-han.github.io/tags/CurrentUser/"}]},{"title":"什么是领域模型？我们常用的贫血模型是否已经过时？","slug":"什么是领域模型？我们常用的贫血模型是否已经过时？","date":"2019-10-24T01:52:22.000Z","updated":"2025-09-03T02:52:50.977Z","comments":true,"path":"post/ebad3220-f600-11e9-a320-89dae6093596/","permalink":"https://matthew-han.github.io/post/ebad3220-f600-11e9-a320-89dae6093596/","excerpt":"","text":"本文转自知乎，作者：美团技术团队 前言至少30年以前，一些软件设计人员就已经意识到领域建模和设计的重要性，并形成一种思潮，Eric Evans将其定义为领域驱动设计（Domain-Driven Design，简称DDD）。在互联网开发“小步快跑，迭代试错”的大环境下，DDD似乎是一种比较“古老而缓慢”的思想。然而，由于互联网公司也逐渐深入实体经济，业务日益复杂，我们在开发中也越来越多地遇到传统行业软件开发中所面临的问题。本文就先来讲一下这些问题，然后再尝试在实践中用DDD的思想来解决这些问题。 问题过度耦合业务初期，我们的功能大都非常简单，普通的CRUD就能满足，此时系统是清晰的。随着迭代的不断演化，业务逻辑变得越来越复杂，我们的系统也越来越冗杂。模块彼此关联，谁都很难说清模块的具体功能意图是啥。修改一个功能时，往往光回溯该功能需要的修改点就需要很长时间，更别提修改带来的不可预知的影响面。 下图是一个常见的系统耦合病例： 订单服务接口中提供了查询、创建订单相关的接口，也提供了订单评价、支付、保险的接口。同时我们的表也是一个订单大表，包含了非常多字段。在我们维护代码时，牵一发而动全身，很可能只是想改下评价相关的功能，却影响到了创单核心路径。虽然我们可以通过测试保证功能完备性，但当我们在订单领域有大量需求同时并行开发时，改动重叠、恶性循环、疲于奔命修改各种问题。 上述问题，归根到底在于系统架构不清晰，划分出来的模块内聚度低、高耦合。 有一种解决方案，按照演进式设计的理论，让系统的设计随着系统实现的增长而增长。我们不需要作提前设计，就让系统伴随业务成长而演进。这当然是可行的，敏捷实践中的重构、测试驱动设计及持续集成可以对付各种混乱问题。重构——保持行为不变的代码改善清除了不协调的局部设计，测试驱动设计确保对系统的更改不会导致系统丢失或破坏现有功能，持续集成则为团队提供了同一代码库。 在这三种实践中，重构是克服演进式设计中大杂烩问题的主力，通过在单独的类及方法级别上做一系列小步重构来完成。我们可以很容易重构出一个独立的类来放某些通用的逻辑，但是你会发现你很难给它一个业务上的含义，只能给予一个技术维度描绘的含义。这会带来什么问题呢？新同学并不总是知道对通用逻辑的改动或获取来自该类。显然，制定项目规范并不是好的idea。我们又闻到了代码即将腐败的味道。 事实上，你可能意识到问题之所在。在解决现实问题时，我们会将问题映射到脑海中的概念模型，在模型中解决问题，再将解决方案转换为实际的代码。上述问题在于我们解决了设计到代码之间的重构，但提炼出来的设计模型，并不具有实际的业务含义，这就导致在开发新需求时，其他同学并不能很自然地将业务问题映射到该设计模型。设计似乎变成了重构者的自娱自乐，代码继续腐败，重新重构……无休止的循环。 用DDD则可以很好地解决领域模型到设计模型的同步、演化，最后再将反映了领域的设计模型转为实际的代码。 注：模型是我们解决实际问题所抽象出来的概念模型，领域模型则表达与业务相关的事实；设计模型则描述了所要构建的系统。 贫血症和失忆症 贫血领域对象贫血领域对象（Anemic Domain Object）是指仅用作数据载体，而没有行为和动作的领域对象。 在我们习惯了J2EE的开发模式后，Action&#x2F;Service&#x2F;DAO这种分层模式，会很自然地写出过程式代码，而学到的很多关于OO理论的也毫无用武之地。使用这种开发方式，对象只是数据的载体，没有行为。以数据为中心，以数据库ER设计作驱动。分层架构在这种开发模式下，可以理解为是对数据移动、处理和实现的过程。 以笔者最近开发的系统抽奖平台为例： 场景需求 奖池里配置了很多奖项，我们需要按运营预先配置的概率抽中一个奖项。实现非常简单，生成一个随机数，匹配符合该随机数生成概率的奖项即可。 贫血模型实现方案 先设计奖池和奖项的库表配置： 设计AwardPool和Award两个对象，只有简单的get和set属性的方法 12345678910111213141516171819class AwardPool &#123; int awardPoolId; List&lt;Award&gt; awards; public List&lt;Award&gt; getAwards() &#123; return awards; &#125; public void setAwards(List&lt;Award&gt; awards) &#123; this.awards = awards; &#125; ......&#125;class Award &#123; int awardId; int probability;//概率 ......&#125; Service代码实现 设计一个LotteryService，在其中的drawLottery()方法写服务逻辑 12345//sql查询，将数据映射到AwardPool对象AwardPool awardPool = awardPoolDao.getAwardPool(poolId);for (Award award : awardPool.getAwards()) &#123; // 寻找到符合award.getProbability()概率的award&#125; 按照我们通常思路实现，可以发现：在业务领域里非常重要的抽奖，我的业务逻辑都是写在Service中的，Award充其量只是个数据载体，没有任何行为。简单的业务系统采用这种贫血模型和过程化设计是没有问题的，但在业务逻辑复杂了，业务逻辑、状态会散落到在大量方法中，原本的代码意图会渐渐不明确，我们将这种情况称为由贫血症引起的失忆症。 更好的是采用领域模型的开发方式，将数据和行为封装在一起，并与现实世界中的业务对象相映射。各类具备明确的职责划分，将领域逻辑分散到领域对象中。继续举我们上述抽奖的例子，使用概率选择对应的奖品就应当放到AwardPool类中。 为什么选择DDD软件系统复杂性应对解决复杂和大规模软件的武器可以被粗略地归为三类：抽象、分治和知识。 分治 把问题空间分割为规模更小且易于处理的若干子问题。分割后的问题需要足够小，以便一个人单枪匹马就能够解决他们；其次，必须考虑如何将分割后的各个部分装配为整体。分割得越合理越易于理解，在装配成整体时，所需跟踪的细节也就越少。即更容易设计各部分的协作方式。评判什么是分治得好，即高内聚低耦合。 抽象 使用抽象能够精简问题空间，而且问题越小越容易理解。举个例子，从北京到上海出差，可以先理解为使用交通工具前往，但不需要一开始就想清楚到底是高铁还是飞机，以及乘坐他们需要注意什么。 知识 顾名思义，DDD可以认为是知识的一种。 DDD提供了这样的知识手段，让我们知道如何抽象出限界上下文以及如何去分治。 与微服务架构相得益彰微服务架构众所周知，此处不做赘述。我们创建微服务时，需要创建一个高内聚、低耦合的微服务。而DDD中的限界上下文则完美匹配微服务要求，可以将该限界上下文理解为一个微服务进程。 上述是从更直观的角度来描述两者的相似处。 在系统复杂之后，我们都需要用分治来拆解问题。一般有两种方式，技术维度和业务维度。技术维度是类似MVC这样，业务维度则是指按业务领域来划分系统。 微服务架构更强调从业务维度去做分治来应对系统复杂度，而DDD也是同样的着重业务视角。如果两者在追求的目标（业务维度）达到了上下文的统一，那么在具体做法上有什么联系和不同呢？ 我们将架构设计活动精简为以下三个层面： 业务架构——根据业务需求设计业务模块及其关系 系统架构——设计系统和子系统的模块 技术架构——决定采用的技术及框架 以上三种活动在实际开发中是有先后顺序的，但不一定孰先孰后。在我们解决常规套路问题时，我们会很自然地往熟悉的分层架构套（先确定系统架构），或者用PHP开发很快（先确定技术架构），在业务不复杂时，这样是合理的。 跳过业务架构设计出来的架构关注点不在业务响应上，可能就是个大泥球，在面临需求迭代或响应市场变化时就很痛苦。 DDD的核心诉求就是将业务架构映射到系统架构上，在响应业务变化调整业务架构时，也随之变化系统架构。而微服务追求业务层面的复用，设计出来的系统架构和业务一致；在技术架构上则系统模块之间充分解耦，可以自由地选择合适的技术架构，去中心化地治理技术和数据。 可以参见下图来更好地理解双方之间的协作关系： 如何实践DDD我们将通过上文提到的抽奖平台，来详细介绍我们如何通过DDD来解构一个中型的基于微服务架构的系统，从而做到系统的高内聚、低耦合。 首先看下抽奖系统的大致需求：运营——可以配置一个抽奖活动，该活动面向一个特定的用户群体，并针对一个用户群体发放一批不同类型的奖品（优惠券，激活码，实物奖品等）。用户-通过活动页面参与不同类型的抽奖活动。 设计领域模型的一般步骤如下： 根据需求划分出初步的领域和限界上下文，以及上下文之间的关系； 进一步分析每个上下文内部，识别出哪些是实体，哪些是值对象； 对实体、值对象进行关联和聚合，划分出聚合的范畴和聚合根； 为聚合根设计仓储，并思考实体或值对象的创建方式； 在工程中实践领域模型，并在实践中检验模型的合理性，倒推模型中不足的地方并重构。 战略建模战略和战术设计是站在DDD的角度进行划分。战略设计侧重于高层次、宏观上去划分和集成限界上下文，而战术设计则关注更具体使用建模工具来细化上下文。 领域现实世界中，领域包含了问题域和解系统。一般认为软件是对现实世界的部分模拟。在DDD中，解系统可以映射为一个个限界上下文，限界上下文就是软件对于问题域的一个特定的、有限的解决方案。 限界上下文 限界上下文一个由显示边界限定的特定职责。领域模型便存在于这个边界之内。在边界内，每一个模型概念，包括它的属性和操作，都具有特殊的含义。 一个给定的业务领域会包含多个限界上下文，想与一个限界上下文沟通，则需要通过显示边界进行通信。系统通过确定的限界上下文来进行解耦，而每一个上下文内部紧密组织，职责明确，具有较高的内聚性。 一个很形象的隐喻：细胞质所以能够存在，是因为细胞膜限定了什么在细胞内，什么在细胞外，并且确定了什么物质可以通过细胞膜。 划分限界上下文划分限界上下文，不管是Eric Evans还是Vaughn Vernon，在他们的大作里都没有怎么提及。 显然我们不应该按技术架构或者开发任务来创建限界上下文，应该按照语义的边界来考虑。 我们的实践是，考虑产品所讲的通用语言，从中提取一些术语称之为概念对象，寻找对象之间的联系；或者从需求里提取一些动词，观察动词和对象之间的关系；我们将紧耦合的各自圈在一起，观察他们内在的联系，从而形成对应的界限上下文。形成之后，我们可以尝试用语言来描述下界限上下文的职责，看它是否清晰、准确、简洁和完整。简言之，限界上下文应该从需求出发，按领域划分。 前文提到，我们的用户划分为运营和用户。其中，运营对抽奖活动的配置十分复杂但相对低频。用户对这些抽奖活动配置的使用是高频次且无感知的。根据这样的业务特点，我们首先将抽奖平台划分为C端抽奖和M端抽奖管理平台两个子域，让两者完全解耦。 在确认了M端领域和C端的限界上下文后，我们再对各自上下文内部进行限界上下文的划分。下面我们用C端进行举例。 产品的需求概述如下： 123451. 抽奖活动有活动限制，例如用户的抽奖次数限制，抽奖的开始和结束的时间等；2. 一个抽奖活动包含多个奖品，可以针对一个或多个用户群体；3. 奖品有自身的奖品配置，例如库存量，被抽中的概率等，最多被一个用户抽中的次数等等；4. 用户群体有多种区别方式，如按照用户所在城市区分，按照新老客区分等；5. 活动具有风控配置，能够限制用户参与抽奖的频率。 根据产品的需求，我们提取了一些关键性的概念作为子域，形成我们的限界上下文。 首先，抽奖上下文作为整个领域的核心，承担着用户抽奖的核心业务，抽奖中包含了奖品和用户群体的概念。 在设计初期，我们曾经考虑划分出抽奖和发奖两个领域，前者负责选奖，后者负责将选中的奖品发放出去。但在实际开发过程中，我们发现这两部分的逻辑紧密连接，难以拆分。并且单纯的发奖逻辑足够简单，仅仅是调用第三方服务进行发奖，不足以独立出来成为一个领域。 对于活动的限制，我们定义了活动准入的通用语言，将活动开始&#x2F;结束时间，活动可参与次数等限制条件都收拢到活动准入上下文中。 对于抽奖的奖品库存量，由于库存的行为与奖品本身相对解耦，库存关注点更多是库存内容的核销，且库存本身具备通用性，可以被奖品之外的内容使用，因此我们定义了独立的库存上下文。 由于C端存在一些刷单行为，我们根据产品需求定义了风控上下文，用于对活动进行风控。最后，活动准入、风控、抽奖等领域都涉及到一些次数的限制，因此我们定义了计数上下文。 可以看到，通过DDD的限界上下文划分，我们界定出抽奖、活动准入、风控、计数、库存等五个上下文，每个上下文在系统中都高度内聚。 上下文映射图在进行上下文划分之后，我们还需要进一步梳理上下文之间的关系。 康威（梅尔·康威）定律任何组织在设计一套系统（广义概念上的系统）时，所交付的设计方案在结构上都与该组织的沟通结构保持一致。 康威定律告诉我们，系统结构应尽量的与组织结构保持一致。这里，我们认为团队结构（无论是内部组织还是团队间组织）就是组织结构，限界上下文就是系统的业务结构。因此，团队结构应该和限界上下文保持一致。 梳理清楚上下文之间的关系，从团队内部的关系来看，有如下好处： 任务更好拆分，一个开发人员可以全身心的投入到相关的一个单独的上下文中； 沟通更加顺畅，一个上下文可以明确自己对其他上下文的依赖关系，从而使得团队内开发直接更好的对接。 从团队间的关系来看，明确的上下文关系能够带来如下帮助： 每个团队在它的上下文中能够更加明确自己领域内的概念，因为上下文是领域的解系统； 对于限界上下文之间发生交互，团队与上下文的一致性，能够保证我们明确对接的团队和依赖的上下游。 限界上下文之间的映射关系 合作关系（Partnership）：两个上下文紧密合作的关系，一荣俱荣，一损俱损。 共享内核（Shared Kernel）：两个上下文依赖部分共享的模型。 客户方-供应方开发（Customer-Supplier Development）：上下文之间有组织的上下游依赖。 遵奉者（Conformist）：下游上下文只能盲目依赖上游上下文。 防腐层（Anticorruption Layer）：一个上下文通过一些适配和转换与另一个上下文交互。 开放主机服务（Open Host Service）：定义一种协议来让其他上下文来对本上下文进行访问。 发布语言（Published Language）：通常与OHS一起使用，用于定义开放主机的协议。 大泥球（Big Ball of Mud）：混杂在一起的上下文关系，边界不清晰。 另谋他路（SeparateWay）：两个完全没有任何联系的上下文。 上文定义了上下文映射间的关系，经过我们的反复斟酌，抽奖平台上下文的映射关系图如下： 由于抽奖，风控，活动准入，库存，计数五个上下文都处在抽奖领域的内部，所以它们之间符合“一荣俱荣，一损俱损”的合作关系（PartnerShip，简称PS）。 同时，抽奖上下文在进行发券动作时，会依赖券码、平台券、外卖券三个上下文。抽奖上下文通过防腐层（Anticorruption Layer，ACL）对三个上下文进行了隔离，而三个券上下文通过开放主机服务（Open Host Service）作为发布语言（Published Language）对抽奖上下文提供访问机制。 通过上下文映射关系，我们明确的限制了限界上下文的耦合性，即在抽奖平台中，无论是上下文内部交互（合作关系）还是与外部上下文交互（防腐层），耦合度都限定在数据耦合（Data Coupling）的层级。 战术建模——细化上下文梳理清楚上下文之间的关系后，我们需要从战术层面上剖析上下文内部的组织关系。首先看下DDD中的一些定义。 实体当一个对象由其标识（而不是属性）区分时，这种对象称为实体（Entity）。例：最简单的，公安系统的身份信息录入，对于人的模拟，即认为是实体，因为每个人是独一无二的，且其具有唯一标识（如公安系统分发的身份证号码）。 在实践上建议将属性的验证放到实体中。 值对象当一个对象用于对事务进行描述而没有唯一标识时，它被称作值对象（Value Object）。例：比如颜色信息，我们只需要知道{“name”:”黑色”，”css”:”#000000”}这样的值信息就能够满足要求了，这避免了我们对标识追踪带来的系统复杂性。 值对象很重要，在习惯了使用数据库的数据建模后，很容易将所有对象看作实体。使用值对象，可以更好地做系统优化、精简设计。 它具有不变性、相等性和可替换性。 在实践中，需要保证值对象创建后就不能被修改，即不允许外部再修改其属性。在不同上下文集成时，会出现模型概念的公用，如商品模型会存在于电商的各个上下文中。在订单上下文中如果你只关注下单时商品信息快照，那么将商品对象视为值对象是很好的选择。 聚合根Aggregate(聚合）是一组相关对象的集合，作为一个整体被外界访问，聚合根（Aggregate Root）是这个聚合的根节点。 聚合是一个非常重要的概念，核心领域往往都需要用聚合来表达。其次，聚合在技术上有非常高的价值，可以指导详细设计。 聚合由根实体，值对象和实体组成。 如何创建好的聚合？ 边界内的内容具有一致性：在一个事务中只修改一个聚合实例。如果你发现边界内很难接受强一致，不管是出于性能或产品需求的考虑，应该考虑剥离出独立的聚合，采用最终一致的方式。 设计小聚合：大部分的聚合都可以只包含根实体，而无需包含其他实体。即使一定要包含，可以考虑将其创建为值对象。 通过唯一标识来引用其他聚合或实体：当存在对象之间的关联时，建议引用其唯一标识而非引用其整体对象。如果是外部上下文中的实体，引用其唯一标识或将需要的属性构造值对象。如果聚合创建复杂，推荐使用工厂方法来屏蔽内部复杂的创建逻辑。 聚合内部多个组成对象的关系可以用来指导数据库创建，但不可避免存在一定的抗阻。如聚合中存在List&lt;值对象&gt;，那么在数据库中建立1:N的关联需要将值对象单独建表，此时是有id的，建议不要将该id暴露到资源库外部，对外隐蔽。 领域服务一些重要的领域行为或操作，可以归类为领域服务。它既不是实体，也不是值对象的范畴。 当我们采用了微服务架构风格，一切领域逻辑的对外暴露均需要通过领域服务来进行。如原本由聚合根暴露的业务逻辑也需要依托于领域服务。 领域事件领域事件是对领域内发生的活动进行的建模。 抽奖平台的核心上下文是抽奖上下文，接下来介绍下我们对抽奖上下文的建模。 在抽奖上下文中，我们通过抽奖(DrawLottery)这个聚合根来控制抽奖行为，可以看到，一个抽奖包括了抽奖ID（LotteryId）以及多个奖池（AwardPool），而一个奖池针对一个特定的用户群体（UserGroup）设置了多个奖品（Award）。 另外，在抽奖领域中，我们还会使用抽奖结果（SendResult）作为输出信息，使用用户领奖记录（UserLotteryLog）作为领奖凭据和存根。 谨慎使用值对象 在实践中，我们发现虽然一些领域对象符合值对象的概念，但是随着业务的变动，很多原有的定义会发生变更，值对象可能需要在业务意义具有唯一标识，而对这类值对象的重构往往需要较高成本。因此在特定的情况下，我们也要根据实际情况来权衡领域对象的选型。 DDD工程实现在对上下文进行细化后，我们开始在工程中真正落地DDD。 模块模块（Module）是DDD中明确提到的一种控制限界上下文的手段，在我们的工程中，一般尽量用一个模块来表示一个领域的限界上下文。 如代码中所示，一般的工程中包的组织方式为{com.公司名.组织架构.业务.上下文.*}，这样的组织结构能够明确的将一个上下文限定在包的内部。 代码演示1 模块的组织： 12345import com.company.team.bussiness.lottery.*;//抽奖上下文import com.company.team.bussiness.riskcontrol.*;//风控上下文import com.company.team.bussiness.counter.*;//计数上下文import com.company.team.bussiness.condition.*;//活动准入上下文import com.company.team.bussiness.stock.*;//库存上下文 对于模块内的组织结构，一般情况下我们是按照领域对象、领域服务、领域资源库、防腐层等组织方式定义的。 代码演示2 模块的组织： 123456import com.company.team.bussiness.lottery.domain.valobj.*;//领域对象-值对象import com.company.team.bussiness.lottery.domain.entity.*;//领域对象-实体import com.company.team.bussiness.lottery.domain.aggregate.*;//领域对象-聚合根import com.company.team.bussiness.lottery.service.*;//领域服务import com.company.team.bussiness.lottery.repo.*;//领域资源库import com.company.team.bussiness.lottery.facade.*;//领域防腐层 每个模块的具体实现，我们将在下文中展开。 领域对象前文提到，领域驱动要解决的一个重要的问题，就是解决对象的贫血问题。这里我们用之前定义的抽奖（DrawLottery）聚合根和奖池（AwardPool）值对象来具体说明。 抽奖聚合根持有了抽奖活动的id和该活动下的所有可用奖池列表，它的一个最主要的领域功能就是根据一个抽奖发生场景（DrawLotteryContext），选择出一个适配的奖池，即chooseAwardPool方法。 chooseAwardPool的逻辑是这样的：DrawLotteryContext会带有用户抽奖时的场景信息（抽奖得分或抽奖时所在的城市），DrawLottery会根据这个场景信息，匹配一个可以给用户发奖的AwardPool。 代码演示3 DrawLottery： 12345678910111213141516171819202122232425262728293031323334353637package com.company.team.bussiness.lottery.domain.aggregate;import ...;public class DrawLottery &#123; private int lotteryId; //抽奖id private List&lt;AwardPool&gt; awardPools; //奖池列表 //getter &amp; setter public void setLotteryId(int lotteryId) &#123; if(id&lt;=0)&#123; throw new IllegalArgumentException(&quot;非法的抽奖id&quot;); &#125; this.lotteryId = lotteryId; &#125; //根据抽奖入参context选择奖池 public AwardPool chooseAwardPool(DrawLotteryContext context) &#123; if(context.getMtCityInfo()!=null) &#123; return chooseAwardPoolByCityInfo(awardPools, context.getMtCityInfo()); &#125; else &#123; return chooseAwardPoolByScore(awardPools, context.getGameScore()); &#125; &#125; //根据抽奖所在城市选择奖池 private AwardPool chooseAwardPoolByCityInfo(List&lt;AwardPool&gt; awardPools, MtCifyInfo cityInfo) &#123; for(AwardPool awardPool: awardPools) &#123; if(awardPool.matchedCity(cityInfo.getCityId())) &#123; return awardPool; &#125; &#125; return null; &#125; //根据抽奖活动得分选择奖池 private AwardPool chooseAwardPoolByScore(List&lt;AwardPool&gt; awardPools, int gameScore) &#123;...&#125;&#125; 在匹配到一个具体的奖池之后，需要确定最后给用户的奖品是什么。这部分的领域功能在AwardPool内。 代码演示4 AwardPool： 1234567891011121314151617181920212223242526272829303132package com.company.team.bussiness.lottery.domain.valobj;import ...;public class AwardPool &#123; private String cityIds;//奖池支持的城市 private String scores;//奖池支持的得分 private int userGroupType;//奖池匹配的用户类型 private List&lt;Awrad&gt; awards;//奖池中包含的奖品 //当前奖池是否与城市匹配 public boolean matchedCity(int cityId) &#123;...&#125; //当前奖池是否与用户得分匹配 public boolean matchedScore(int score) &#123;...&#125; //根据概率选择奖池 public Award randomGetAward() &#123; int sumOfProbablity = 0; for(Award award: awards) &#123; sumOfProbability += award.getAwardProbablity(); &#125; int randomNumber = ThreadLocalRandom.current().nextInt(sumOfProbablity); range = 0; for(Award award: awards) &#123; range += award.getProbablity(); if(randomNumber&lt;range) &#123; return award; &#125; &#125; return null; &#125;&#125; 与以往的仅有getter、setter的业务对象不同，领域对象具有了行为，对象更加丰满。同时，比起将这些逻辑写在服务内（例如Service），领域功能的内聚性更强，职责更加明确。 资源库领域对象需要资源存储，存储的手段可以是多样化的，常见的无非是数据库，分布式缓存，本地缓存等。资源库（Repository）的作用，就是对领域的存储和访问进行统一管理的对象。在抽奖平台中，我们是通过如下的方式组织资源库的。 代码演示5 Repository组织结构： 12345678//数据库资源import com.company.team.bussiness.lottery.repo.dao.AwardPoolDao;//数据库访问对象-奖池import com.company.team.bussiness.lottery.repo.dao.AwardDao;//数据库访问对象-奖品import com.company.team.bussiness.lottery.repo.dao.po.AwardPO;//数据库持久化对象-奖品import com.company.team.bussiness.lottery.repo.dao.po.AwardPoolPO;//数据库持久化对象-奖池import com.company.team.bussiness.lottery.repo.cache.DrawLotteryCacheAccessObj;//分布式缓存访问对象-抽奖缓存访问import com.company.team.bussiness.lottery.repo.repository.DrawLotteryRepository;//资源库访问对象-抽奖资源库 资源库对外的整体访问由Repository提供，它聚合了各个资源库的数据信息，同时也承担了资源存储的逻辑（例如缓存更新机制等）。 在抽奖资源库中，我们屏蔽了对底层奖池和奖品的直接访问，而是仅对抽奖的聚合根进行资源管理。代码示例中展示了抽奖资源获取的方法（最常见的Cache Aside Pattern）。 比起以往将资源管理放在服务中的做法，由资源库对资源进行管理，职责更加明确，代码的可读性和可维护性也更强。 代码演示6 DrawLotteryRepository： 123456789101112131415161718192021222324package com.company.team.bussiness.lottery.repo;import ...;@Repositorypublic class DrawLotteryRepository &#123; @Autowired private AwardDao awardDao; @Autowired private AwardPoolDao awardPoolDao; @AutoWired private DrawLotteryCacheAccessObj drawLotteryCacheAccessObj; public DrawLottery getDrawLotteryById(int lotteryId) &#123; DrawLottery drawLottery = drawLotteryCacheAccessObj.get(lotteryId); if(drawLottery!=null)&#123; return drawLottery; &#125; drawLottery = getDrawLotteyFromDB(lotteryId); drawLotteryCacheAccessObj.add(lotteryId, drawLottery); return drawLottery; &#125; private DrawLottery getDrawLotteryFromDB(int lotteryId) &#123;...&#125;&#125; 防腐层亦称适配层。在一个上下文中，有时需要对外部上下文进行访问，通常会引入防腐层的概念来对外部上下文的访问进行一次转义。 有以下几种情况会考虑引入防腐层： 需要将外部上下文中的模型翻译成本上下文理解的模型。 不同上下文之间的团队协作关系，如果是供奉者关系，建议引入防腐层，避免外部上下文变化对本上下文的侵蚀。 该访问本上下文使用广泛，为了避免改动影响范围过大。 如果内部多个上下文对外部上下文需要访问，那么可以考虑将其放到通用上下文中。 在抽奖平台中，我们定义了用户城市信息防腐层(UserCityInfoFacade)，用于外部的用户城市信息上下文（微服务架构下表现为用户城市信息服务）。 以用户信息防腐层举例，它以抽奖请求参数(LotteryContext)为入参，以城市信息(MtCityInfo)为输出。 代码演示7 UserCityInfoFacade： 123456789101112131415161718package com.company.team.bussiness.lottery.facade;import ...;@Componentpublic class UserCityInfoFacade &#123; @Autowired private LbsService lbsService;//外部用户城市信息RPC服务 public MtCityInfo getMtCityInfo(LotteryContext context) &#123; LbsReq lbsReq = new LbsReq(); lbsReq.setLat(context.getLat()); lbsReq.setLng(context.getLng()); LbsResponse resp = lbsService.getLbsCityInfo(lbsReq); return buildMtCifyInfo(resp); &#125; private MtCityInfo buildMtCityInfo(LbsResponse resp) &#123;...&#125;&#125; 领域服务上文中，我们将领域行为封装到领域对象中，将资源管理行为封装到资源库中，将外部上下文的交互行为封装到防腐层中。此时，我们再回过头来看领域服务时，能够发现领域服务本身所承载的职责也就更加清晰了，即就是通过串联领域对象、资源库和防腐层等一系列领域内的对象的行为，对其他上下文提供交互的接口。 我们以抽奖服务为例（issueLottery），可以看到在省略了一些防御性逻辑（异常处理，空值判断等）后，领域服务的逻辑已经足够清晰明了。 代码演示8 LotteryService： 12345678910111213141516171819202122232425package com.company.team.bussiness.lottery.service.implimport ...;@Servicepublic class LotteryServiceImpl implements LotteryService &#123; @Autowired private DrawLotteryRepository drawLotteryRepo; @Autowired private UserCityInfoFacade UserCityInfoFacade; @Autowired private AwardSendService awardSendService; @Autowired private AwardCounterFacade awardCounterFacade; @Override public IssueResponse issueLottery(LotteryContext lotteryContext) &#123; DrawLottery drawLottery = drawLotteryRepo.getDrawLotteryById(lotteryContext.getLotteryId());//获取抽奖配置聚合根 awardCounterFacade.incrTryCount(lotteryContext);//增加抽奖计数信息 AwardPool awardPool = lotteryConfig.chooseAwardPool(bulidDrawLotteryContext(drawLottery, lotteryContext));//选中奖池 Award award = awardPool.randomChooseAward();//选中奖品 return buildIssueResponse(awardSendService.sendAward(award, lotteryContext));//发出奖品实体 &#125; private IssueResponse buildIssueResponse(AwardSendResponse awardSendResponse) &#123;...&#125;&#125; 数据流转在抽奖平台的实践中，我们的数据流转如下图所示： 首先领域的开放服务通过信息传输对象（DTO）来完成与外界的数据交互；在领域内部，我们通过领域对象（DO）作为领域内部的数据和行为载体；在资源库内部，我们沿袭了原有的数据库持久化对象（PO）进行数据库资源的交互。同时，DTO与DO的转换发生在领域服务内，DO与PO的转换发生在资源库内。 与以往的业务服务相比，当前的编码规范可能多造成了一次数据转换，但每种数据对象职责明确，数据流转更加清晰。 上下文集成通常集成上下文的手段有多种，常见的手段包括开放领域服务接口、开放HTTP服务以及消息发布-订阅机制。 在抽奖系统中，我们使用的是开放服务接口进行交互的。最明显的体现是计数上下文，它作为一个通用上下文，对抽奖、风控、活动准入等上下文都提供了访问接口。同时，如果在一个上下文对另一个上下文进行集成时，若需要一定的隔离和适配，可以引入防腐层的概念。这一部分的示例可以参考前文的防腐层代码示例。 分离领域接下来讲解在实施领域模型的过程中，如何应用到系统架构中。 我们采用的微服务架构风格，与Vernon在《实现领域驱动设计》并不太一致，更具体差异可阅读他的书体会。 如果我们维护一个从前到后的应用系统： 下图中领域服务是使用微服务技术剥离开来，独立部署，对外暴露的只能是服务接口，领域对外暴露的业务逻辑只能依托于领域服务。而在Vernon著作中，并未假定微服务架构风格，因此领域层暴露的除了领域服务外，还有聚合、实体和值对象等。此时的应用服务层是比较简单的，获取来自接口层的请求参数，调度多个领域服务以实现界面层功能。 随着业务发展，业务系统快速膨胀，我们的系统属于核心时： 应用服务虽然没有领域逻辑，但涉及到了对多个领域服务的编排。当业务规模庞大到一定程度，编排本身就富含了业务逻辑（除此之外，应用服务在稳定性、性能上所做的措施也希望统一起来，而非散落各处），那么此时应用服务对于外部来说是一个领域服务，整体看起来则是一个独立的限界上下文。 此时应用服务对内还属于应用服务，对外已是领域服务的概念，需要将其暴露为微服务。 注：具体的架构实践可按照团队和业务的实际情况来，此处仅为作者自身的业务实践。除分层架构外，如CQRS架构也是不错的选择 以下是一个示例。我们定义了抽奖、活动准入、风险控制等多个领域服务。在本系统中，我们需要集成多个领域服务，为客户端提供一套功能完备的抽奖应用服务。这个应用服务的组织如下： 代码演示9 LotteryApplicationService： 123456789101112131415161718192021222324252627282930313233343536package ...;import ...;@Servicepublic class LotteryApplicationService &#123; @Autowired private LotteryRiskService riskService; @Autowired private LotteryConditionService conditionService; @Autowired private LotteryService lotteryService; //用户参与抽奖活动 public Response&lt;PrizeInfo, ErrorData&gt; participateLottery(LotteryContext lotteryContext) &#123; //校验用户登录信息 validateLoginInfo(lotteryContext); //校验风控 RiskAccessToken riskToken = riskService.accquire(buildRiskReq(lotteryContext)); ... //活动准入检查 LotteryConditionResult conditionResult = conditionService.checkLotteryCondition(otteryContext.getLotteryId(),lotteryContext.getUserId()); ... //抽奖并返回结果 IssueResponse issueResponse = lotteryService.issurLottery(lotteryContext); if(issueResponse!=null &amp;&amp; issueResponse.getCode()==IssueResponse.OK) &#123; return buildSuccessResponse(issueResponse.getPrizeInfo()); &#125; else &#123; return buildErrorResponse(ResponseCode.ISSUE_LOTTERY_FAIL, ResponseMsg.ISSUE_LOTTERY_FAIL) &#125; &#125; private void validateLoginInfo(LotteryContext lotteryContext)&#123;...&#125; private Response&lt;PrizeInfo, ErrorData&gt; buildErrorResponse (int code, String msg)&#123;...&#125; private Response&lt;PrizeInfo, ErrorData&gt; buildSuccessResponse (PrizeInfo prizeInfo)&#123;...&#125;&#125; 结语在本文中，我们采用了分治的思想，从抽象到具体阐述了DDD在互联网真实业务系统中的实践。通过领域驱动设计这个强大的武器，我们将系统解构的更加合理。 但值得注意的是，如果你面临的系统很简单或者做一些SmartUI之类，那么你不一定需要DDD。尽管本文对贫血模型、演进式设计提出了些许看法，但它们在特定范围和具体场景下会更高效。读者需要针对自己的实际情况，做一定取舍，适合自己的才是最好的。 本篇通过DDD来讲述软件设计的术与器，本质是为了高内聚低耦合，紧靠本质，按自己的理解和团队情况来实践DDD即可。 另外，关于DDD在迭代过程中模型腐化的相关问题，本文中没有提及，将在后续的文章中论述，敬请期待。 鉴于作者经验有限，我们对领域驱动的理解难免会有不足之处，欢迎大家共同探讨，共同提高。 参考书籍 Eric Evans.领域驱动设计.赵俐 盛海艳 刘霞等译.人民邮电出版社，2016.Vaughn Vernon.实现领域驱动设计.滕云译.电子工业出版社，2014. 作者简介文彬、子维，美团点评资深研发工程师，毕业于南京大学，现从事美团外卖营销相关的研发工作。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://matthew-han.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"领域模型","slug":"领域模型","permalink":"https://matthew-han.github.io/tags/%E9%A2%86%E5%9F%9F%E6%A8%A1%E5%9E%8B/"},{"name":"DDD","slug":"DDD","permalink":"https://matthew-han.github.io/tags/DDD/"},{"name":"架构模式","slug":"架构模式","permalink":"https://matthew-han.github.io/tags/%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%BC%8F/"}],"author":"美团技术团队"},{"title":"《码出高效》系列笔记（三）：异常与日志","slug":"《码出高效》系列笔记三：异常与日志","date":"2019-10-10T08:02:11.000Z","updated":"2025-09-03T02:52:50.976Z","comments":true,"path":"post/43892940-eb34-11e9-8e01-011debd96741/","permalink":"https://matthew-han.github.io/post/43892940-eb34-11e9-8e01-011debd96741/","excerpt":"","text":"良好的编码风格和完善统一的规约是最高效的方式。 前言本篇汲取了本书中较为精华的知识要点和实践经验加上读者整理，作为本系列里的第三篇章：异常与日志篇。 本系列目录： 《码出高效》系列笔记（一）：面向对象中的类 《码出高效》系列笔记（一）：面向对象中的方法 《码出高效》系列笔记（一）：面向对象中的其他知识点 《码出高效》系列笔记（二）：代码风格 《码出高效》系列笔记（三）：异常与日志 《码出高效》系列笔记（四）：数据结构与集合的框架 《码出高效》系列笔记（四）：数据结构与集合的数组和泛型 《码出高效》系列笔记（四）：元素的比较 走进JVM之内部布局 走进JVM之字节码与类加载 走进JVM之GC 异常处理异常程序时，需要解决以下3个问题： 哪里发生异常 谁来处理异常 如何处理异常 无论采用哪种方式处理异常，都严禁捕获异常后什么都不做或打印一行日志了事。 学会对任何事情提出质疑；思考问题相比之前会更加多维度的切入；工作上做一件事会考虑它的责任划分、职能问题、；更加谨慎了（也不知道是好是坏） 异常分类JDK中定义了一套完整的异常机制，所有异常都是Throwable的子类，分为Error（致命异常）和Exception（非致命异常）。其中Exception又分为checked（受检型异常）和unchecked（非受检型异常）。 checked异常与unchecked异常checked异常是需要在代码中显示处理的异常，否则会编译出错。 力所能及、坦然处置型。如发生未授权异常（UnAuthorizedException），程序可以跳转至权限申请页面。 unchecked异常是运行时异常，它们是都继承自RuntimeException，不需要程序进行显式的捕捉和处理，该类异常可以分为以下3类： 可预测型异常（Predicted Exception）：常见的大家都很熟悉包括IndexOutOfBoundsException、NullPointException等，此类异常不应该产生或者抛出，而应该提前做好边界检查、空指针判断处理等。显式的声明很蠢。 需捕捉异常（Caution Exception）：例如在使用Dubbo框架在进行RPC调用时产生的远程服务超时异常DubboTimeoutException，此类异常是客户端必须显示处理的异常，不应该出现因产生该异常而导致不可用的情况，一般处理方法是重试或者降级处理。 可透出异常（Ignored Exception）：主要是指框架或系统产生的且会自动处理的异常，而程序无需关心。例如Spring框架中抛出的NoSuchRequestHandlingMethodException异常，Spring框架会自己完成异常的处理，默认将自身抛出的异常自动映射到合适的状态码，比如启动防护机制跳转到404页面。 针对上图的结构，下面结合旅行的实例来说明一下异常分类。 第一，机场地震，属于不可抗力，对应异常分类中的Error。平时在出行时无需考虑该因素。 第二，堵车属于checked异常，应对这种异常，我们可以提前出发，或者改签机票。而飞机延误异常，虽然也需要check，但是我们无能为力，只能持续关注航班动态。 第三，忘带护照，可提前预测的异常，在出发前检查避免。去机场路上厕纸抛锚，突发异常难以预料，但是必须处理，属于需要捕获的异常，可以通过更换交通工具应对。检票机器故障属于可透出型异常，交由航空公司处理，我们无须关心。 try代码块try-catch-finally是处理程序异常的三部曲。当存在try时，可以只有catch代码块，也可以只有finally代码块，就是不能单独只有try这个光杆司令。 try代码块：监视代码执行过程，一旦发现发现异常则直接跳转至catch，如果没有catch，则直接跳转至finally。 catch代码块：可选执行的代码块，如果没有异常发生则不会执行；如果发现异常则进行处理或向上抛出。这一切都在catch代码块中执行。 finally代码块：必选执行的代码块，不管是否有异常产生，即使发生OutOfMemoryError也会执行，通常用于处理善后清理工作。如果finally代码块没有执行，那么有三种可能： 没有进入try代码块 进入try代码块，但是代码运行中出现了死循环或死锁状态 进入try代码块，但是执行了System.exit()操作 和return的关系finally是在return表达式运行后执行的，此时将要return的结果已经被暂存起来，待finally代码块执行结束后再将之前的暂存的结果返回。 打印的结果： 1234value = 101x = 1y = 11z = 101 以上的结果说明： 最后return的动作是由finally代码块中的return ++z完成的，所以方法返回的结果101。 语句return ++x中的++x被成功执行，所以运行结果是2。 如果有异常抛出，那么运行结果将会是y&#x3D;11，而x&#x3D;1。 finally代码块中使用return语句，使返回值的判断变得复杂，所以避免返回值不可控，我们不要在finally代码块中使用return语句。 try与锁的关系lock方法可能会抛出unchecked异常，如果放在try中，必然触发finally中的unlock方法执行。对未加锁的对象解锁会抛出unchecked异常。所以在try代码块之前调用lock方法，避免由于加锁失败导致finally调用unlock抛出异常。 123456789Lock lock = new XxxLock();preDo();try &#123; // 无论加锁是否成功，unlock都会被执行。 lock.lock(); doSomething();&#125; finally &#123; lock.unlock();&#125; 所以在try代码块之前调用lock方法，避免由于加锁失败导致finally调用unlock方法抛出异常。lock.lock();这段代码应该移到try的上方。 异常的抛与接 对外提供的开放接口，使用错误码； 公司内部跨应用远程服务调用优先考虑使用Result对象来封装错误码、错误描述、栈信息； 应用内部者推荐直接抛出异常对象。 个人习惯：无论是否自定义了异常类或者 handle，都应该做两点：根据实际情况选择是否输出、保留原始栈信息；向上转型成分类好的错误码和简要描述。 日志 日志有什么用就不用多说了吧 日志规范推荐的日志的命名方式：appName_logType_logName.log，其中logType位日志类型，推荐分类有status、monitor、visit等，logName为日志描述。日志的保存至少在15天，当然还是以实际情况为准。 日志的级别由低到高排序： DEBUG：记录对调试程序有帮助的信息。 INFO：记录程序运行现场，一般作用于对其他错误的指导意义。 WARN：也可记录程序运行现场，但是更偏向于表明此处有出现潜在错误的可能。 ERROR：表明此处发生了错误，需要被关注，但是当前发生的错误，并未影响系统的运行。 FATAL：表明当前程序运行出现了严重的错误事件，并且将会导致应用程序中断。 不同的级别，要有不同的处理方式。 预先判断日志的级别使用占位符的形式打印，避免字符串的拼接输出信息 1logger.info(&quot;id = &#123;&#125; and symbol = &#123;&#125;&quot;, id, symbol); 避免无效日志打印生产环境禁止DEBUG日志打印且有选择的输出INFO日志。避免重复打印，设置additivity&#x3D;false，示例如下： 1&lt;logger name = &quot;com.xxx.xxx.config&quot; additivity=&quot;false&quot;&gt; 区别对待错误日志一般设定ERROR级别的日志需要人为介入 保证记录内容完整 记录异常时一定要输出异常堆栈，例如logger.error(&quot;xxx&quot; + e.getMessage(), e);。 日志中如果输出对象实例，要确保实例类重写了toString方法，否则只会输出对象的hashCode的值，没有实际意义。 日志框架 现在ELK也非常流行，功能比较强大。 日志门面门面设计模式是面向对象设计模式中的一种，类似JDBC的概念。提供一套接口规范，本身不具备实现，目的是让使用者不用关注底层是哪个日志库。最广泛的有两种：slf4j和commons-logging。 日志库它是具体实现日志的相关功能，主流有三个，分别是log4j、log-jdk、logback。logback最晚出现，和log4j是同一个作者，是它的升级版并且本身就实现了slf4j的接口。 业界标准门面模式：slf4j+logback组合。 日志打印规范如下 1private static final Logger logger = LoggerFactory.getLogger(Xxx.class); logger被定义为static变量，是因为与当前的类绑定，避免每次都new一个新的对象，造成资源浪费，甚至引发OOM问题。 另外注意日志库冲突。例如：页面出现500错误，但是整个系统中未发现任务异常日志。由于是log4j作为当前日志库，但是间接地引入了logback日志库，导致打印日志的logger引用实际指向ch.qos.logback.classic.Logger对象，冲突导致日志打印失效。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://matthew-han.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Easy Coding","slug":"Easy-Coding","permalink":"https://matthew-han.github.io/tags/Easy-Coding/"},{"name":"异常","slug":"异常","permalink":"https://matthew-han.github.io/tags/%E5%BC%82%E5%B8%B8/"},{"name":"日志","slug":"日志","permalink":"https://matthew-han.github.io/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"D区","slug":"D区","date":"2019-09-17T06:34:49.000Z","updated":"2025-09-03T02:52:50.970Z","comments":true,"path":"post/3f573050-d915-11e9-9d5e-538baaf5d924/","permalink":"https://matthew-han.github.io/post/3f573050-d915-11e9-9d5e-538baaf5d924/","excerpt":"","text":"1“我上次是不得已啊...” “我是不要再做这个胃镜了。” … “好像大家都很怕这个胃镜啊...”我刨了两口饭。 当晚，胃灼、不适愈发明显。 手术台、注射剂、胃癌细胞一幕幕浮现我的眼前。 晚饭时刚聊完这个话题，就轮到我了吗？ 其实胃镜我很早就想做了，从小到大一直很瘦。小时候营养科去诊查过，微量元素也检测过并未发现有什么异常，只能默默归咎于体质和饮食。果然是肠胃不好吗？ 遂马上预约浙医二院第二天的精英门诊，即便平台提醒我初诊挂普通门诊就好。想着还是好好检查下胃吧，胃镜痛苦就痛苦了。挂完号之后大概是心理作用胃更加难受了。 “医生，我最近偶有胃部不适、微灼感，时长几天左右，半年就有这个情况，去药店吃药解决了。另外最近没有吃辣和刺激性的食物。” “嗯...那要不要做个胃肠镜？” 胃肠镜？肠镜这个好像有点超出了我的接受范围了，听说半小时到一小时不等。 “就先做个胃镜吧。” “预约个胃镜吧。” 门诊就这么几句话，毕竟是初诊，再有经验的医生也不能只凭你的几句描述就做出相应精确的诊断，尤其是消化内科，说了一大堆最后还是变成先做胃肠镜。精英门诊的初诊和普通门诊比就只是不用排很久的队而已。 2预约的周一下午，为保证胃镜的准确性，需要空腹8小时，禁饮4小时以上。 到达医院后望了一眼排队等待屏幕，普通胃镜的排队名单只有零星二三，而无痛胃镜下一大串名单，排队人数是普通的几倍。我顿时咽了咽口水，今天喉咙还有点不舒服，那我是不是还挺勇敢的？ 周围一半都是有家属陪同的老人👴👵，有些被搀扶着还颤颤巍巍即将送去做无痛胃肠镜。我突然想到了几十年后的我，如果年轻就不注意自己的身体的话，年老之后的痛苦会一一找上门吧。但是转念一想，有些人早晚刷牙使用牙线、冲牙器还是得了龋齿；有些人作息健康、坚持健身锻炼还是得了癌症；有些人烟酒都沾，还是能长命百岁。也许就是个患病风险大小的问题吧。 “一瓶油，一瓶药。这瓶油现在先喝，药等医生和你说再喝。” 我翻出楼下药房取得那瓶白色小瓶子，二甲硅油乳剂，混浊浓稠的液体。一开始还以为是涂抹在医疗器械上的，原来是口服的，心想这真的能喝吗。味道无味，非常的粘稠，查了下才知道一般用于检测前清洁胃肠道。不过另一瓶麻醉消化道的药就是真难喝了，比苦还要复杂一点的感觉，不过比起即将要面对的胃镜这点苦味似乎也不算什么了。为了更好地麻痹自己的喉咙，我还把药在口腔中逗留了一会儿，第一次把药喝得这么干净。 麻醉药很快就表现出药效，约莫二分钟就能感觉到已经无法正常咽喉咙和吞口水了，而且这时候强咽口水反而会有误入气管的风险，只得乖乖侧躺在病床等待。 “你怎么这么瘦？” “可能就是因为胃不太好才来看病，所以才这么瘦的啊。”又双叒叕一次回答了别人对我瘦的疑问。 胃镜的管子大概1厘米粗，头上有一闪一闪五颜六色的灯，应该是一个摄像头，说实话有点好看。在管子伸入你喉咙之前为了不让你的牙齿接触到，会有一个类似扩口器一样的道具让你咬住。 “放松，鼻子吸气嘴巴吐气。” “口区……” 管子刚进入喉咙的那一刻，是窒息的。身体本能抵抗的呕吐感强烈袭来，我尽管已经预想到了这种感觉，已经尽量控制绷紧自己的胸腔和肌肉还是止不住的干呕。我闭上双眼用右手抵住嘴巴上的道具为了不被我吐出，慢慢调整呼吸，尽量先用鼻子吸气吐气，可是节奏还是被剧烈的呕吐感打乱。 “口区……” 色情片的女星们果然还是很厉害啊！我突然体会到了女优们的不容易。大概干呕了两次之后，我设法转移我的注意力。管子移动也开始慢了起来，很快像是肾部位有捅感，不知道是不是是到了十二指肠了，这种感觉很奇妙，不痛不痒冰冰凉凉的。任由它在我身体内自由穿梭，通过慢吸慢呼后面基本在平静中度过。 整个过程5分钟，实际体验还以为只有3分钟。除开前面的干呕了二次让人感受到了死亡以外，后面的过程只要配合医生，掌握好呼吸节奏不要有吞咽的动作很快就可以结束，拔出管子的那一刻也没有任何不适。胃镜项目中医生还取胃窦小弯一块进行活检，用于一周之后的病理报告。 3所幸基本没什么问题，就是需要注意以后的饮食结构和规律了。","categories":[{"name":"点滴","slug":"点滴","permalink":"https://matthew-han.github.io/categories/%E7%82%B9%E6%BB%B4/"}],"tags":[{"name":"生活","slug":"生活","permalink":"https://matthew-han.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"轨迹","slug":"轨迹","permalink":"https://matthew-han.github.io/tags/%E8%BD%A8%E8%BF%B9/"},{"name":"日记","slug":"日记","permalink":"https://matthew-han.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"《码出高效》系列笔记（二）：代码风格","slug":"《码出高效》系列笔记二：代码风格","date":"2019-09-09T02:52:17.000Z","updated":"2025-09-03T02:52:50.976Z","comments":true,"path":"post/d5aea070-d2ac-11e9-ab1f-f97e9fd39695/","permalink":"https://matthew-han.github.io/post/d5aea070-d2ac-11e9-ab1f-f97e9fd39695/","excerpt":"","text":"良好的编码风格和完善统一的规约是最高效的方式。 前言本篇汲取了本书中较为精华的知识要点和实践经验加上读者整理，作为本系列里的第二篇章：代码风格篇。 本系列目录： 《码出高效》系列笔记（一）：面向对象中的类 《码出高效》系列笔记（一）：面向对象中的方法 《码出高效》系列笔记（一）：面向对象中的其他知识点 《码出高效》系列笔记（二）：代码风格 《码出高效》系列笔记（三）：异常与日志 《码出高效》系列笔记（四）：数据结构与集合的框架 《码出高效》系列笔记（四）：数据结构与集合的数组和泛型 《码出高效》系列笔记（四）：元素的比较 走进JVM之内部布局 走进JVM之字节码与类加载 走进JVM之GC 命名规约代码风格一般不会影响程序运行，通常与数据结构、逻辑表达无关。往往指代不可见字符的展示方式、代码元素的命名方式和代码注释风格等，但是却会隐藏潜在风险。虽然编码习惯不存在明显优劣之分，但是在团队开发效率上也许会是一个巨大的内耗，牺牲小我，成就大我，提升效能也许来的更关键。但是我们都是独一无二有灵魂有思想的个体，不是clone出来的机器人，难免在理解和习惯有所偏差，如何去统一部分习惯呢？这本《码出高效》最早就是以规约而出名，本人也遵循了本书的中的大部分规则用于日常的开发中，书中有很多点因为阿里大量业务经验的存在而比我们考虑规范周全得多，所以直接采用本书的一些“规定”往往会便捷的多。 命名符合本语言特性每种语言都有自己独特的命名风格，有些语言在定义时提倡以前缀来区分局部变量、全局变量、控件类型。比如li_count表示local int局部整型变量，dw_report表示data window用于暂时报表数据的控件，有些语言规定以下划线为前缀来进行命名。在Java中，所有代码元素的命名均不能以下划线或美元符号开始或结束。 命名体现代码元素特征 类名采用大驼峰形式（UpperCamelCase），一般为名词，例如：Object、StringBuffer、FileInputStream等。 方法名采用小驼峰形式（lowerCamelCase），一般为动词，与参数组成动宾结构，例如Object的wait()、StringBuffer的append(String)、FileInputStream的read()等。 变量包括参数、成员变量、局部变量等，也采用小驼峰形式。 常量的命名方式比较特殊，除了局部常量外字母全部大写，单词之间用下划线连接。 在Java命名时，以下列方式体现元素特征： 包名统一使用小写，点分隔符之间有且仅有一个自然语义的英文单词。包名统一使用单数形式，但是类名如果有复数含义，则可以使用复数形式。 抽象类命名是用Abstract或Base开头；异常类明明采用Exception结尾；测试类命名以它要测试的类名开始，以Test结尾。 类型与中括号紧挨着相连来定义数组，例如：String[] args。 枚举类名带上Enum后缀，枚举成员名称参考常量的命名方式。 命名最好望文知义从名称上就能理解某个词句的确切含义是坠吼滴，带到自解释的目的。 所以要避免不规范的缩写，比如condition缩写成condi、consumer缩写成cons，类似随意的缩写会严重降低代码的可理解性。 避免中文拼音、中英混合的方式，比如DaZePromotion（打折促销类）、PfmxBuilder（评分模型抽闲工厂类）。alibaba、baidu、taobao这类国际通用的名称，视为英文。 常量作为在作用域内保持不变的值，一般用final关键字进行修饰，根据作用域划分成：全局常量、类内常量、局部常量。 全局常量：指类的公开静态属性，使用public static final修饰。 类内常量：私有静态属性，使用private static final修饰， 局部常量分为方法常量和参数常量，前者是在方法或代码内定义的常量，后者是定义形式参数是，增加final标识，表示此参数值不能被修改。 123456789101112public class EasyCoding &#123; public static final String GLOBAL_CONSTANT = &quot;shared in global&quot;; public static final String CLASS_CONSTANT = &quot;shared in class&quot;; public void f(String a) &#123; final String methodConstant = &quot;shared in method&quot;; &#125; public void g(final int b) &#123; // 编译出错，不允许对常量参数进行重新赋值 b = 3; &#125;&#125; 常量在代码中具有穿透性，使用甚广，所以必须是一个恰当的命名并且保证长期使用。常量是为了干掉一些可能会在迭代中改变的魔法值，比如某业务中，12345五种代表着课程的审核状态，在团队规模小时口口相传加上注释可以保证不出错，但是在业务扩展的过程中会变得更加复杂（课程的等级状态也有12345五种，很容易混淆），则需要一套枚举类和全局常量类提高可读性来管理这些状态。 书中认为，系统成长到某个阶段后，重构是一种必然选择。优秀的架构设计不是去阻止未来一切重构的可能性，毕竟技术栈、业务方向和规模都在不断变化，二是尽量让重构来得晚一些，幅度小一些。 变量广义来说，在程序中变量是一切通过分配内存并赋值的量，分为不可变量（常量）和可变变量。变量命名需要满足小驼峰形式，体现业务含义即可。重点强调：在POJO类中，针对布尔类型的变量，命名不可以加is前缀。例如ORM映射关系中，数据库is_deleted字段，在类中不可以这样声明Boolean isDeleted;，因为getter方法也是isDeleted()，因为框架反向解析时会误以为对应的属性是deleted，导致获取不到属性，进而抛出异常。我们可以通过中添加下映射就vans辣！ 代码展示风格缩进、空格和空行像Python这种没有大括号的语言，对缩进的使用非常严格，Java虽然没有这么严格，但是井然有序的风格让review变得更加高效。 缩进：缩进表示层次对应关系，由于不同编辑器对Tab的解析不一致，而空格在编辑器中往往是兼容的，所以一般规定采用4个空格作为默认的缩进方式，当然现在IDE这么智能，早就不需要手打4个空格了，可以再Tab键和空格之间实现快速转换。其中IDEA设置Tab键为4个空格时，请勿勾选Use tab character；而在eclipse中，必须勾选Inset spaces for tabs。高版本的IDEA好像已经是默认4个空格代替tab缩进。 空格：空格用于分隔不同的的编程元素，空格使得各元素之间错落有致，方便定位。一般有如下规定： 任何二目、三目运算符的左右两边都必须加一个空格。 注释的双斜线与注释内容之间有且仅有一个空格。 方法参数在定义和传入时，多个参数逗号后面必须加空格。 没有必要增加若干空格使变量的赋值等号遇上一行对应位置的等号对齐。 如果是大括号内为空，那么简洁的写成{}即可，大括号中间无需换行和空格。 左右小括号与括号内部的相邻字符之间不要出现空格。 左大括号前需要加空格。 实例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class EasyCoding &#123; /** * 不需要等号的位置一致 */ public static String one = &quot;1&quot;; public static String two = &quot;2&quot;; public static Long three = 2L; public static String weChat = &quot;weChat&quot;; public static void main(String[] args) &#123; // 缩进4个空格，并且在try关键字与左大括号之间保留一个空格 try &#123; // 二目运算符的左右必须有一个空格 int count = 0; // 三目运算符的左右两边必须有一个空格，小括号相邻字符无需空格。 boolean condition = (count == 1) ? true : false; int num = (count == 0) ? 99 : -1; /** * if关键字与小括号之间保留一个空格 * 小括号与大括号之间保留一个空格 * 建议使用IDE的自动补全 */ if (condition) &#123; System.out.println(&quot;996&quot;); /** * if-else后无论逻辑复杂与否，都需要加上大括号，并且之间保留一个空格 * else不用换行 */ &#125; else &#123; System.out.println(&quot;965&quot;); &#125; // 多个实参逗号后面必须有一个空格 String fuckTheWorld = getStr(one, two); System.out.println(fuckTheWorld); // catch体是不应该出现空内容的，但是这里为了讲解需要。&#123;&#125;中无需换行和空格。 &#125; catch (Exception e) &#123;&#125; &#125; /** * 多个形参，逗号后面保留一个空格 * @param one * @param two * @return */ private static String getStr(String one, String two) &#123; // 任何二目运算符的左右必须有一个空格，包括赋值运算符，加号运算符。 return one + two; &#125;&#125; 空行：空行用来分隔功能相似、逻辑内聚、意思相近的代码片段，是的代码布局更加清晰。一般在如下地方可以添加空行： 方法定义 属性定义结束 不同逻辑 不同于一 不同业务 换行与高度 换行：单行字符不超过120个，超过必须要换行，换行遵循以下原则： 第二行相对第一行缩进4个空格，从第三行开始，不再继续缩进，参考示例 运算符与下文一起换行 方法调用的点符号与下文一起换行 方法调用中的多个参数需要换行时，在逗号后面换行 在括号前不要换行 12345StringBuffer sb = new StringBuffer();sb.append(&quot;我&quot;).append(&quot;要&quot;)... .append(&quot;正&quot;)... .append(&quot;能&quot;)... .append(&quot;量&quot;); 方法行数限制：方法是执行单位，也是阅读代码逻辑的最高粒度模块。代码逻辑要分为主次、个性与共性，抽取次要逻辑作为独立方法，共性逻辑抽取陈共性方法（日期、参数校验、权限判断）。约定单个方法的总行数不超过80行。 控制语句控制语句遵循如下约定： 在if、else、for、while、do-while等语句中必须使用大括号。即使只有一行代码，也要加上大括号。 在条件表达式中不允许有赋值操作，也不允许在判断表达式中出现复杂的逻辑组合。 1234// 反例：如下。if ((file.open(fileName, &quot;w&quot;) != null) &amp;&amp; (...) || (...)) &#123; ...&#125; 12345// 正例：而是应该赋值给一个布尔变量。final boolean existed = (file.open(fileName, &quot;w&quot;) != null) &amp;&amp; (...) || (...);if (existed) &#123; ...&#125; 多层嵌套不要超过3层。还记得太吾绘卷的一个if-else走天下吗？如果确实比较复杂的判断逻辑，可以采用卫语句、策略模式、状态模式来实现。其中卫语句即代码逻辑先考虑失败、异常、中断、退出等直接返回的情况，以方法多个出口的方式，解决代码中判断 分支嵌套的问题，这是逆向思维的体现。 12345678910111213public void func &#123; if (condition1) &#123; ... &#125; if (condition2) &#123; ... &#125; if (condition3) &#123; ... &#125; ... return;&#125; 避免采用取反逻辑运算符。判断x是否小于1，应该采用if (x &lt; 1)而不是if (!(x &gt;= 1))。 代码注释Javadoc规范类、类属性和类方法的注释必须遵循Javadoc规范，使用文档注释（&#x2F;** *&#x2F;）的格式。规范编写的注释，可以生成规范的JavaAPI文档，为外部用户提供有效支持。IDE也会自动提示所用到的类、方法的注释。 枚举类十分特殊，他的代码极为稳定。（我以前就有这个疑问，枚举类的一般的description属性加上name已经可以描述该枚举，为什么还要再加上注释。但是枚举类和全局常量一样，穿透性极强，而且在定义前就要深思熟虑，因为影响较大，所以注释是必须。） 注释的内容不仅限于解释属性值的含义，还可以包括注意事项、业务逻辑。（修改代码，可以加上修改和创建时间。） 枚举类的删除或者修改都存在很大的风险。（一般需要标注为过时属性，不可直接删除。） 简单注释包括单行和多行注释，特别强调此类注释不可写在代码后方，必须写在代码上方。双划线的注释与注释内容保留一个空格。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://matthew-han.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Easy Coding","slug":"Easy-Coding","permalink":"https://matthew-han.github.io/tags/Easy-Coding/"},{"name":"代码风格","slug":"代码风格","permalink":"https://matthew-han.github.io/tags/%E4%BB%A3%E7%A0%81%E9%A3%8E%E6%A0%BC/"},{"name":"系统规范","slug":"系统规范","permalink":"https://matthew-han.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%A7%84%E8%8C%83/"}]},{"title":"《码出高效》系列笔记（一）：面向对象中的其他知识点","slug":"《码出高效》系列笔记：面向对象之其他知识点","date":"2019-08-27T07:35:08.000Z","updated":"2025-09-03T02:52:50.976Z","comments":true,"path":"post/3239f2f0-c89d-11e9-89c4-bd64deffb20f/","permalink":"https://matthew-han.github.io/post/3239f2f0-c89d-11e9-89c4-bd64deffb20f/","excerpt":"","text":"良好的编码风格和完善统一的规约是最高效的方式。 前言本篇汲取了本书中较为精华的知识要点和实践经验加上读者整理，作为本系列里的第一篇章第三节：面向对象的其他知识点篇。 本系列目录： 《码出高效》系列笔记（一）：面向对象中的类 《码出高效》系列笔记（一）：面向对象中的方法 《码出高效》系列笔记（一）：面向对象中的其他知识点 《码出高效》系列笔记（二）：代码风格 《码出高效》系列笔记（三）：异常与日志 《码出高效》系列笔记（四）：数据结构与集合的框架 《码出高效》系列笔记（四）：数据结构与集合的数组和泛型 《码出高效》系列笔记（四）：元素的比较 走进JVM之内部布局 走进JVM之字节码与类加载 走进JVM之GC 同步与异步同步调用是刚性调用，是阻塞式操作，必须等待调用方法体执行结束。而异步调用是柔性调用，是非阻塞式操作。举个与我们息息相关的例子，git代码提交托管时，提交代码的操作是同步调用，需要实时返回给用户结果，但是当前库代码相关活动就不是时间敏感的，在提交代码时，发送一个消息到后台的缓存队列中，后台服务器定时消费这些消息即可。 覆写覆写是多态的一中表现，大部分人可能把它称为重写，我也遵循了本书的命名，重写可能暗示了推倒重来的过程，而覆写则更多的表达出重写一部分而覆盖。出现覆写的情况非常的多，POJO类toString()方法的覆写，工厂模式的抽象工厂类调用具体工厂子类的方法。通常这也被称作向上转型： 123Father father = new Son();// son 覆写了此方法father.doSomething(); 向上转型时，通过父类应用执行子类方法时需要注意以下两点： 无法调用到子类中存在而父类本身不存在的方法。 可以调用到子类中覆写了父类的方法，这是一种多态实现。 成功覆写父类方法，满足以下4个条件： 访问权限不能变小。具体表现为父类中public的方法，在子类继承覆写该方法时变成了private，则破坏了封装，编译也不会通过，所以不允许将访问权限缩小： 1234567891011121314151617181920class Father &#123; public void say() &#123; System.out.println(&quot;我要逃离这里。&quot;); &#125; protected void virus() &#123; System.out.println(&quot;2020，更加爱宁！&quot;) &#125;&#125;class Son extends Father &#123; // 编译报错 @Override private void say() &#123; System.out.println(&quot;用笔尖微颤歪歪扭扭的线条&quot;); &#125; // 编译通过 @Override public void virus() &#123; System.out.println(&quot;2020，病毒横行！&quot;); &#125;&#125; 返回类型能够向上转型称为父类的返回类型。 异常也要能向上转型成为父类的异常。unchecked异常（空指针异常这些）不需要显式的向上抛出，但是checked异常只能抛出异常或者此异常的子类。 方法名和参数类型以及个数必须严格一致。所以建议添加一个@Override注解，编译器会自动检查覆写方法签名是否一致。防止出现明明是要覆写该方法变成新的方法。@Override还可以避免控制权限修饰符可见范围引发的问题，比如Father类中的A方法，是无权限修饰符，Son类继承Father类但是不在一个包下，Son类直接覆写A方法，若是没有加上@Override注解，可能会被编译器认为是一个新的方法。 总结成口诀：「一大两小两同」。 一大：之类的方法访问权限控制符只能相同或者变大。 两小：抛出的异常和返回值只能变小，可以转型成父类对象。子类的返回值、抛出异常类型必须与父类的返回值、抛出异常类型存在继承关系。 两同：方法名和参数必须相同。 另外注意：子类和父类不要相互调用彼此的方法，不然会变成循环调用，最后直至JVM崩溃，产生StackOverflowError异常。 重载在同一个类中，如果多个方法有相同的方法名、不同的参数，即称为重载，比如一个POJO类中多个构造方法。以及String类中的valueOf，它有9个方法，可以将输入的基本数据类型、数组、Object等转化成为字符串。我们再回顾下方法签名的概念：方法名称+参数类型+参数个数，组成一个唯一键，成为方法签名，这个唯一键是⑧能重复的。JVM就是通过这个唯一键决定调用那种重载的方法。以下代码就是错误的重载方式，他们都有共同的特征，就是方法签名重复冲突了。 12345678910111213141516public class EasyCoding &#123; public void methodForOverload() &#123;&#125; // 编译出错，返回值并不是方法签名的一部分。 public final int methodForOverload() &#123;&#125; // 编译出错，访问权限控制符也不是方法签名的一部分。 private void methodForOverload() &#123;&#125; // 编译出错，静态标识符而不是方法签名的一部分。 public static void methodForOverload() &#123;&#125; // 编译出错，final标识符一样也⑧是方法签名的一部分。 public final void methodForOverload() &#123;&#125;&#125; 那么下面这几种情况，编译器是如何判断正确调用的呢，比如下面几种重载方法，第一处和第二处的结果是什么呢： 1234567891011121314151617181920212223242526public class EasyCoding &#123; public void methodForOverload(int arg) &#123; System.out.println(&quot;int&quot;); &#125; public void methodForOverload(Integer arg) &#123; System.out.println(&quot;Integer&quot;); &#125; public void methodForOverload(Integer... args) &#123; System.out.println(&quot;Integer...&quot;); &#125; public void methodForOverload(Object arg) &#123; System.out.println(&quot;Object&quot;); &#125; public static void main(String[] args)&#123; EasyCoding ec = new EasyCoding(); // 第一处 ec.methodForOverload(996); // 第二处 ec.methodForOverload(); &#125;&#125; 第一处答案是「int」，第二处的答案是「Integer…」。那么为什么ec.methodForOverload(996)方法编译器会匹配到methodForOverload(int arg)呢，而ec.methodForOverload()无参方法缺席的情况下却匹配到了可变参数methodForOverload(Integer... args)?可变参数的个数其实是从0个到多个，所以首先它也会和其他方法抢夺匹配ec.methodForOverload(996)，然而他的优先级是最低的，弟中弟嗷。但是在无参方法缺席的情况，只有他符合这一条件，所以ec.methodForOverload()无参方法自然匹配上。而int和Integer还有Object的较量中胜出的原因是不需要自动装箱，假如把int类型改成long类型，编译器一定也是Matchlong类型，而优于装箱的Interger。但是如果是methodForOverload(null)这种情况则会调用参数为Integer的方法，Null可以匹配任何类对象，从最底层一次向上查找，会找到Integer和Integer...这两个参数方法，但是会报错，因为他们同时Match上了。JVM在重载方法的顺序如下： 精确匹配。 如果是基本数据类型，自动转换成更大表示范围的基本类型。 通过自动拆箱和装箱。 通过子类向上转型继承路线依次匹配。 通过可变参数匹配。 我们程序猿心情不好的时候也会把气撒在编译器上，有时候，我们会不断挑战编译器的下限，比如这样： 123456789101112131415161718192021222324public class EasyCoding &#123; public void methodForOverload(int arg, Integer arg2) &#123; System.out.println(&quot;int arg, Integer arg2&quot;); &#125; public void methodForOverload(Integer arg, int arg2) &#123; System.out.println(&quot;Integer arg, int arg2&quot;); &#125; public void methodForOverload(int... args) &#123; System.out.println(&quot;int...&quot;); &#125; public void methodForOverload(Integer... args) &#123; System.out.println(&quot;Integer...&quot;); &#125; public static void main(String[] args)&#123; EasyCoding ec = new EasyCoding(); // 第一处 ec.methodForOverload(965,996); &#125;&#125; 此种方式就是完全在挑战编译器的底线了，虽然编译会通过，但是调用的时候一定会报错。 泛型泛型也许是很多人相对陌生的领域，但是它⑧是多么神秘，本质是类型参数化，解决不确定具体对象类型的问题。Java在引入泛型之前，表示可变类型往往存在类型安全的风险，举个例子，微波炉最主要的功能是加热食物，而食物也有几十几百种可能，所以一般会像下面这样写业务设计： 12345678910111213public class EasyCoding &#123; public static Object heat(Object food) &#123; System.out.println(food + &quot;isOK&quot;); return food; &#125; public static void main(String[] args) &#123; Meat m = new Meat(); m = (Meat) EasyCoding.heat(m); Soup s = new Soup(); s = (Soup) EasyCoding.heat(s); &#125;&#125; 这里的heat方法就是为了避免给每个类型的食物定义一个加热方法，但是只能采用“向上转型”的方式才能具备加热任意类型食物的能力。但是会让客户端困惑，因为对加热的内容不能正确区分，在取出时进行强制类型转换就会存在类型转换风险。而泛型就是为了解决这个而生。 泛型使用泛型可以定义在类、接口、方法中，编译器通过识别尖括号和尖括号内的字母来解析泛型。现在一般约定俗成的符号有： E：代表Element，用于集合中的元素。 T：代表the type of object，表示某个类。 K：代表Key。 V：代表Value，K和V用于键值对元素。 下面这段代码可以很好地说明泛型定义的概念： 12345678910111213141516171819public class EasyCoding&lt;T&gt; &#123; static &lt;String, T, Object&gt; String get(String arg1, Object arg2) &#123; System.out.println(arg1.getClass()); System.out.println(arg2.getClass()); return arg1; &#125; public static void main(String[] args) &#123; Integer arg1 = 996; Long arg2 = 965L; Integer result1 = get(arg1,arg2); byte[] b1 = new byte[666]; byte[] b2 = new byte[666]; byte[] result2 = get(b1,b2); &#125;&#125; 首先这段代码是完全可以通过编译的，可能没用过泛型的小伙伴会疑问为什么get()方法可以传入Integer和Long甚至是byte[]类型？而且返回的结果不应该是String类型吗？其实关键就在于&lt;String, T, Object&gt;这个泛型标识，String是我们常见的所熟知的包装类了，Object是所有类的父类，但是在泛型标识里，它就不是String和Object了，而是可以成为任意类型，属于完全未知的类型，入参的第一个参数如果是Integer类型，那么在方法体内的所有arg1就不是我们认知里的java.lang.String了，这个String就是相当于之前说明的T，Object也是一种T，仅仅只是一个代号。当然我们平时编码不会也不要这样去定义泛型，确实会容易引发歧义和造成其他问题。所以我应该注意以下几点： 尖括号里的每个元素都指代一种位置类型。&lt;String&gt;这里的String就不是我们认知上的java.lang.String了，仅仅只是个代号。包括类名后的&lt;T&gt;和get方法前的&lt;T&gt;是两个指代，互不影响。 尖括号的位置非常讲究，必须在类名之后或方法返回值之前。 泛型在定义处只具备执行Object方法的能力。所以arg1和arg2只能调用Object类中的方法，比如toString()。 对于编码之后的字节码指令，其实没有这些花头花脑的方法签名，充分说明了泛型只是一种编码时的语法检查。 所以之前微波炉加热食物的例子可以用泛型这样改写： 12345678910111213public class EasyCoding &#123; public static &lt;T&gt; T heat(T food) &#123; System.out.println(food.getClass()); System.out.println(food + &quot;isOK&quot;); return food; &#125; public static void main(String[] args) &#123; heat(new Meat()); heat(new Soup()); &#125;&#125; 避免使用Object作为输入和输出可以控制强制转换带来的风险。因为依据墨菲定律，只要这种风险存在，就一定会发生ClassCastException异常。 数据类型基本数据类型基本数据类型9种：int、short、long、float、double、char、boolean、byte、refvar，其中refvar是句柄，是面向对象中的引用变量，默认值为Null。详细如下表格： 类型名称 默认值 大小 最小值 最大值 包装类 缓存区域 boolean false 1B 0(flase) 1(true) Boolean 无 byte (byte)0 1B -128 127 Byte -128~127 char ‘\\u0000’ 2B ‘\\u0000’ ‘\\uFFFF’ Character (char)0~(char)127 short (short)0 2B -2^15 2^15-1(32767) Short -128~127 int 0 4B -2^31 2^31-1 Integer -128~127 long 0L 8B -2^63 2^63-1 Long -128~127 float 0.0f 4B 1.4e-45 3.4e+38 Float 无 double 0.0d 8B 4.9e-324 1.798e+308 Double 无 注意：其中缓存区间是个有意思的东西，估计很多人没有深究过，大厂面试很有可能就来这么一道题，所以接下来的包装类的内容要仔细看看哦~ 对象分为三块存储区域： 对象头。对象头占用12B，其中包括：哈希码、GC标记、GC次数、同步锁标记、偏向锁持有者（反正👴⑧是很懂）。 实例数据。存储本类对象的实例成员变量和所有可见的父类成员变量。 对齐填充。 包装类型包装类的存在是为了解决了基本数据类型无法做到的事情：泛型类型参数、序列化、类型转换、高频区间数据缓存。尤其是最后一个，因为除了Float和Double之外，其他包装类型都会缓存。拿Integer举例，缓存区间在-127~128，所以在这个区间的赋值，Integer对象会由IntegerCache.cache产生，就不会复用已有对象。因此，推荐所有包装类对象之间的比较，全都使用equals()方法。源码如下： 12345public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; 各个包装类的缓存区间： Boolean：使用静态final变量定义，valueOf()就是返回这两个静态值。 Byte：表示范围是-128~127，全部缓存。 Short：表示范围是-3276832767，缓存范围是-128127。 Charater：表示范围是065535，缓存范围是0127。 Long：表示范围是[-2^63,2^63-1]，缓存范围是-128~127。 Integer：表示范围hi[-2^31,2^31-1]。 接下来我们看看如果不使用equals()方法去进行包装类的比较会出现什么情况 123456789101112131415161718192021222324252627public static void main(String[] args) &#123; Integer i1 = 127; Integer i2 = 127; Integer i3 = 128; Integer i4 = 128; Long l1 = 127L; Long l2 = 127L; Long l3 = 128L; Long l4 = 128L; // 第一处 System.out.println(i1 == i2); System.out.println(i3 == i4); // 第二处 System.out.println(i1.equals(i2)); System.out.println(i3.equals(i4)); System.out.println(&quot;------------------&quot;); // 第三处 System.out.println(l1 == l2); System.out.println(l3 == l4); // 第四处 System.out.println(l1.equals(l2)); System.out.println(l3.equals(l4)); &#125; 以上代码四处打印的结果是不是让人觉得都是true？但是答案是第一处打印的结果是true和flase，第二处全是true，第三处也是true和flase，第四处全是true。那么为什么System.out.println(i1 == i2);的结果是true，而System.out.println(i3 == i4);是flase呢？该例很好地说明了Integer和Long只是缓存了-128~127之间的值，而大于或者小于区间的值没有被缓存，i3和i4是128，刚好超出了这个区间，下面的l3和l4同理。当然我们也可以修改包装类的缓存范围，在VM options加入参数-XX:AutoBoxCacheMax=7777，即可设置最大缓存值为7777，那么以上代码的打印结果全为true。 在选择使用包装类和基本类型的时候，也不能完全按照心情，我们可以从以下几点来看： 所有的POJO类属性必须使用包装数据类型。 RPC方法的返回值和参数必须使用包装数据类型。 所有的局部变量推荐使用基本数据类型。 字符串字符串是从堆上分配而来，算是基本数据类型的小弟。主要是三种：String、StringBuilder、StringBuffer。 String是只读字符串，典型的immutable对象，对它的任何改动，其实都是创建一个新对象，再把引用指向该对象。String对象赋值操作后，会在常量池中进行缓存，下次申请创建对象时，缓存中已经存在，则直接返回相应引用给调用者。 StringBuffer可以在原对象上进行修改，是线程安全的。 StringBuilder是非线程安全的，把多线程的锁的处理交给工程师（也就是宁👴）来处理，所以操作效率比较高。线程安全的对象的产生一般是因为计算机的发展总是从单线程到多线程，从单机到分布式。 字符串的连接方式在循环体内非常不推荐使用String类型相加，而是应该使用StringBuilder的append方法。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://matthew-han.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"面向对象","slug":"面向对象","permalink":"https://matthew-han.github.io/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"},{"name":"Easy Coding","slug":"Easy-Coding","permalink":"https://matthew-han.github.io/tags/Easy-Coding/"},{"name":"泛型","slug":"泛型","permalink":"https://matthew-han.github.io/tags/%E6%B3%9B%E5%9E%8B/"}]},{"title":"《码出高效》系列笔记（一）：面向对象中的方法","slug":"《码出高效》系列笔记：面向对象之方法","date":"2019-08-27T07:24:23.000Z","updated":"2025-09-03T02:52:50.977Z","comments":true,"path":"post/b1acf8e0-c89b-11e9-9ee1-01379c6f9115/","permalink":"https://matthew-han.github.io/post/b1acf8e0-c89b-11e9-9ee1-01379c6f9115/","excerpt":"","text":"良好的编码风格和完善统一的规约是最高效的方式。 前言本篇汲取了本书中较为精华的知识要点和实践经验加上读者整理，作为本系列里的第一篇章第二节：面向对象之方法篇。 本系列目录： 《码出高效》系列笔记（一）：面向对象中的类 《码出高效》系列笔记（一）：面向对象中的方法 《码出高效》系列笔记（一）：面向对象中的其他知识点 《码出高效》系列笔记（二）：代码风格 《码出高效》系列笔记（三）：异常与日志 《码出高效》系列笔记（四）：数据结构与集合的框架 《码出高效》系列笔记（四）：数据结构与集合的数组和泛型 《码出高效》系列笔记（四）：元素的比较 走进JVM之内部布局 走进JVM之字节码与类加载 走进JVM之GC 方法签名方法签名包括方法名称和参数列表，将JVM标识方法的唯一索引，不包括返回值，更加不包括访问权限控制符、异常类型等。 参数参数一般又分为实参和形参，在代码注释中用@param表示参数类型，属于方法签名的一部分，包含参数类型和参数个数，在代码风格中，约定每个逗号猴年必须要有一个空格，不管是形参和实参。想到有一次面试时，就问到了成员变量和局部变量的传递过程，虽然很简单，说明还是有一些面试官会注意到这些方面。 可变参数一种特殊的参数————可变参数。在JDK5版本中引进，在实际应用中不算多见，适用于不确定参数个数的场景。有时候我们需要打印多个变量或参数的时候，用字符串拼接并不是很省力的方式，我们可以利用format或者printf来进行格式化输出。其中PrintStream类中printf()方法就是使用了可变参数： 1234567public PrintStream printf(String format, Object... args) &#123; return format(format, args);&#125;// 第一处System.out.printf(&quot;%d&quot;, n);// 第二处System.out.printf(&quot;%d %s&quot;, n, &quot;str&quot;); 在第一处调用传入了两个参数，在第二处调用传入了三个参数，他们调用的都是printf(String format, Object... args)方法。这种方式即是语法糖，也可能是小恶魔，在实际开发中处理不当，容易影响代码可读性和可维护性，书中也建议不要使用Object作为可变参数。 123456789public static void late(Object... args) &#123; System.out.println(args.length);&#125;public static void main(String[] args) &#123; // 第一处，此处打印结果为2 late(4, new Integer[] &#123;1, 2, 3&#125;); // 第二处，此处打印结果为3 late(new Integer[] &#123;1, 2, 3&#125;);&#125; 由于Object参数过于灵活，在第一处new Integer[] &#123;1, 2, 3&#125;和4都转型成了Object[]，作为2个对象，在第二处则是作为3个int[]对象，所以不同类型的参数尽量避免使用该种方式传参。 入参保护入参保护是对服务提供商的保护，常见于批量接口。因为批量接口虽然能够处理一批数据，但其处理能力是有限的，因此要对入参的数据进行判断和控制，超出处理能力的，直接返回错误给客户端。 入参校验需要进行参数校验的场景： 调用频度低的方法。 执行时间开销很大的方法。此情形中，参数校验的时间相对于就是小开销了，但是如果遇到因为参数错误导致中间执行回退或者错误，则得不偿失。 需要极高稳定性和可用性的方法。 对外提供的开放接口。 敏感权限入口。 不需要参数校验的场景： 极有可能被循环调用的方法。但是在方法说明里必须注明外部参数检查。 底层调用平度较高的方法。由于是频度较高，反而不容易是参数问题而引发，一般DAO和SERVICE都在同一个应用中，部署在同一台服务器中，所以可以省略DAO的参数校验。 声明private只会被自己的代码调用的方法。如果能够确定调用方法的代码传入参数已经做过检查，一般就不太会出现这种问题，此时便可不需要参数校验。 构造方法构造方法是方法名与类名相同的特殊方法，在新建对象时调用，可以通过不同的构造方法实现不同方式的对象初始化，他有如下特征： 构造方法名称必须与类名相同。 构造方法是没有返回类型的，即使是void也不能有。他返回对象的地址，并赋值给引用变量。 构造方法不能被继承，不能被覆写，不能被直接调用。调用途径有三种：一是通过new关键字，二是在子类的构造方法中通过super关键字调用父类的构造方法（前面super关键字那里可以看下），三是通过反射方式获取。 类定义时提供了默认的无参构造方法。但是如果显式的定义了有参构造方法，此无参构造方法就会被覆盖。 构造方法可以私有。外部无法使用私有构造方法创建对象。 一个类可以有多个参数不同的构造方法，称为构造方法的重载。 类内方法在面向过程的语言中，所有的方法都是全局静态方法。在引入面向对象理念后，某些方法才归属于具体对象，即类内方法。除了构造方法外，还有三类方法：实例方法、静态方法、静态代码块。 实例方法又称为非静态方法，依附于某个对象，可以通过引用变量调用其方法。类内部各个实例方法互相调用，但是不包含this。实例方法可以调用静态变量和静态方法，当从外部创建对象后，应该尽量使用「类名.静态方法」来调用，而不是对象名，依赖为编译器减负，二来提升代码可读性。 静态方法又称为类方法。其中注意以下两点： 静态方法中不能使用实例成员变量和实例方法。 静态方法不能使用super和this关键字，这两个关键字指代的都是需要被创建出来的对象。 通常静态方法用于定义工具类的方法等，静态方法使用了可修改的对象，那么在并发时会存在线程安全问题。所以工具类常见静态方法和单例相伴而生。 静态代码块在书中是极不推荐的一种处理方式，这里就不提啦~ getter与setter这是一类比较特殊的方法，一般自身不包含任何业务逻辑，仅仅为了类成员属性提供读取和修改的方法，这样设计的好处就是： 满足面向对象语言封装的特性。将类成员属性设置成private，访问与修改统统交由getter与setter方法处理。 有利于统一控制。 以下情况不推荐使用 getter与setter中添加了业务逻辑。 同时定义isXxx()和getXxx()。 相同的属性名容易带来歧义。主要体现在子类与父类之间。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://matthew-han.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"面向对象","slug":"面向对象","permalink":"https://matthew-han.github.io/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"},{"name":"Easy Coding","slug":"Easy-Coding","permalink":"https://matthew-han.github.io/tags/Easy-Coding/"},{"name":"方法","slug":"方法","permalink":"https://matthew-han.github.io/tags/%E6%96%B9%E6%B3%95/"}]},{"title":"《码出高效》系列笔记（一）：面向对象中的类","slug":"《码出高效》系列笔记一","date":"2019-08-19T08:26:30.000Z","updated":"2025-09-03T02:52:50.975Z","comments":true,"path":"post/0bdf0b10-c25b-11e9-9d06-1f20e5bd3f76/","permalink":"https://matthew-han.github.io/post/0bdf0b10-c25b-11e9-9d06-1f20e5bd3f76/","excerpt":"","text":"良好的编码风格和完善统一的规约是最高效的方式。 前言虽然在GitHub有着17000+的star和大量的学习者，这本书即使涵盖的知识点对于很多入行较久developer来说并没有太大深入研究的价值，但是当时刚刚出炉的开发手册PDF精简版却一点一点的影响了我。也许是知乎上关注的技术话题下孤尽先生发布的回答吸引到了我，我开始注意到了平时编码中的那些事。 本篇汲取了本书中较为精华的知识要点和实践经验加上读者整理，作为本系列里的第一篇章第一节：面向对象之类篇。 本系列目录： 《码出高效》系列笔记（一）：面向对象中的类 《码出高效》系列笔记（一）：面向对象中的方法 《码出高效》系列笔记（一）：面向对象中的其他知识点 《码出高效》系列笔记（二）：代码风格 《码出高效》系列笔记（三）：异常与日志 《码出高效》系列笔记（四）：数据结构与集合的框架 《码出高效》系列笔记（四）：数据结构与集合的数组和泛型 《码出高效》系列笔记（四）：元素的比较 走进JVM之内部布局 走进JVM之字节码与类加载 走进JVM之GC 集成IDE《码出高效》不但有实体书，同时在IDE中有对应的插件，可以帮助你在实际开发中扫描代码编写存在的问题和可能会引发的隐患。 Intellij IDEA在Plugins中直接搜索alibaba，如图所示的第一个点击install即可，第二个名为cloud Toolkit是阿里中间件团队出品的Apache dubbo快速开发部署的插件，可以快速创建Apache Dubbo工程，阿里中间件团队博客。 在需要扫描的地方邮件，最后有个编码规约扫描，当然也可以将整个工程扫描。 扫描的结果，可以根据tips进行代码的整改，当然这个插件也没有那么智能，有些特定场景不需要这些提示，可以将自行定义。 面向对象 一切万物皆对象 面向过程让计算机有步骤地按照顺次做一件事情，是一种过程化的叙事思维。但是在大型软件开发中，流程互相穿插，模块互相耦合，往往牵一发动全身。面向对象就是计算机世界里解决复杂软件工程的方法论，拆解问题复杂度。 类 无类鬼 面向过程的结构相对松散，强调如何流程化地解决问题；面向对象的思维往往更加内聚，强调低耦合，高内聚，先抽象模型，定义共性行为，再解决实际问题。传统意义上，面向对象有三大特性：封装、继承、多态。在《码出高效》这本书中将抽象也作为面向对象的特性之一，进而成为四大特性。OOP（Object Oriented Programming） 第一特性封装：使模块之间的耦合度变低，增强复用性，更具有维护性。例如多个业务类中socket对象需要对请求消息体的对象转化成字节数组并且计算消息体长度，在多个业务类中分别去实现是不合适的，不但低效而且一旦需求变更将会更改大量的代码，抽象出共性的行为特征封装成专门维护请求消息对象的类才是正确的选择。 第二特性继承：在代码中广泛存在，子类继承父类，获得父类的部分属性和行为，也是增强复用性的体现。例如我们最常见的集合中的List，Set接口就是继承于Collection接口，而Collection则继承于Iterable接口。假如自定义的一个exception类，我们可以将它继承RuntimeException，通过super方法去个性化构建一个我们想要catch到的异常格式。 第三特性多态：多态使得模块在复用性的基础上更加具有扩展性，让运行期更具有想象空间。可以进行覆写Override和重载Overload就是很好地体现了多态的意义。前面篇章中的工厂模式也是很好体验了多态的作用。 第四特性抽象：抽象其实是完全囊括了以上三种特性，应该是所有程序员的核心素养之一。体现出程序员对业务的建模能力，以及对架构的宏观掌控力，从抽象到具体，逐步形象化的过程。比如Object类，是任何类的默认父类，是对万事万物的抽象，高度概括事物的自然行为和社会行为。我们在写代码中会常见到这些：getClass()是用来说明本质上是谁；toString()是当前名片；finalize()是再度向销毁时触发的方法；clone()是繁殖对象的一种方式；hashCode和equals()是判断你其他元素是否相等的身份证。 抽象类与接口 语法维度 抽象类 接口 定义关键字 abstract interface 子类继承或实现的关键字 extends extends 方法访问控制符 无限制 有限制，默认是public abstract类型 属性访问控制符 无限制 有限制，默认是public abstract类型 静态方法 可以有 不能有 static{静态代码块} 可以有 不能有 本类型之间扩展 单继承 多继承 本类型之间扩展的关键字 extends extends 总结：抽象类在被继承时体现的是is-a关系，而接口被实现时是can-do关系。抽象类可以包含抽象方法、属性变量、实体方法。抽象方法与接口一样，继承他的类必须要覆写实现。抽象类往往是用作同类食物的抽象，比如各类排行榜（常见的土豪排行榜、天台排行榜、天梯排行榜）他们中有着相似的特征。飞机会飞，鸟类也会飞，而fly()不应该被定义在抽象类中，因为飞机和鸟类除了都会飞以外很难再找到其他的共同特征。抽象类是模板式设计，类似一个模具，而接口是契约式设计，更像一个合同。 内部类在一个.java源文件中，只能定义一个类名与文件名完全一致的公开类，使用public class关键字来修饰，我们可以在这个类的内部和外部分别去定义另外的类，前者就叫内部类，后者叫外部类，内部类就成了这个类本身的一个属性，与其他属性的定义方式一致，可以使用public，private，protected访问权限关键字。可以定义成static静态内部类，当然类型也可以定义成class，interface和enum。 访问权限控制我们在讲到封装的时候往往不能忽略掉使用关键字来限制类外部对类内属性和方法的随意访问，那么在Java中访问权限主要分为以下四个等级 访问权限控制符 任何地方 包外子类 包内 类内 public OK OK OK OK protected NO OK OK OK 无 NO NO OK OK private NO NO NO OK public：可以修饰外部类、属性、方法，其他不详写了。 protected：只能修饰属性和方法，只能够被包内的类访问，当然还有一种情况就是只要是他的子类都可以访问。 无：这个比较陌生，Intellij IDEA有时会提示是否把一些只在包内访问的方法修改成无控制符。他并非是default，书中也明确说到定义外部类也极少用到无控制符的方式，一般要么定义public class，包外实例化；要么定义内部类，功能内聚。 private：修饰属性，方法，内部类，被其修饰过的属性或方法只能在该类访问，子类no way，包内外部类no way，包外without thinking。 在代码重构时，private方法过旧，可以直接删除，且无后顾之忧。但是删除一个public的方法就要谨慎小心地检查是否被调用。变量就像自己的小孩（我还没小孩），要尽量控制在自己的视线范围内，作用域太大，往往容易出现问题。因此，在定义类时，推荐访问控制级别从严处理： 如果不允许通过外部通过new创建对象，构造方法必须是private。 工具类不允许有public或者default构造方法。 类非static成员变量并且与子类共享，必须是protected。 类非static成员变量并且仅在本类使用，必须是private。 类static成员变量如果仅在本类使用，必须是private。 类static成员变量，必须考虑是否为final。 类成员方法只供类内部调用，必须是private。 类成员方法只对继承类公开，那么限制为protected。 this与super对象实例化时，至少有一条从本类到Object的通路，打通这一条路的工兵就是this和super，但是this和super往往是默默无闻的，在很多情况不需要显式的调用，比如： 本类方法调用本类属性 本类方法调用另一个本类方法 子类构造器隐含调用super() 子类基层的父类，而父类坚持不提供默认的无参构造方法，必须在本类的无参构造方法中使用super方法调用父类的有参构造方法，比如以下情形： 12345678class Father &#123; public Father(int arg) &#123;&#125;&#125;class Son extends Father &#123; public Son() &#123; super(123); &#125;&#125; 关键字 基本概念 查找范围 特异功能 this 访问本类属性和方法 先找本类，没有则找父类 单独使用时，表示当前对象 super 由子类访问父类中的实例属性和方法 直接查找父类 在子类覆写父类方法时，访问父类同名方法 共同点1 都是关键字，起指代作用 共同点2 在构造方法中必须出现在第一行 类关系5种类型： 继承：extends（is-a关系） 实现：implements（can-do关系） 组合：类是成员变量（contains-a关系） 聚合：类似成员变量（has-a关系） 依赖：import类（use-a关系） 类关系 英文名 description 权力强侧 示例说明 继承 Generalization 父类与子类之间的关系：is-a 父类方 舔狗继承于动物，完全符合里式代换 实现 Realization 接口与实现类之间的关系：can-do 接口方 舔狗实现了舔的接口行为 组合 Composition 比聚合更强的关系：contains-a 整体方 头只能是身体强组合的一部分，两者完全不可分，具有相同的生命周期 聚合 Aggregation 暂时组装的关系：has-a 组装方 小狗与项圈之间只是暂时的聚合的关系，项圈完全可以复用在另一条舔狗身上 依赖 Dependency 一个类用到另一个类：use-a 被依赖方 女神玩弄舔狗，舔狗作为参数传入，是一种依赖关系（这里是女神依赖舔狗哦，舔狗大翻身！） 序列化内存中的数据对象只有转换为二进制流才可以进行数据持久化和网络传输。将数据对象转换为二进制流的过程称为对象的序列化。反之，将二进制流恢复为数据对象的过程称为反序列化。序列化常见的场景是RPC框架的数据传输。常见的序列化方式有三种： Java原生序列化 Hessian序列化 JSON序列化","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://matthew-han.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"面向对象","slug":"面向对象","permalink":"https://matthew-han.github.io/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"},{"name":"类","slug":"类","permalink":"https://matthew-han.github.io/tags/%E7%B1%BB/"},{"name":"Easy Coding","slug":"Easy-Coding","permalink":"https://matthew-han.github.io/tags/Easy-Coding/"}]},{"title":"近期学习计划","slug":"8月近期学习计划","date":"2019-08-13T07:09:37.000Z","updated":"2025-09-03T02:52:50.970Z","comments":true,"path":"post/fae94450-bd9c-11e9-bafd-2904b28e3726/","permalink":"https://matthew-han.github.io/post/fae94450-bd9c-11e9-bafd-2904b28e3726/","excerpt":"","text":"2020年10月开始的学习计划 wdnmd SpringCloud全家桶 先学会使用吧，感觉没什么难度 NIO（Netty） 感觉这个很有趣 EasticSearch相关 梦开始的地方 Docker 重点系统学习 近期不打算花时间了 网红教你设计模式 持续更新 基本完成的计划 wdnmd JUC相关 关键字 Api 多线程、高并发 JVM相关 GC相关 类加载机制 内存模型 Spring源码 极客时间小马哥课程学习 《码出高效》笔记 规范代码风格整理 细节整理 知识点整理 Redis深入 《Redis开发与实战》书籍学习 极客时间学习 数据库 基本按照极客时间《MySQL45讲》来学习了。 B+树、基础巩固 日志系统 事务 LeetCode刷题 长期计划 [动态规划, 贪心, 位运算]重点巩固 只需要每天刷「每日一题」和有空参加下周赛即可 进度记录 // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts1980')); // 指定图表的配置项和数据 var option = { title: { text: \"近期计划\", x: \"center\", padding: 20 }, tooltip: { trigger: \"axis\" }, legend: { data: [\"期望投入\", \"实际投入\"], selectedMode: \"multiple\", x: \"left\", padding: 20, borderColor: \"#ccc\" }, toolbox: { show: true, feature: { mark: { show: true }, dataView: { show: true, readOnly: true }, magicType: { show: false, type: [\"line\", \"bar\"] }, restore: { show: true }, saveAsImage: { show: true } }, showTitle: true }, calculable: true, xAxis: [ { type: \"value\", boundaryGap: [0, 0.01] } ], yAxis: [ { type: \"category\", data: [\"SpringCloud全家桶\", \"NIO（Netty）\", \"EasticSearch相关\", \"JVM\", \"JUC\", \"Spring源码\", \"Redis\", \"数据库\", \"设计模式\", \"Docker\", \"《码出高效》笔记\", \"LeetCode\"] } ], series: [ { name: \"期望投入\", type: \"bar\", data: [6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 8, 8] }, { name: \"实际投入\", type: \"bar\", data: [6, 0, 0, 6, 6, 3, 4, 4, 2, 2, 8, 8] } ], grid: { x: 120 } } // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option);","categories":[{"name":"点滴","slug":"点滴","permalink":"https://matthew-han.github.io/categories/%E7%82%B9%E6%BB%B4/"}],"tags":[{"name":"学习计划","slug":"学习计划","permalink":"https://matthew-han.github.io/tags/%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/"}]},{"title":"千千万万设计模式之工厂模式","slug":"千千万万设计模式之工厂模式","date":"2019-08-01T07:57:25.000Z","updated":"2025-09-03T02:52:50.977Z","comments":true,"path":"post/faabc628-bd9c-11e9-b52a-878085b5c0f3/","permalink":"https://matthew-han.github.io/post/faabc628-bd9c-11e9-b52a-878085b5c0f3/","excerpt":"","text":"禁止私下搞对象，对象统一由工厂发放！ 血汗工厂的由来大家在写代码的时候都知道要注意解耦、增加复用性，但是偶尔也许会ctrl+c，ctrl+v大法来覆写代码片，包括Intellij IDEA编辑器发现有重复代码片也有用黄色波浪线来提醒。然而网上的教程都是如何教你去掉该死的黄色波浪线，1️⃣0️⃣🐭弟弟行为。实际上出现这种问题，你更应该去关注你的代码设计的是否合理，是否符合开闭原则，有共性的地方能否提取出来？工厂模式一共有三种，其中简单工厂模式是比较特殊的实现，首先它违背了开闭原则，根据工厂类的静态方法通过if...else...或者switch...case...来判断分支，一旦需要增减改分支都要去改代码。工厂模式是适用性最广也是应用最多的一种工厂模式，该模式强调，每一个对象都有一个对应管理的工厂（你的对象其实是工具人）。 工厂模式抽象类的解释一般我们需要对象时候，通常的做法是new一个对象，工厂模式则是强调由具体的工厂来生产一个对象给你使用。 首先最好解释一下抽象类，我当初就是一直不太能理解，可能对于很多初学者来说也是。简单来说，抽象类像是一个模板，比如说Apple的MacBook Pro产品线，基本上历年迭代一次。而最新2019年MacBook Pro产品线中，包含着几款配置不同的产品。这些产品的屏幕、键盘、CPU、内存、金属一体外壳是抽象出来的共同特征，每一款具体的产品都离不开这些属性。而不同型号的产品又存在差异化和卖点，比如15inch和13inch的屏幕，低中高配的CPU、显卡、存储，特有的touch bar和触控ID等等。 为了方便举例，我们理想化的认为这些不同型号产品的诞生都是由一个MacBook Pro模具从抽象到具体的过程，针对不同需求的人群差异化的结果。抽象类也是如此，它通过类的继承可以有不同版本的实现，不同版本都会做相应的增删改。 具体实现什么时候用工厂模式比较好？它能解决什么问题？ 其实我觉得就一句话，降低耦合度和批量化生产。 因为工厂模式是针对单一产品簇的对象，比如一类膨化食品、一类手机、一类blazer。这些产品不去麻烦客户而交给工厂去处理，之后产品大面积出现问题返厂或者迭代更新也都是各个工厂的事。 这里有4个关于工厂模式的角色概念，我用下图表示了他们之间的关系。 抽象工厂(Abstract Factory)角色：是工厂方法模式的核心，与应用程序无关。任何在模式中创建的对象的工厂类必须实现这个接口。 具体工厂(Concrete Factory)角色：这是实现抽象工厂接口的具体工厂类，包含与应用程序密切相关的逻辑，并且受到应用程序调用以创建某一种产品对象。 抽象产品(AbstractProduct)角色：工厂方法模式所创建的对象的超类型，也就是产品对象的共同父类或共同拥有的接口。 具体产品(Concrete Product)角色：这个角色实现了抽象产品角色所定义的接口。某具体产品有专门的具体工厂创建，它们之间往往一一对应。 123456789101112131415/** * @ClassName MacBookFactory * @Description MacBook的抽象工厂类 * @Author MatthewHan * @Date 2019/8/1 18:01 * @Version 1.0 **/public interface MacBookFactory &#123; /** * MacBook抽象工厂 * @return */ AbstractMacBookProduct createMacBook();&#125; MacBook的抽象工厂类，用于描述所有具体型号生产的MacBook工厂的抽象基类。 1234567891011121314151617181920212223242526/** * @ClassName AbstractMacBookProduct * @Description 所有MacBook抽象产品类，可以理解成各种型号的MacBook笔记本 * @Author MatthewHan * @Date 2019/8/1 18:02 * @Version 1.0 **/@Setter(value = AccessLevel.PUBLIC)@Getter(value = AccessLevel.PUBLIC)@ToString@AllArgsConstructor@NoArgsConstructorpublic abstract class AbstractMacBookProduct &#123; private String sn; private String type; private String display; private String keyboard; private String weight; private Double price; /** * 打印结账语 * @return */ public abstract String printSlogan();&#125; 一类MacBook产品的抽象产品，差异化的产品配置。 抽象二兄弟的实现比较简单，其中抽象工厂接口定义的是生产MacBook的方法，就像是和各个工厂之间签了一份略有差别的合同，那么在具体生产的工厂中需要严格按照这份合同执行。抽象产品类则是体现is-a关系，更像是把这类产品的雏形给雕琢出来的模具，是具体产品的爹，具体工厂按照合同去生产合规的产品。 12345678910111213141516171819202122232425/** * @ClassName MacBook13Factory * @Description MacBook 13-inch的具体工厂 * @Author MatthewHan * @Date 2019/8/2 09:12 * @Version 1.0 **/public class MacBook13Factory implements MacBookFactory &#123; @Override public AbstractMacBookProduct createMacBook() &#123; MacBook13Product macBook13 = new MacBook13Product(); macBook13.setSn(RandomUtil.getStr()); macBook13.setType(&quot;MacBook Pro 13-inch&quot;); macBook13.setDisplay(&quot;13-inch&quot;); macBook13.setKeyboard(&quot;new keyboard&quot;); macBook13.setPrice(999D); macBook13.setWeight(&quot;88kg&quot;); /* * 游戏大礼包竟然是！ * 《坦克大战乔碧萝》 */ macBook13.setGameGiftBag(&quot;《坦克大战乔碧萝》&quot;); return macBook13; &#125;&#125; 12345678910111213141516171819202122/** * @ClassName MacBook13Product * @Description MacBook 13-inch具体产品类 * @Author MatthewHan * @Date 2019/8/2 09:37 * @Version 1.0 **/@Setter(value = AccessLevel.PUBLIC)@Getter(value = AccessLevel.PUBLIC)@ToStringpublic class MacBook13Product extends AbstractMacBookProduct &#123; /** * 13-inch MacBook附赠游♂戏大礼包 */ private String gameGiftBag; @Override public String printSlogan() &#123; return &quot;This is your new MacBook 13-inch.&quot;; &#125;&#125; 13-inch MacBook的具体工厂和他生产的具体产品13-inch MacBook 13-inch MacBook具体工厂也按照`合同`和`模具`对MacBook进行批量生产组装加工，`MacBook13Product`通过`extend`的方式，完全继承了模具的属性和行为，其中《坦克大战乔碧萝》这个游戏礼包是该产品的特有属性。 123456789101112131415161718192021222324252627/** * @ClassName MacBook15Factory * @Description MacBook 15-inch具体工厂 * @Author MatthewHan * @Date 2019/8/2 09:30 * @Version 1.0 **/public class MacBook15Factory implements MacBookFactory &#123; @Override public AbstractMacBookProduct createMacBook() &#123; MacBook15Product macBook15 = new MacBook15Product(); macBook15.setSn(RandomUtil.getStr()); macBook15.setType(&quot;MacBook Pro 15-inch&quot;); macBook15.setDisplay(&quot;15-inch&quot;); macBook15.setKeyboard(&quot;new keyboard&quot;); macBook15.setPrice(1999D); macBook15.setWeight(&quot;88kg&quot;); /* * 蕴含着神秘力量的密码 * 带你找回丢失的纯真时光 */ macBook15.setCode(&quot;magnet:?xt=urn:btih:36AAB086D9AF39A323082CBAD452D6BDC42147D1&quot;); return macBook15; &#125;&#125; 1234567891011121314151617181920212223/** * @ClassName MacBook15Product * @Description MacBook 15-inch具体产品类 * @Author MatthewHan * @Date 2019/8/2 09:37 * @Version 1.0 **/@Setter(value = AccessLevel.PUBLIC)@Getter(value = AccessLevel.PUBLIC)@ToStringpublic class MacBook15Product extends AbstractMacBookProduct &#123; /** * 15-inch MacBook附赠的神秘代♂码 */ private String code; @Override public String printSlogan() &#123; return &quot;This is your new MacBook 15-inch.&quot;; &#125;&#125; 15-inch MacBook的具体工厂和他生产的具体产品15-inch MacBook 15-inch MacBook具体工厂也按照`合同`和`模具`对MacBook进行批量生产组装加工，`MacBook13Product`通过`extend`的方式，完全继承了模具的属性和行为，其中神秘代码是该产品的特有属性。 来测试一下这些代工厂996生产的产品到底合不合规： 123456789101112131415161718192021@Testpublic void createMacBook() &#123; /* * 抽象==================&gt;具体 */ MacBookFactory macBook13Factory = new MacBook13Factory(); /* * 13-inch MacBook实例化对象就由MacBook13Factory创建 */ AbstractMacBookProduct mac13WithMatthew = macBook13Factory.createMacBook(); /* * 具体工厂生产的对象与具体产品类实例化的产品 */ MacBook13Product c = new MacBook13Product(); assertEquals(c.getClass(), mac13WithMatthew.getClass()); System.out.println(mac13WithMatthew.getClass()); System.out.println(mac13WithMatthew.printSlogan()); System.out.println(mac13WithMatthew);&#125; 12345678910111213141516171819202122@Testpublic void createMacBook() &#123; /* * 抽象==================&gt;具体 */ MacBookFactory macBook15Factory = new MacBook15Factory(); /* * 15-inch MacBook实例化对象就由MacBook15Factory创建 */ AbstractMacBookProduct mac15WithMatthew = macBook15Factory.createMacBook(); /* * 具体工厂生产的对象与具体产品类实例化的产品 */ MacBook15Product c = new MacBook15Product(); assertEquals(c.getClass(), mac15WithMatthew.getClass()); System.out.println(mac15WithMatthew.getClass()); System.out.println(mac15WithMatthew.printSlogan()); System.out.println(mac15WithMatthew);&#125; System.out.println(mac13WithMatthew)打印的结果只有gameGiftBag是因为子类重写父类的toString()方法，如果把子类（MacBook13Product）的@ToString注解去掉的话，就是默认继承的父类（AbstractMacBookProduct）的toString()方法了。 避免滥用事实上，在SpringBoot中已经用到了不少设计模式，在单例模式那章讲过的Bean就用到了单例模式和今天讲的工厂模式（很怀念第一次使用Spring框架手写第一个Bean的时候），模板方法(Template Method)，Jdbctempldate、Redistemplate等等。但是切记一定不要过于拘泥与死板，为了设计模式而设计模式，忽略本身业务场景和实际情况。模式本身是对编程思想的扩展，我们在编写代码的时候还是要专注于业务本身，设计模式的初衷就是解决问题采用最优解，为了追求更高效率而诞生，保护需要加班的你。最靠谱的还是实践中慢慢总结，踩过的坑自己去总结、优化。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://matthew-han.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://matthew-han.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"工厂模式","slug":"工厂模式","permalink":"https://matthew-han.github.io/tags/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"}]},{"title":"Apache Maven标签详解","slug":"Apache-Maven标签详解","date":"2019-07-31T01:52:18.000Z","updated":"2025-09-03T02:52:50.970Z","comments":true,"path":"post/faabc62a-bd9c-11e9-b52a-878085b5c0f3/","permalink":"https://matthew-han.github.io/post/faabc62a-bd9c-11e9-b52a-878085b5c0f3/","excerpt":"","text":"现在真的空，能不能给我点任务？ 关于MavenApache Maven发布于2004年。目的是解决码农使用Ant所带来的一些问题。 Maven作为Java开发者最常用的构建工具之一，就相当于前端的npm和yarn，现在任何项目自动化对团队来说是非常普遍和重要的。大多数Java开发者对Maven来说是比较熟悉的了，因为在Spring框架覆盖几乎整个Java后端开发的环境里，很多时候复杂、晦涩的配置也有大量的共性，所以基本上可以演变成一部分人完成，几代人模仿使用。 虽然没用过Gradle，但是各大论坛的反映都是比Maven友好，构建越复杂Gradle的优势越明显，貌似Android开发基本都是使用Gradle，以后Gradle可能就是主流了呢。 Springboot提倡干掉XML，用Bean配置类注入的方式，而Maven的独立核心配置文件pom.xml依然是采用XML语言作为编写构建配置的文件格式，不过好在Maven中的pom.xml的还是比较好用的，除了&lt;build&gt;插件&lt;/build&gt;会麻烦点。 项目配置和标签解释Apache Maven官方文档：https://maven.apache.org/pom.html 我对于Maven的了解，也就停留在知其然而不知其所以然，连很多标签的含义都没有完全熟悉，之前travis-ci持续集成的过程中就因为Maven打包跳过javadoc环节出了问题而半天不清楚问题的源头在哪。不同类型的项目在初始化创建的过程中生成的pom.xml可能略有不同，下面拿实际的例子来解释。 生命周期&amp;基本命令 一共三套生命周期，每套生命周期都包含一些命令： clean：清理项目 clean：这个应该很熟悉，清理上一次构建生成的文件，在Intellij IDEA就相当于target（单个module编译后） default：构建项目 compile：编译项目主源码，将src/main/resources目录的内容经过处理后，复制到项目输出的主classpath目录中。 test：这个也应该很熟悉，使用单元测试框架运行测试，测试代码不会被打包或部署。 package：将编译好的代码，打包成可发布的格式。 install：发布到本地仓库 deploy：发布到远程仓库 verify：运行任何检查，验证包是否有效且达到质量标准。 validate：验证工程是否正确，所有需要的资源是否OK。 site：建立和发布项目 site：生成项目站点文档 package和install命令的看起来好像实现的功能都一样，都是编译打包，但是package命令其实进行了打包步骤，而install命令同时把打好的可执行包布署到本地Maven仓库，但没有布署到远程Maven私服仓库。假设B项目依赖A项目，A项目仅仅是package将发布的包发布在target下，这时候编译目标B项目，就会GG报找不到A项目依赖的问题~所以要先把A项目install发布在本地仓库后，即可编译（compile）、打包、部署。如下图该jar是我执行install命令后在本地仓库部署的结果。 自写的jar或者收费产品添加到本地仓库：mvn install:install-file -Dfile=$&#123;jar包的位置&#125; -DgroupId=$&#123;设置groupId&#125; -DartifactId=$&#123;设置artifactId&#125; -Dversion=$&#123;设置version&#125; -Dpackaging=jar。比如ojdbc6.jar添加到本地仓库。 12345&lt;dependency&gt; &lt;groupId&gt;com.oracle.ojdbc_6&lt;/groupId&gt; &lt;artifactId&gt;com.oracle.ojdbc_6&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt;&lt;/dependency&gt; 其他还有一些命令比较好用，比如mvn dependency:tree：打印依赖目录树。 依赖冲突项目中的多jar同时引用了相同的jar时，如果以来的版本不一致就可能产生依赖冲突。 由于Maven采用短路优先的策略，假如project--&gt;A--&gt;B--&gt;C(1.0)，project--&gt;D--&gt;C(1.1)那么实际最终依赖C的版本是1.1，因为他的依赖路径最短，那如果一样路径的情况下，则是声明优先，谁先被声明就优先被使用。一般来说，只要不是太久太老的依赖，出现这个问题还是好解决的，可以通过锁定版本一致，或者排除某个依赖。太旧的依赖容易造成版本一致却引起其他依赖无法正常工作。 为了营造这个冲突效果我特地试验了两个依赖，项目引入了5.1.8.RELEASE的spring-webmvc，同时引入了5.1.1.RELEASE的spring-security-web。可以看到spring-security-web的依赖关系是5.1.1.RELEASE的spring-security-core，并提示omitted for duplicate，因为spring-security-web的依赖路径较长，根据短路优先原则，所有相同的依赖被重写成了5.1.8.RELEASE版本。 依赖继承当一个项目比较大的时候，通常会拆分成多个module，多个module同时运行就称为聚合。 1234567&lt;modules&gt; &lt;module&gt;core&lt;/module&gt; &lt;module&gt;framework&lt;/module&gt; &lt;module&gt;market&lt;/module&gt; &lt;module&gt;payment&lt;/module&gt; &lt;module&gt;sender&lt;/module&gt;&lt;/modules&gt; 当这些被聚合的项目需要引入相同的jar时（这是很常见的事吧！），可以将这些jar写入父pom中，各个子项目继承该pom即可。 父pom：以下依赖将会被子pom继承~ 123456789&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.oracle.ojdbc_6&lt;/groupId&gt; &lt;artifactId&gt;com.oracle.ojdbc_6&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 子pom：父pom的坐标 12345&lt;parent&gt; &lt;groupId&gt;父pom所在项目的groupId&lt;/groupId&gt; &lt;artifactId&gt;父pom所在项目的artifactId&lt;/artifactId&gt; &lt;version&gt;父pom所在项目的版本号&lt;/version&gt;&lt;/parent&gt; 标签解释123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;!--父项目的坐标。如果项目中没有规定某个元素的值，那么父项目中的对应值即为项目的默认值。 坐标包括group ID，artifact ID和 version。--&gt; &lt;parent&gt; &lt;!--被继承的父项目的构件标识符--&gt; &lt;artifactId/&gt; &lt;!--被继承的父项目的全球唯一标识符--&gt; &lt;groupId/&gt; &lt;!--被继承的父项目的版本--&gt; &lt;version/&gt; &lt;!-- 父项目的pom.xml文件的相对路径。相对路径允许你选择一个不同的路径。默认值是../pom.xml。Maven首先在构建当前项目的地方寻找父项 目的pom，其次在文件系统的这个位置（relativePath位置），然后在本地仓库，最后在远程仓库寻找父项目的pom。--&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;!--声明项目描述符遵循哪一个POM模型版本。模型本身的版本很少改变，虽然如此，但它仍然是必不可少的，这是为了当Maven引入了新的特性或者其他模型变更的时候，确保稳定性。--&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!--项目的全球唯一标识符，通常使用全限定的包名区分该项目和其他项目。并且构建时生成的路径也是由此生成， 如com.mycompany.app生成的相对路径为：/com/mycompany/app--&gt; &lt;groupId&gt;cn.erhuowang&lt;/groupId&gt; &lt;!-- 构件的标识符，它和group ID一起唯一标识一个构件。换句话说，你不能有两个不同的项目拥有同样的artifact ID和groupID；在某个 特定的group ID下，artifact ID也必须是唯一的。构件是项目产生的或使用的一个东西，Maven为项目产生的构件包括：JARs，源 码，二进制发布和WARs等。--&gt; &lt;artifactId&gt;erhuowang-maven2&lt;/artifactId&gt; &lt;!--项目产生的构件类型，例如jar、war、ear、pom。插件可以创建他们自己的构件类型，所以前面列的不是全部构件类型--&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;!--项目当前版本，格式为:主版本.次版本.增量版本-限定版本号--&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--项目的名称, Maven产生的文档用--&gt; &lt;name&gt;erhuo-maven&lt;/name&gt; &lt;!--项目主页的URL, Maven产生的文档用--&gt; &lt;url&gt;http://erhuowang.cn&lt;/url&gt; &lt;!-- 项目的详细描述, Maven 产生的文档用。 当这个元素能够用HTML格式描述时（例如，CDATA中的文本会被解析器忽略，就可以包含HTML标 签）， 不鼓励使用纯文本描述。如果你需要修改产生的web站点的索引页面，你应该修改你自己的索引页文件，而不是调整这里的文档。--&gt; &lt;description&gt;A maven project to study maven.&lt;/description&gt; &lt;!--描述了这个项目构建环境中的前提条件。--&gt; &lt;prerequisites&gt; &lt;!--构建该项目或使用该插件所需要的Maven的最低版本--&gt; &lt;maven/&gt; &lt;/prerequisites&gt; &lt;!--项目名称和URL--&gt; &lt;issueManagement&gt; &lt;!--项目名字，--&gt; &lt;system&gt;erhuowang&lt;/system&gt; &lt;!--该项目使用的URL--&gt; &lt;url&gt;http://erhuowang.cn&lt;/url&gt; &lt;/issueManagement&gt; &lt;!--项目持续集成信息--&gt; &lt;ciManagement&gt; &lt;!--持续集成系统的名字，例如continuum--&gt; &lt;system/&gt; &lt;!--该项目使用的持续集成系统的URL（如果持续集成系统有web接口的话）。--&gt; &lt;url/&gt; &lt;!--构建完成时，需要通知的开发者/用户的配置项。包括被通知者信息和通知条件（错误，失败，成功，警告）--&gt; &lt;notifiers&gt; &lt;!--配置一种方式，当构建中断时，以该方式通知用户/开发者--&gt; &lt;notifier&gt; &lt;!--传送通知的途径--&gt; &lt;type/&gt; &lt;!--发生错误时是否通知--&gt; &lt;sendOnError/&gt; &lt;!--构建失败时是否通知--&gt; &lt;sendOnFailure/&gt; &lt;!--构建成功时是否通知--&gt; &lt;sendOnSuccess/&gt; &lt;!--发生警告时是否通知--&gt; &lt;sendOnWarning/&gt; &lt;!--不赞成使用。通知发送到哪里--&gt; &lt;address/&gt; &lt;!--扩展配置项--&gt; &lt;configuration/&gt; &lt;/notifier&gt; &lt;/notifiers&gt; &lt;/ciManagement&gt; &lt;!--项目创建年份，4位数字。当产生版权信息时需要使用这个值。--&gt; &lt;inceptionYear/&gt; &lt;!--项目相关邮件列表信息--&gt; &lt;mailingLists&gt; &lt;!--该元素描述了项目相关的所有邮件列表。自动产生的网站引用这些信息。--&gt; &lt;mailingList&gt; &lt;!--邮件的名称--&gt; &lt;name&gt;Demo&lt;/name&gt; &lt;!--发送邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建--&gt; &lt;post&gt;chaibozhou@163.com&lt;/post&gt; &lt;!--订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建--&gt; &lt;subscribe&gt;chaibozhou@163.com&lt;/subscribe&gt; &lt;!--取消订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建--&gt; &lt;unsubscribe&gt;chaibozhou@163.com&lt;/unsubscribe&gt; &lt;!--你可以浏览邮件信息的URL--&gt; &lt;archive&gt;chaibozhou@163.com&lt;/archive&gt; &lt;/mailingList&gt; &lt;/mailingLists&gt; &lt;!--项目开发者列表--&gt; &lt;developers&gt; &lt;!--某个项目开发者的信息--&gt; &lt;developer&gt; &lt;!--SCM里项目开发者的唯一标识符--&gt; &lt;id&gt;HELLO WORLD&lt;/id&gt; &lt;!--项目开发者的全名--&gt; &lt;name&gt;chaimm&lt;/name&gt; &lt;!--项目开发者的email--&gt; &lt;email&gt;chaibozhou@163.com&lt;/email&gt; &lt;!--项目开发者的主页的URL--&gt; &lt;url/&gt; &lt;!--项目开发者在项目中扮演的角色，角色元素描述了各种角色--&gt; &lt;roles&gt; &lt;role&gt;Project Manager&lt;/role&gt; &lt;role&gt;Architect&lt;/role&gt; &lt;/roles&gt; &lt;!--项目开发者所属组织--&gt; &lt;organization&gt;demo&lt;/organization&gt; &lt;!--项目开发者所属组织的URL--&gt; &lt;organizationUrl&gt;http://erhuowang.cn&lt;/organizationUrl&gt; &lt;!--项目开发者属性，如即时消息如何处理等--&gt; &lt;properties&gt; &lt;dept&gt;No&lt;/dept&gt; &lt;/properties&gt; &lt;!--项目开发者所在时区， -11到12范围内的整数。--&gt; &lt;timezone&gt;-5&lt;/timezone&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;!--项目的其他贡献者列表--&gt; &lt;contributors&gt; &lt;!--项目的其他贡献者。参见developers/developer元素--&gt; &lt;contributor&gt; &lt;name/&gt;&lt;email/&gt;&lt;url/&gt;&lt;organization/&gt;&lt;organizationUrl/&gt;&lt;roles/&gt;&lt;timezone/&gt;&lt;properties/&gt; &lt;/contributor&gt; &lt;/contributors&gt; &lt;!--该元素描述了项目所有License列表。 应该只列出该项目的license列表，不要列出依赖项目的 license列表。如果列出多个license，用户可以选择它们中的一个而不是接受所有license。--&gt; &lt;licenses&gt; &lt;!--描述了项目的license，用于生成项目的web站点的license页面，其他一些报表和validation也会用到该元素。--&gt; &lt;license&gt; &lt;!--license用于法律上的名称--&gt; &lt;name&gt;Apache 2&lt;/name&gt; &lt;!--官方的license正文页面的URL--&gt; &lt;url&gt;http://www.baidu.com/erhuwoang/LICENSE-2.0.txt&lt;/url&gt; &lt;!--项目分发的主要方式： repo，可以从Maven库下载 manual， 用户必须手动下载和安装依赖--&gt; &lt;distribution&gt;repo&lt;/distribution&gt; &lt;!--关于license的补充信息--&gt; &lt;comments&gt;A business-friendly OSS license&lt;/comments&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;!--SCM(Source Control Management)标签允许你配置你的代码库，供Maven web站点和其它插件使用。--&gt; &lt;scm&gt; &lt;!--SCM的URL,该URL描述了版本库和如何连接到版本库。欲知详情，请看SCMs提供的URL格式和列表。该连接只读。--&gt; &lt;connection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/banseon-maven2-trunk(dao-trunk) &lt;/connection&gt; &lt;!--给开发者使用的，类似connection元素。即该连接不仅仅只读--&gt; &lt;developerConnection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/dao-trunk &lt;/developerConnection&gt; &lt;!--当前代码的标签，在开发阶段默认为HEAD--&gt; &lt;tag/&gt; &lt;!--指向项目的可浏览SCM库（例如ViewVC或者Fisheye）的URL。--&gt; &lt;url&gt;http://svn.baidu.com/banseon&lt;/url&gt; &lt;/scm&gt; &lt;!--描述项目所属组织的各种属性。Maven产生的文档用--&gt; &lt;organization&gt; &lt;!--组织的全名--&gt; &lt;name&gt;demo&lt;/name&gt; &lt;!--组织主页的URL--&gt; &lt;url&gt;http://www.erhuowang.cn&lt;/url&gt; &lt;/organization&gt; &lt;!--构建项目需要的信息--&gt; &lt;build&gt; &lt;!--该元素设置了项目源码目录，当构建项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。--&gt; &lt;sourceDirectory/&gt; &lt;!--该元素设置了项目脚本源码目录，该目录和源码目录不同：绝大多数情况下，该目录下的内容 会被拷贝到输出目录(因为脚本是被解释的，而不是被编译的)。--&gt; &lt;scriptSourceDirectory/&gt; &lt;!--该元素设置了项目单元测试使用的源码目录，当测试项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。--&gt; &lt;testSourceDirectory/&gt; &lt;!--被编译过的应用程序class文件存放的目录。--&gt; &lt;outputDirectory/&gt; &lt;!--被编译过的测试class文件存放的目录。--&gt; &lt;testOutputDirectory/&gt; &lt;!--使用来自该项目的一系列构建扩展--&gt; &lt;extensions&gt; &lt;!--描述使用到的构建扩展。--&gt; &lt;extension&gt; &lt;!--构建扩展的groupId--&gt; &lt;groupId/&gt; &lt;!--构建扩展的artifactId--&gt; &lt;artifactId/&gt; &lt;!--构建扩展的版本--&gt; &lt;version/&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;!--当项目没有规定目标（Maven2 叫做阶段）时的默认值--&gt; &lt;defaultGoal/&gt; &lt;!--这个元素描述了项目相关的所有资源路径列表，例如和项目相关的属性文件，这些资源被包含在最终的打包文件里。--&gt; &lt;resources&gt; &lt;!--这个元素描述了项目相关或测试相关的所有资源路径--&gt; &lt;resource&gt; &lt;!-- 描述了资源的目标路径。该路径相对target/classes目录（例如$&#123;project.build.outputDirectory&#125;）。举个例 子，如果你想资源在特定的包里(org.apache.maven.messages)，你就必须该元素设置为org/apache/maven /messages。然而，如果你只是想把资源放到源码目录结构里，就不需要该配置。--&gt; &lt;targetPath/&gt; &lt;!--是否使用参数值代替参数名。参数值取自properties元素或者文件里配置的属性，文件在filters元素里列出。--&gt; &lt;filtering/&gt; &lt;!--描述存放资源的目录，该路径相对POM路径--&gt; &lt;directory/&gt; &lt;!--包含的模式列表，例如**/*.xml.--&gt; &lt;includes/&gt; &lt;!--排除的模式列表，例如**/*.xml--&gt; &lt;excludes/&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!--这个元素描述了单元测试相关的所有资源路径，例如和单元测试相关的属性文件。--&gt; &lt;testResources&gt; &lt;!--这个元素描述了测试相关的所有资源路径，参见build/resources/resource元素的说明--&gt; &lt;testResource&gt; &lt;targetPath/&gt;&lt;filtering/&gt;&lt;directory/&gt;&lt;includes/&gt;&lt;excludes/&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;!--构建产生的所有文件存放的目录--&gt; &lt;directory/&gt; &lt;!--产生的构件的文件名，默认值是$&#123;artifactId&#125;-$&#123;version&#125;。--&gt; &lt;finalName/&gt; &lt;!--当filtering开关打开时，使用到的过滤器属性文件列表--&gt; &lt;filters/&gt; &lt;!--子项目可以引用的默认插件信息。该插件配置项直到被引用时才会被解析或绑定到生命周期。给定插件的任何本地配置都会覆盖这里的配置--&gt; &lt;pluginManagement&gt; &lt;!--使用的插件列表 。--&gt; &lt;plugins&gt; &lt;!--plugin元素包含描述插件所需要的信息。--&gt; &lt;plugin&gt; &lt;!--插件在仓库里的group ID--&gt; &lt;groupId/&gt; &lt;!--插件在仓库里的artifact ID--&gt; &lt;artifactId/&gt; &lt;!--被使用的插件的版本（或版本范围）--&gt; &lt;version/&gt; &lt;!--是否从该插件下载Maven扩展（例如打包和类型处理器），由于性能原因，只有在真需要下载时，该元素才被设置成enabled。--&gt; &lt;extensions/&gt; &lt;!--在构建生命周期中执行一组目标的配置。每个目标可能有不同的配置。--&gt; &lt;executions&gt; &lt;!--execution元素包含了插件执行需要的信息--&gt; &lt;execution&gt; &lt;!--执行目标的标识符，用于标识构建过程中的目标，或者匹配继承过程中需要合并的执行目标--&gt; &lt;id/&gt; &lt;!--绑定了目标的构建生命周期阶段，如果省略，目标会被绑定到源数据里配置的默认阶段--&gt; &lt;phase/&gt; &lt;!--配置的执行目标--&gt; &lt;goals/&gt; &lt;!--配置是否被传播到子POM--&gt; &lt;inherited/&gt; &lt;!--作为DOM对象的配置--&gt; &lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;!--项目引入插件所需要的额外依赖--&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!--任何配置是否被传播到子项目--&gt; &lt;inherited/&gt; &lt;!--作为DOM对象的配置--&gt; &lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!--使用的插件列表--&gt; &lt;plugins&gt; &lt;!--参见build/pluginManagement/plugins/plugin元素--&gt; &lt;plugin&gt; &lt;groupId/&gt;&lt;artifactId/&gt;&lt;version/&gt;&lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt;&lt;phase/&gt;&lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!--在列的项目构建profile，如果被激活，会修改构建处理--&gt; &lt;profiles&gt; &lt;!--根据环境参数或命令行参数激活某个构建处理--&gt; &lt;profile&gt; &lt;!--构建配置的唯一标识符。即用于命令行激活，也用于在继承时合并具有相同标识符的profile。--&gt; &lt;id/&gt; &lt;!--自动触发profile的条件逻辑。Activation是profile的开启钥匙。profile的力量来自于它 能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。activation元素并不是激活profile的唯一方式。--&gt; &lt;activation&gt; &lt;!--profile默认是否激活的标志--&gt; &lt;activeByDefault/&gt; &lt;!--当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。--&gt; &lt;jdk/&gt; &lt;!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。--&gt; &lt;os&gt; &lt;!--激活profile的操作系统的名字--&gt; &lt;name&gt;Windows XP&lt;/name&gt; &lt;!--激活profile的操作系统所属家族(如 &#x27;windows&#x27;)--&gt; &lt;family&gt;Windows&lt;/family&gt; &lt;!--激活profile的操作系统体系结构 --&gt; &lt;arch&gt;x86&lt;/arch&gt; &lt;!--激活profile的操作系统版本--&gt; &lt;version&gt;5.1.2600&lt;/version&gt; &lt;/os&gt; &lt;!--如果Maven检测到某一个属性（其值可以在POM中通过$&#123;名称&#125;引用），其拥有对应的名称和值，Profile就会被激活。如果值 字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段--&gt; &lt;property&gt; &lt;!--激活profile的属性的名称--&gt; &lt;name&gt;mavenVersion&lt;/name&gt; &lt;!--激活profile的属性的值--&gt; &lt;value&gt;2.0.3&lt;/value&gt; &lt;/property&gt; &lt;!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活 profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。--&gt; &lt;file&gt; &lt;!--如果指定的文件存在，则激活profile。--&gt; &lt;exists&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/&lt;/exists&gt; &lt;!--如果指定的文件不存在，则激活profile。--&gt; &lt;missing&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/&lt;/missing&gt; &lt;/file&gt; &lt;/activation&gt; &lt;!--构建项目所需要的信息。参见build元素--&gt; &lt;build&gt; &lt;defaultGoal/&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath/&gt;&lt;filtering/&gt;&lt;directory/&gt;&lt;includes/&gt;&lt;excludes/&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;testResources&gt; &lt;testResource&gt; &lt;targetPath/&gt;&lt;filtering/&gt;&lt;directory/&gt;&lt;includes/&gt;&lt;excludes/&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;directory/&gt;&lt;finalName/&gt;&lt;filters/&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!--参见build/pluginManagement/plugins/plugin元素--&gt; &lt;plugin&gt; &lt;groupId/&gt;&lt;artifactId/&gt;&lt;version/&gt;&lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt;&lt;phase/&gt;&lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;plugins&gt; &lt;!--参见build/pluginManagement/plugins/plugin元素--&gt; &lt;plugin&gt; &lt;groupId/&gt;&lt;artifactId/&gt;&lt;version/&gt;&lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt;&lt;phase/&gt;&lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径--&gt; &lt;modules/&gt; &lt;!--发现依赖和扩展的远程仓库列表。--&gt; &lt;repositories&gt; &lt;!--参见repositories/repository元素--&gt; &lt;repository&gt; &lt;releases&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;id/&gt;&lt;name/&gt;&lt;url/&gt;&lt;layout/&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!--发现插件的远程仓库列表，这些插件用于构建和报表--&gt; &lt;pluginRepositories&gt; &lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素--&gt; &lt;pluginRepository&gt; &lt;releases&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;id/&gt;&lt;name/&gt;&lt;url/&gt;&lt;layout/&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。--&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!--不赞成使用. 现在Maven忽略该元素.--&gt; &lt;reports/&gt; &lt;!--该元素包括使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。参见reporting元素--&gt; &lt;reporting&gt; ...... &lt;/reporting&gt; &lt;!--参见dependencyManagement元素--&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!--参见distributionManagement元素--&gt; &lt;distributionManagement&gt; ...... &lt;/distributionManagement&gt; &lt;!--参见properties元素--&gt; &lt;properties/&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径--&gt; &lt;modules/&gt; &lt;!--发现依赖和扩展的远程仓库列表。--&gt; &lt;repositories&gt; &lt;!--包含需要连接到远程仓库的信息--&gt; &lt;repository&gt; &lt;!--如何处理远程仓库里发布版本的下载--&gt; &lt;releases&gt; &lt;!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --&gt; &lt;enabled/&gt; &lt;!--该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。--&gt; &lt;updatePolicy/&gt; &lt;!--当Maven验证构件校验文件失败时该怎么做：ignore（忽略），fail（失败），或者warn（警告）。--&gt; &lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;!-- 如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的 策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --&gt; &lt;snapshots&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;!--远程仓库唯一标识符。可以用来匹配在settings.xml文件里配置的远程仓库--&gt; &lt;id&gt;banseon-repository-proxy&lt;/id&gt; &lt;!--远程仓库名称--&gt; &lt;name&gt;banseon-repository-proxy&lt;/name&gt; &lt;!--远程仓库URL，按protocol://hostname/path形式--&gt; &lt;url&gt;http://192.168.1.169:9999/repository/&lt;/url&gt; &lt;!-- 用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然 而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。--&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!--发现插件的远程仓库列表，这些插件用于构建和报表--&gt; &lt;pluginRepositories&gt; &lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素--&gt; &lt;pluginRepository&gt; ...... &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!--依赖的group ID--&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;!--依赖的artifact ID--&gt; &lt;artifactId&gt;maven-artifact&lt;/artifactId&gt; &lt;!--依赖的版本号。 在Maven 2里, 也可以配置成版本号的范围。--&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;!-- 依赖类型，默认类型是jar。它通常表示依赖的文件的扩展名，但也有例外。一个类型可以被映射成另外一个扩展名或分类器。类型经常和使用的打包方式对应， 尽管这也有例外。一些类型的例子：jar，war，ejb-client和test-jar。如果设置extensions为 true，就可以在 plugin里定义新的类型。所以前面的类型的例子不完整。--&gt; &lt;type&gt;jar&lt;/type&gt; &lt;!-- 依赖的分类器。分类器可以区分属于同一个POM，但不同构建方式的构件。分类器名被附加到文件名的版本号后面。例如，如果你想要构建两个单独的构件成 JAR，一个使用Java 1.4编译器，另一个使用Java 6编译器，你就可以使用分类器来生成两个单独的JAR构件。--&gt; &lt;classifier&gt;&lt;/classifier&gt; &lt;!--依赖范围。在项目发布过程中，帮助决定哪些构件被包括进来。欲知详情请参考依赖机制。 - compile ：默认范围，用于编译 - provided：类似于编译，但支持你期待jdk或者容器提供，类似于classpath - runtime: 在执行时需要使用 - test: 用于test任务时使用 - system: 需要外在提供相应的元素。通过systemPath来取得 - systemPath: 仅用于范围为system。提供相应的路径 - optional: 当项目自身被依赖时，标注依赖是否传递。用于连续依赖时使用--&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;!--仅供system范围使用。注意，不鼓励使用这个元素，并且在新的版本中该元素可能被覆盖掉。该元素为依赖规定了文件系统上的路径。需要绝对路径而不是相对路径。推荐使用属性匹配绝对路径，例如$&#123;java.home&#125;。--&gt; &lt;systemPath&gt;&lt;/systemPath&gt; &lt;!--当计算传递依赖时， 从依赖构件列表里，列出被排除的依赖构件集。即告诉maven你只依赖指定的项目，不依赖项目的依赖。此元素主要用于解决版本冲突问题--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;!--可选依赖，如果你在项目B中把C依赖声明为可选，你就需要在依赖于B的项目（例如项目A）中显式的引用对C的依赖。可选依赖阻断依赖的传递性。--&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!--不赞成使用. 现在Maven忽略该元素.--&gt; &lt;reports&gt;&lt;/reports&gt; &lt;!--该元素描述使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。--&gt; &lt;reporting&gt; &lt;!--true，则，网站不包括默认的报表。这包括“项目信息”菜单中的报表。--&gt; &lt;excludeDefaults/&gt; &lt;!--所有产生的报表存放到哪里。默认值是$&#123;project.build.directory&#125;/site。--&gt; &lt;outputDirectory/&gt; &lt;!--使用的报表插件和他们的配置。--&gt; &lt;plugins&gt; &lt;!--plugin元素包含描述报表插件需要的信息--&gt; &lt;plugin&gt; &lt;!--报表插件在仓库里的group ID--&gt; &lt;groupId/&gt; &lt;!--报表插件在仓库里的artifact ID--&gt; &lt;artifactId/&gt; &lt;!--被使用的报表插件的版本（或版本范围）--&gt; &lt;version/&gt; &lt;!--任何配置是否被传播到子项目--&gt; &lt;inherited/&gt; &lt;!--报表插件的配置--&gt; &lt;configuration/&gt; &lt;!--一组报表的多重规范，每个规范可能有不同的配置。一个规范（报表集）对应一个执行目标 。例如，有1，2，3，4，5，6，7，8，9个报表。1，2，5构成A报表集，对应一个执行目标。2，5，8构成B报表集，对应另一个执行目标--&gt; &lt;reportSets&gt; &lt;!--表示报表的一个集合，以及产生该集合的配置--&gt; &lt;reportSet&gt; &lt;!--报表集合的唯一标识符，POM继承时用到--&gt; &lt;id/&gt; &lt;!--产生报表集合时，被使用的报表的配置--&gt; &lt;configuration/&gt; &lt;!--配置是否被继承到子POMs--&gt; &lt;inherited/&gt; &lt;!--这个集合里使用到哪些报表--&gt; &lt;reports/&gt; &lt;/reportSet&gt; &lt;/reportSets&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt; &lt;!-- 继承自该项目的所有子项目的默认依赖信息。这部分的依赖信息不会被立即解析,而是当子项目声明一个依赖（必须描述group ID和 artifact ID信息），如果group ID和artifact ID以外的一些信息没有描述，则通过group ID和artifact ID 匹配到这里的依赖，并使用这里的依赖信息。--&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!--项目分发信息，在执行mvn deploy后表示要发布的位置。有了这些信息就可以把网站部署到远程服务器或者把构件部署到远程仓库。--&gt; &lt;distributionManagement&gt; &lt;!--部署项目产生的构件到远程仓库需要的信息--&gt; &lt;repository&gt; &lt;!--是分配给快照一个唯一的版本号（由时间戳和构建流水号）？还是每次都使用相同的版本号？参见repositories/repository元素--&gt; &lt;uniqueVersion/&gt; &lt;id&gt;banseon-maven2&lt;/id&gt; &lt;name&gt;banseon maven2&lt;/name&gt; &lt;url&gt;file://$&#123;basedir&#125;/target/deploy&lt;/url&gt; &lt;layout/&gt; &lt;/repository&gt; &lt;!--构件的快照部署到哪里？如果没有配置该元素，默认部署到repository元素配置的仓库，参见distributionManagement/repository元素--&gt; &lt;snapshotRepository&gt; &lt;uniqueVersion/&gt; &lt;id&gt;banseon-maven2&lt;/id&gt; &lt;name&gt;Banseon-maven2 Snapshot Repository&lt;/name&gt; &lt;url&gt;scp://svn.baidu.com/banseon:/usr/local/maven-snapshot&lt;/url&gt; &lt;layout/&gt; &lt;/snapshotRepository&gt; &lt;!--部署项目的网站需要的信息--&gt; &lt;site&gt; &lt;!--部署位置的唯一标识符，用来匹配站点和settings.xml文件里的配置--&gt; &lt;id&gt;banseon-site&lt;/id&gt; &lt;!--部署位置的名称--&gt; &lt;name&gt;business api website&lt;/name&gt; &lt;!--部署位置的URL，按protocol://hostname/path形式--&gt; &lt;url&gt; scp://svn.baidu.com/banseon:/var/www/localhost/banseon-web &lt;/url&gt; &lt;/site&gt; &lt;!--项目下载页面的URL。如果没有该元素，用户应该参考主页。使用该元素的原因是：帮助定位那些不在仓库里的构件（由于license限制）。--&gt; &lt;downloadUrl/&gt; &lt;!--如果构件有了新的group ID和artifact ID（构件移到了新的位置），这里列出构件的重定位信息。--&gt; &lt;relocation&gt; &lt;!--构件新的group ID--&gt; &lt;groupId/&gt; &lt;!--构件新的artifact ID--&gt; &lt;artifactId/&gt; &lt;!--构件新的版本号--&gt; &lt;version/&gt; &lt;!--显示给用户的，关于移动的额外信息，例如原因。--&gt; &lt;message/&gt; &lt;/relocation&gt; &lt;!-- 给出该构件在远程仓库的状态。不得在本地项目中设置该元素，因为这是工具自动更新的。有效的值有：none（默认），converted（仓库管理员从 Maven 1 POM转换过来），partner（直接从伙伴Maven 2仓库同步过来），deployed（从Maven 2实例部 署），verified（被核实时正确的和最终的）。--&gt; &lt;status/&gt; &lt;/distributionManagement&gt; &lt;!--以值替代名称，Properties可以在整个POM中使用，也可以作为触发条件（见settings.xml配置文件里activation元素的说明）。格式是&lt;name&gt;value&lt;/name&gt;。--&gt; &lt;properties/&gt; &lt;/project&gt;","categories":[{"name":"其他技术","slug":"其他技术","permalink":"https://matthew-han.github.io/categories/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"https://matthew-han.github.io/tags/Maven/"},{"name":"构建工具","slug":"构建工具","permalink":"https://matthew-han.github.io/tags/%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7/"}]},{"title":"千千万万设计模式之单例模式","slug":"千千万万设计模式之单例模式","date":"2019-07-30T07:01:17.000Z","updated":"2025-09-03T02:52:50.977Z","comments":true,"path":"post/faabc627-bd9c-11e9-b52a-878085b5c0f3/","permalink":"https://matthew-han.github.io/post/faabc627-bd9c-11e9-b52a-878085b5c0f3/","excerpt":"","text":"这下好了，对象也要共享不让你new了。 单例模式我们先不谈什么是单例模式，我想其实很多人其实最关心的是什么时候需要用到单例模式？使用单例模式之后有什么提升与益处？ 首先我们知道单例单例，可以简单理解为单个实例，而实例化是指在面向对象的编程中，把用类创建对象的过程称为实例化。是将一个抽象的概念类，具体到该类实物的过程。 那么什么情况下会优先、或者强制使用单例模式创建实例呢： 数据库连接池，注意： 这里的单例指的是数据库连接池对象，而不是单个连接对象，这点一定要分清。 Spring中的Bean，获取实例的时候都是默认单例模式，所以多线程是要注意（面试题警告⚠）。 API接口中的token、id的获取，比如百度AI文字识别的accessToken中的获取，一般该token有一定的有效期，需要自行管理，当失效时需重新获取的方式，采用单例模式就可以很好的节约资源。 多个子类想共享一个父类的线程池的业务场景，频繁创建ThreadPool应该是不合适的，其实这个时候static单例化ThreadPool，注入是比较好的选择（这个例子比较特殊，可能是设计问题高耦合，可以不看）。 单例模式确保某个类只有一个实例，而且是自身创建唯一实例，提供一个全局访问的入口。网上的单例模式的写法大致就是3种：懒汉式单例模式、饿汉式单例模式、登记式单例模式： 懒汉式单例模式：在类加载时不初始化。 饿汉式单例模式：在类加载时就完成了初始化，所以类加载比较慢，但获取对象的速度快。 登记式单例模式：它的单例在类被装载的时候就被实例化了，内部也算是饿汉式单例模式。 登记式单例模式由于本人不太熟悉，所以在本文中只讲述前两种。 Java类加载顺序为什么要叫饿汉式、懒汉式呢？饿汉式则可以想象成因为太饿了，在类加载时就迫不及待完成了实例化，但是如果从初始化到线程结束都没有使用过的，就是变成了资源浪费。这里需要拓展下Java类的加载机制： 12345678910111213141516171819202122232425262728293031323334/** * @ClassName Initialization * @Description 类的初始化顺序 * @Author MatthewHan * @Date 2019/7/30 10:02 * @Version 1.0 **/public class Initialization &#123; private static IKun iKun = new IKun(); static &#123; System.out.println(&quot;静态代码块&quot;); &#125; &#123; System.out.println(&quot;非静态代码块&quot;); &#125; private Initialization()&#123; System.out.println(&quot;构造器&quot;); &#125; public static void main(String[] args)&#123; System.out.println(&quot;top-静态函数&quot;); new Initialization(); System.out.println(&quot;bottom-静态函数&quot;); &#125;&#125;class IKun&#123; IKun()&#123; System.out.println(&quot;静态变量&quot;); &#125;&#125; 从打印的结果可以看到Java类的加载顺序大致是：静态成员/静态代码块 –&gt; main方法 –&gt; 非静态成员/非静态代码块 –&gt; 构造器 饿汉式单例模式上面讲到了，饿汉式单例是在类加载就是内部实例化对象，并且不允许外部创建实例。饿汉式单例模式的实现也比较简单，记住无参构造器私有化，内部实例化对象，外部通过static方法获取对象。 我们都知道坤坤是一个对细节把控很有追求的人，从那段舞蹈的诸多细节就能够看出来。尤其是最后的白色吊带滑落，堪称经典之举，坤坤通过有意的小失误将前面表演精心铺垫的「舞王」设定迅速推翻，营造了一种反差萌拉近与粉丝的距离，白带异常的表现也让粉丝们感同身受。 坤坤自从白色吊带表演大火🔥之后，淘宝厂商为了恰烂钱💰纷纷效仿推出「坤坤同款异常白色吊带」、「坤坤潮流异常背带」的爆款产品。谁知道厂商还没开始恰烂钱💰的时候，坤坤就机智的把「坤式白色吊带」和「白色吊带异常」申请了发明专利、外观设计专利、实用专利，将「坤式白色吊带」这个商品和「白色吊带异常」这个艺术作品的所有权把握在了自己手里。「白色吊带异常」的表演不允许外界直接模仿、抄袭，必须先向坤坤申请，支付一定费用才购买了「坤式白色吊带」对象的licence后才可以表演「白色吊带异常」，并且使用完后要进行归还，这样就能确保只有一个白色吊带在外部商演能够很好的锁定。孙哥烂钱💰都恰得没这么6嗷~ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * @ClassName EarlySingleton * @Description 饿汉式单例模式 * @Author MatthewHan * @Date 2019/7/30 10:50 * @Version 1.0 **/public class EarlySingleton &#123; /** * 独享的moment */ private EarlySingleton()&#123;&#125; /** * 内部实例化一个白色吊带对象 */ private static EarlySingleton suspenders = new EarlySingleton(); /** * 全局入口点 * @return */ public static EarlySingleton getInstance()&#123; return suspenders; &#125; /** * 白带异常的演出 * @return */ public Suspenders slipping()&#123; return new Suspenders(&quot;white&quot;,&quot;白色吊带异常&quot;); &#125;&#125;/** * 坤坤申请专利了嗷 */@ToString@Setter(value = AccessLevel.PUBLIC)@Getter(value = AccessLevel.PUBLIC)@AllArgsConstructor@NoArgsConstructorclass Suspenders&#123; private String color; private String action;&#125; 12345678@Testpublic void getInstance() &#123; // 向坤坤申请 EarlySingleton s = EarlySingleton.getInstance(); assertNotNull(s); // 白色吊带异常演出 System.out.println(s.slipping());&#125; 优点： 线程安全 缺点： 类初始化实例化对象后未被调用则是浪费资源的表现 懒汉式单例模式坤坤虽然唱跳俱佳，但也耐不住是条懒狗🐶，只有等到电话、message、inbox连环催，他才开始发货。 12345678910111213141516171819202122232425262728/** * @ClassName LazilySingleton * @Description 懒汉式单例模式 * @Author MatthewHan * @Date 2019/7/30 15:46 * @Version 1.0 **/public class LazilySingleton &#123; /** * 同样的避免外部实例化 */ private LazilySingleton() &#123; &#125; private static LazilySingleton suspenders = null; /** * 线程不安全 * @return */ public static LazilySingleton getInstance() &#123; if (suspenders == null) &#123; suspenders = new LazilySingleton(); &#125; return suspenders; &#125;&#125; 优点： 单例实例在第一次被使用时构建 缺点： 不加锁的话，存在线程安全问题，即使加了锁，对性能也产生了影响。 注： 为什么说懒汉式单例模式是线程不安全的呢，假如有两个客户线程准备购买「坤式白色吊带」和「白色吊带异常」进行商演，第一位客户提出申请，坤坤刚回复马上交付，另一位客户的聊天窗口弹了出来也问能马上交付吗？坤坤一急立马把「白色吊带」和「白色吊带异常」的licence的交付第二位客户，交付完之后坤坤想到第一位客户也在等待，于是又把新的「白色吊带」和license交付给了第一位客户。然而现在已经有两个对象游离在外了，坤坤表示头很大。 坤坤发现自己亲自处理不但没牌面，而且容易出事情，但是交给经纪人又不放心，思来想去坤坤还是决定把这项业务交给哥哥孙笑川打理，自己则脱离去做更纯粹的音乐去了。 123456789101112131415161718192021/** * @ClassName Singleton * @Description 静态内部类 * @Author MatthewHan * @Date 2019/7/30 16:16 * @Version 1.0 **/public class Singleton &#123; /** * 把业务交给哥哥孙笑川打理 */ private static class SunXiaoChuan&#123; private static Singleton suspenders = new Singleton(); &#125; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; return SunXiaoChuan.suspenders; &#125;&#125; 优点： 线程安全 单例实例在第一次被使用时构建 缺点： 暂无 还是孙哥办事靠谱嗷，毕竟恰烂钱💰带师~","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://matthew-han.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"单例模式","slug":"单例模式","permalink":"https://matthew-han.github.io/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式","permalink":"https://matthew-han.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"千千万万设计模式之适配器模式","slug":"千千万万设计模式之适配器模式","date":"2019-07-23T09:38:46.000Z","updated":"2025-09-03T02:52:50.978Z","comments":true,"path":"post/faabc629-bd9c-11e9-b52a-878085b5c0f3/","permalink":"https://matthew-han.github.io/post/faabc629-bd9c-11e9-b52a-878085b5c0f3/","excerpt":"","text":"模式千万条，生命就一条，可以下班了。 本系列已经开源至GitHub，repository地址。 最初只是为了做个人笔记，参考了前人的笔记和博客，在这里我用更接潮流、更接地气的例子来帮助加深理解记忆。 由于本人技术水平也有限，着重点在于思想的理解，若出现任何错误、不恰当内容，欢迎各位前来issues指正。 感谢任何分享、开源学习教程的前辈，正是有你们这一群乐于奉献的人才让整个生态变得生机勃勃、让这个行业日新月异。 设计模式的思想新开个系列，把前人写的设计模式好好地学习钻研下，这里做点笔记。这里参考的博文地址 什么是设计模式？放在两年前的我，不但不了解它，也不会去重视它。我只在乎能够猥琐实现，程序运行不报错。但是在版本快速迭代、需求明天就改、框架稳定升级的现在，自己也写了不少代码，积累了一些经验和知识，在快速成长的过程中，愈发觉得优秀的开发工程师就是会比平庸的开发工程师在设计、建模的过程中去花更多时间去思考、去推理。其实我觉得我也算是考虑问题比较全面、比较细致的人了（大雾）。这里又可以引申出面向对象和面向过程，优秀的开发工程师可以把面向过程的程序写得非常内聚、可扩展性好、具备一定的复用性；而平庸的程序员用面向对象的语言一样也能把程序写得松散随意、毫无抽象与建模、模块耦合严重、维护性差。而设计模式也是考究程序员对业务的建模能力，以及对架构的宏观掌握能力，面向对象来说，以对象模型为核心，丰富模型的内涵，扩展模型的外延，通过模型的行为组合去共同解决某一力问题，抽象的能力必不可少。啥是面向对象？总结就是四大特性：封装、继承、多态、抽象。这里不细讲了，留到之后在总结一篇post吧。 适配器模式适配器模式简而言之就是一个类的转接口转换成客户希望的另外一个接口，主要作用就是兼容。举个例子：中国标准220伏特的电压，日本是110伏特的电压，iPhone的充电头是5伏1安（万年没有快充，iPhone 4也是5伏1安），220伏特的电压没法直接给iPhone充电，就需要一个电源适配器来连接两者，所以适配器模式就是讲一个类的转接口转换成客户希望的另一个接口。 在Spring的体现：Spring AOP模块BeforeAdvice、AfterAdvice、ThrowsAdvice三种通知类型的支持实际上是借助适配器模式来实现的， 这样的好处是使得框架允许用户向框架中加入自己想要支持的任何一种通知类型， 上述三种通知类型是Spring AOP模块定义的， 它们是AOP联盟定义的Advice的子类型。在Spring中 基本adapter结尾都是适配器~ 适配器的分类 类适配器 (通过引用适配者进行组合实现) 对象适配器 (通过继承适配者进行实现) 接口适配器 （通过抽象类来实现适配） 前二者在实现上有些许区别，作用一样，第三个接口适配器差别较大。 类适配器模式 原理：通过继承来实现适配器功能。 在这里我就是拿两位德艺双馨的人民艺术家老师：坤坤和凡凡的业务能力用代码来解释类适配器模式。大家都知道坤坤是一位练习时长2年半的个人练习生，喜欢唱跳rap篮球： 123456789101112131415161718192021222324252627282930313233343536/** * @ClassName KunKunService * @Description 坤坤业务的能力 * @Author MatthewHan * @Date 2019/7/25 15:42 * @Version 1.0 **/public interface KunKunService &#123; /** * 唱 * @param lyric * @return */ String singing(String lyric); /** * 跳 * @param music * @return */ boolean dance(Music music); /** * rap * @return */ boolean rap(); /** * 虚假的篮球🏀 * @param basketball * @return */ boolean playBall(Basketball basketball);&#125; 1234567891011121314151617181920212223242526272829303132333435/** * @ClassName KunKunServiceImpl * @Description 坤坤练习生业务能力的展现 * @Author MatthewHan * @Date 2019/7/25 15:58 * @Version 1.0 **/public class KunKunServiceImpl implements KunKunService &#123; @Override public String singing(String lyric) &#123; return lyric; &#125; @Override public boolean dance(Music music) &#123; return false; &#125; @Override public boolean rap() &#123; return false; &#125; /** * 坤坤皮球还是给个赞👍 * @return */ @Override public boolean playBall(Basketball basketball) &#123; return true; &#125;&#125; 当然我们的加拿带🇨🇦电鳗凡凡业务能力也⑧差。自带auto tone放电的男人，每次看完他的Live，手机电就满了（据说凡凡打算成立凡电科技公司，主营移动充电业务）。恰面🍜水平也很高，而且恰面一定要大碗的。当然了，这么优秀的蓝人还是有个弱点的，就是怕苏韵锦像个石头一样欠的钱不还。 123456789101112131415161718192021222324252627282930313233343536/** * @ClassName KrisService * @Description 加拿带电鳗的业务水平 * @Author MatthewHan * @Date 2019/7/25 16:02 * @Version 1.0 **/public interface KrisService &#123; /** * 凡凡的充电计划√ * @return */ String autoTone(String lyric); /** * 苏⚡️韵⚡️锦⚡️，你⚡️这⚡️里⚡️欠⚡️我⚡️的⚡️用⚡️什⚡️么⚡️还⚡️？ * @param id * @return */ boolean repay(long id); /** * size一定要大，因为是大碗宽面! * @param size * @return */ boolean eatNoodles(long size); /** * 真正的篮球🏀 vs 虚假的篮球🏀 * @param basketball * @return */ boolean playBasketball(Basketball basketball);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142/** * @ClassName KrisServiceImpl * @Description U R so bad girl ! * @Author MatthewHan * @Date 2019/7/25 16:11 * @Version 1.0 **/public class KrisServiceImpl implements KrisService &#123; /** * auto tone ⑧用麦克风就天然打开 * @return */ @Override public String autoTone(String lyric) &#123; StringBuilder freestyle = new StringBuilder(); String[] str = lyric.split(&quot;&quot;); for(String c : str)&#123; freestyle.append(c); freestyle.append(&quot; ⚡ &quot;); &#125; return String.valueOf(freestyle); &#125; @Override public boolean repay(long id) &#123; return true; &#125; @Override public boolean eatNoodles(long size) &#123; return true; &#125; @Override public boolean playBasketball(Basketball basketball)&#123; return true; &#125;&#125; 有一天坤坤觉得自己的成名作《鸡你太美》虽然灵幻动听，但是还是少了点什么味道。为了充电的他打开了pilipili看了凡凡的Live后恍然大悟，原来是少了auto tone！但是坤坤自身根本没有这种天赋，于是身为带明星的坤坤就打算偷学凡凡的绝技，打算在以后的唱歌中都加入这种带电的感觉。 123456789101112131415161718192021222324252627282930/** * @ClassName ClassKunKunAdapter * @Description 坤の偷学 * @Author MatthewHan * @Date 2019/7/25 17:02 * @Version 1.0 **/public class ClassAdapterImpl extends KrisServiceImpl implements KunKunService &#123; @Override public String singing(String lyric) &#123; return super.autoTone(lyric); &#125; @Override public boolean dance(Music music) &#123; return false; &#125; @Override public boolean rap() &#123; return false; &#125; @Override public boolean playBall(Basketball basketball) &#123; return true; &#125;&#125; 12345678@Testpublic void singingOfClass() &#123; KunKunService c = new ClassAdapterImpl(); assertEquals(c.singing(&quot;鸡你太美!&quot;),&quot;鸡 ⚡ 你 ⚡ 太 ⚡ 美 ⚡ ! ⚡ &quot;); System.out.println(c.singing(&quot;鸡你太美!&quot;));&#125; 我们来测试下结果，坤坤师承凡凡，通过偷学凡凡的绝技成功的让自己的唱歌技巧上了几个鹿晗的level，成为young OG就是这么简单。 但是我们也可以看到这种实现方式，需要将坤坤的所有业务能力全部覆写一遍，实属⑧够灵活，其实我们还有接口适配器模式。 对象适配器模式 原理：通过组合来实现适配器功能。 通过将凡凡业务员初始化，new一个对象凡凡，让凡凡来帮忙使用auto tone，坤凡合体演绎鸡🐔你太美！ 1234567891011121314151617181920212223242526272829303132333435/** * @ClassName ObjectAdapterImpl * @Description 对象适配器 * @Author MatthewHan * @Date 2019/7/26 09:53 * @Version 1.0 **/public class ObjectAdapterImpl implements KunKunService &#123; private KrisService krisService; public ObjectAdapterImpl(KrisService krisService) &#123; this.krisService = krisService; &#125; @Override public String singing(String lyric) &#123; return krisService.autoTone(lyric); &#125; @Override public boolean dance(Music music) &#123; return false; &#125; @Override public boolean rap() &#123; return false; &#125; @Override public boolean playBall(Basketball basketball) &#123; return true; &#125;&#125; 同样的，坤坤在更♂衣室也来测试下效果 12345678910@Testpublic void singingOfObject() &#123; KrisService krisService = new KrisServiceImpl(); KunKunService o = new ObjectAdapterImpl(krisService); assertEquals(o.singing(&quot;鸡你太美~&quot;),&quot;鸡 ⚡ 你 ⚡ 太 ⚡ 美 ⚡ ~ ⚡ &quot;); System.out.println(o.singing(&quot;鸡你太美~&quot;));&#125; 虽然是坤坤的舞台，但是却有加拿带🇨🇦电流声？假唱实锤！ 接口适配器模式 通过抽象类来实现适配，这种适配方式有别于上面两种。 上面两种实现方式，毫无例外的都覆写了坤坤的所有业务能力，略显笨重，那么适配器模式可以只将坤坤的一种或多种技能进行适配强化。自从坤坤唱歌也能发电之后，坤坤成功的选上了NBA篮球带使，但是却被广大直男们怒喷。坤坤很抑郁啊，于是就去找了当年美国校队啦啦队的队长Chaoyue Yang，希望能够从幸运光环一身的她找到点帮助。Chaoyue妹妹耐心地和坤坤说，你现在被直男们喷还是因为把篮球🏀玩出皮球的感觉，实属弟弟，篮球技术还是要偷学凡凡嗷~于是坤坤在一个与杰伦超话流量争顶的晚上，专门虚心去请教凡凡关于篮球技巧，顺便把auto tone升级到2.0。凡凡见到坤坤没有丝毫意外，缓缓说道：你想要的一切，我都放在了抽象圣经《AbstractAdapter》里面了，自己去取需要的吧，别再来打扰我了，U R so bad girl！ 12345678910111213141516171819202122232425262728293031323334/** * @ClassName AbstractAdapter * @Description 抽象圣经 * @Author MatthewHan * @Date 2019/7/26 16:18 * @Version 1.0 **/public abstract class AbstractAdapter implements KunKunService &#123; @Override public String singing(String lyric) &#123; StringBuilder freestyle = new StringBuilder(); String[] str = lyric.split(&quot;&quot;); for(String c : str)&#123; freestyle.append(c); // 2.0 电力加强了 freestyle.append(&quot; ⚡⚡ &quot;); &#125; return String.valueOf(freestyle); &#125; @Override public boolean dance(Music music) &#123; return false; &#125; @Override public boolean rap() &#123; return false; &#125; @Override public boolean playBall(Basketball basketball) &#123; return true; &#125;&#125; 12345678910111213141516171819/** * @ClassName InterfaceAdapterImpl * @Description 坤の学习 * @Author MatthewHan * @Date 2019/7/26 16:30 * @Version 1.0 **/public class InterfaceAdapterImpl extends AbstractAdapter &#123; @Override public String singing(String lyric) &#123; return super.singing(lyric); &#125; @Override public boolean playBall(Basketball basketball) &#123; return super.playBall(basketball); &#125;&#125; 123456789101112131415@Testpublic void singingOfInterface() &#123; KunKunService i = new InterfaceAdapterImpl(); assertEquals(i.singing(&quot;鸡你太美...&quot;),&quot;鸡 ⚡⚡ 你 ⚡⚡ 太 ⚡⚡ 美 ⚡⚡ . ⚡⚡ . ⚡⚡ . ⚡⚡ &quot;); System.out.println(i.singing(&quot;鸡你太美...&quot;));&#125;@Testpublic void playBallOfInterface() &#123; KunKunService i = new InterfaceAdapterImpl(); assertTrue(i.playBall(new Basketball()));&#125; 坤坤通过研读抽象圣经《AbstractAdapter》后，不但学到了真正的篮球，还把auto tone成功升级到2.0，电力翻倍。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://matthew-han.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://matthew-han.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"适配器模式","slug":"适配器模式","permalink":"https://matthew-han.github.io/tags/%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/"}]},{"title":"Quick Sort思想以及Java代码实现","slug":"Quick-Sort思想以及Java代码实现","date":"2019-07-19T07:18:15.000Z","updated":"2025-09-03T02:52:50.972Z","comments":true,"path":"post/faabc620-bd9c-11e9-b52a-878085b5c0f3/","permalink":"https://matthew-han.github.io/post/faabc620-bd9c-11e9-b52a-878085b5c0f3/","excerpt":"","text":"快速排序概要 快排的三个步骤： 选择基准：在待排序列中，按照某种方式挑出一个元素，作为 “基准”（pivot）。 分割操作：以该基准在序列中的实际位置，把序列分成两个子序列。此时，在基准左边的元素都比该基准小，在基准右边的元素都比基准大。 递归地对两个序列进行快速排序，直到序列为空或者只有一个元素。 其实快排实现的核心思想就是分治和递归，接下来用大白话解释下快排的原理，用词和说明可能不是那么正确，但是能够先听懂它的实现，我觉得这更重要。 我们假设这样杂乱无序不重复的数组[21, 5, 44, 63, 3]，设定他的基准pivot为第一位Array[0]，则pivot就是21，当然不一定都是第一位，并且low指针指向最左边，high指针指向最后边。 当low指针指向的值大于pivot就赋值给high指针，若当前指向的值不大于pivot，则一直向右移动，直到两个指针重合或者找到比pivot大的值。 high指针则反之，一直找寻比pivot小的值，找到则赋值给low指针，否则一直向左移动，直到两个指针重合或者找到比pivot小的值。 快排原理解释 high指针先于low指针比较和移动，high指针所指向的value是3，比pivot小，则赋值给low指针所指向的21，并且high指针不动。 这时，轮到low指针向右移动了。 此时low指针向右移动发现比pivot小，则继续向右移动。 这时候lei了，low指针指向的44比pivot大，辣么就赋值给high指针指向的3，并且low指针保持不动。 high指针向左移动。 发现比pivot大，这继续向左移动。 当两指针重合的时候，此时指向的44将会被基准值改写。 这时候一轮分治就OJBK了。可以清楚地看到（好像这个例子不是很清楚的看到，果然是size太短了吗），在基准值的左边数组大小都是小于基准值的，而右边数组都是大于基准值。这个时候就体现了快排的分治思想，相当于从基准中切一刀，左边的数组单独去排序，右边的数组单独去排序。这时候就变成了[3, 5]和[63, 44]继续递归快速排序，所以说快排实现的核心思想就是分治和递归。 Java代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package sort;import java.util.Arrays;import java.util.Timer;/** * @author Matthew Han * @description * @date 2021/4/21 17:06 * @since 1.0.0 **/public class QuickSort&lt;T extends Comparable&lt;T&gt;&gt; implements ISort&lt;T&gt; &#123; /** * 快速排序 * * @param arr */ @Override public void sort(T[] arr) &#123; quickSort(arr, 0, arr.length - 1); System.out.println(&quot;arr = &quot; + Arrays.toString(arr)); &#125; public void quickSort(T[] arr, int left, int right) &#123; if (left &gt; right) &#123; return; &#125; int i = left; int j = right; T pivot = arr[i]; while (i &lt; j) &#123; while (i &lt; j &amp;&amp; arr[j].compareTo(pivot) &gt;= 0) &#123; j--; &#125; if (i &lt; j &amp;&amp; arr[j].compareTo(pivot) &lt; 0) &#123; arr[i] = arr[j]; i++; &#125; while (i &lt; j &amp;&amp; arr[i].compareTo(pivot) &lt; 1) &#123; i++; &#125; if (i &lt; j &amp;&amp; arr[i].compareTo(pivot) &gt; 0) &#123; arr[j] = arr[i]; j--; &#125; &#125; if (i == j) &#123; arr[i] = pivot; &#125; quickSort(arr, left, i - 1); quickSort(arr, i + 1, right); &#125;&#125; 要注意每次要判断i和k的大小，因为数组size是多少就会有多少次基准数归位，会不断地拆分成两对数组，最后变成2位，1位。 快排的一些知识点和算法复杂度 选取基准最怕的就是选到了最大值或者最小值，这样一轮就是只是把基准数移到了最边上。 从概率学上来说，基准数选不选择第一个，还是中间随机抽取一个对是否会选取到最大值或最小值都是没有任何影响的。但是存在数列完全逆序的情况，从中间选取基准数可以有效避免这种情况发生，若还是选择数列最左位当做基准数的话，就会变成最糟糕的情况，时间复杂度就会变成O（n^2）。 所以快速排序的平均时间复杂度是 O（nlogn），最坏情况下的时间复杂度是 O（n^2）。","categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"快速排序","slug":"快速排序","permalink":"https://matthew-han.github.io/tags/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"}]},{"title":"阿里云对象存储使用","slug":"阿里云对象存储使用","date":"2019-07-17T07:25:18.000Z","updated":"2025-09-03T02:52:50.980Z","comments":true,"path":"post/faabc624-bd9c-11e9-b52a-878085b5c0f3/","permalink":"https://matthew-han.github.io/post/faabc624-bd9c-11e9-b52a-878085b5c0f3/","excerpt":"","text":"这两天僵住了，分配给我的项目是提前写完了，但是测试样例却不好弄，索性就划着，反而给了我很多时间去学习其他知识。 图床很有必要首先GayHub本来就不是很稳定，公司网络访问十分OK，回到家连ping都快ping不通了，clone个repository真的是玩一年，更别说编辑blog了，打开博客图片就加载不出来，家里好歹也是电信100Mbps的，网速应该没问题。像我这种对艺术与美都有追求的人，选的图片都是色影师实拍的高清原图，分辨率都是3K、4K级别的。自己的照片也是高分辨率，容量也不小，要是没有类似CDN之类或者云存储的话，以后blog变多怕是博客在哪里都打不开了，毕竟GayHub也不是用爱发电的。 辣么就选一个方案吧，网上推荐比较多的就是sm.ms、阿里云OSS和七牛了，七牛这个hape，还要身份证正反面实名认证，也没留身份证的照片就懒得搞了，阿里云这个B天天发邮件促销活动，就选择冲阿里云了。 对象存储这个概念之前在带库升级的时候，各家方案和需求都有提及过，当时与百度云团队、IBM、Oracle厂商都有过交流，虽然我是完全不懂都是听个大概，但是概念和特点也略微了解了。不过这和使用这个存储服务没有什么关系，不用管底层照着阿里的文档用就vans了。 开通服务猛冲成功后，点击创建一个Bucket 其中区域选择，网上说选择香港好像有免费额度，但是普遍反映这个成本极低，所以我就冲了华东1（杭州），读写权限这里要注意对象存储OSS提供Bucket级别的权限访问控制。Bucket目前有三种访问权限：public-read-write，public-read和private，它们的含义如下： 权限值 中文名称 权限对访问者的限制 public-read-write 公共读写 任何人（包括匿名访问者）都可以对该存储空间内文件进行读写操作。警告：互联网上任何用户都可以对该 Bucket 内的文件进行访问，并且向该 Bucket 写入数据。这有可能造成您数据的外泄以及费用激增，若被人恶意写入违法信息还可能会侵害您的合法权益。除特殊场景外，不建议您配置公共读写权限。 public-read 公共读，私有写 只有该存储空间的拥有者可以对该存储空间内的文件进行写操作，任何人（包括匿名访问者）都可以对该存储空间中的文件进行读操作。警告 互联网上任何用户都可以对该 Bucket 内文件进行访问，这有可能造成您数据的外泄以及费用激增，请谨慎操作。 private 私有读写 只有该存储空间的拥有者可以对该存储空间内的文件进行读写操作，其他人无法访问该存储空间内的文件。 如果设置成私有的话，阿里云没有警告信息，1️⃣0️⃣🐭安全行为，但是读需要鉴权、签名，并且访问有时效性，最大超时时间是18小时；如果设置成公共读私写的话，谁都可以进行读取，并且无超时，有一定的安全隐患；公共读写就8️⃣说了，1️⃣0️⃣🐭弟弟行为，难道是要空手套黄图？ 这里我们的需求就是hexo博客存储图片，我选择了公读私写，因为选择全私有的话，貌似不能修改访问的超时机制在静态页面的博客中不好去授权访问，不如公开读取（反正我也8️⃣是冠希哥），反正这个选项在这里总是要给人用的啊！ 计费方式注：该计费方式更新于Jul.29th,2019，实际情况请以阿里云对象存储官网为准，本文计费方式描述仅供参考。 详细的计费方式建议直接去阿里云了解或咨询客服，根据反馈来说应该是比较低廉的（不开启CDN加速服务）。 这里强烈建议选择包年包月的方式： 按量付费：按实际使用量*单价的方式计费，每小时统计前一小时的实际用量并从账户余额中扣除实际消费金额。例如，当前时间是 9:30，结算的是 8:00-9:00 产生的费用。 包年包月：预先购买指定资源包，之后使用资源时，扣除相应的额度。一般情况下，包年包月比按量付费更加优惠。资源包目前仅提供标准型存储包、归档型存储包、下行流量包、 回源流量包，可购买地域请参见购买对象存储OSS资源包。 注意： OSS的所有收费项目都是单独计费的，例如：您在OSS 的存储空间内存放了100GB数据，会产生存储费用；若每天有不同的客户通过外网访问您的数据，则您还会额外产生请求费用和外网流出流量费用。 简而言之就是如果你开通了包年包月服务，你实际产生的费用一般是由包年包月的服务费（数据存储、外网流出）+数据处理费用+请求费用。大头其实就是在数据存储和外网流出流量上，所以选择一个合适的套餐开通包年包月服务还是很有必要的。 其他工具 管理界面和百度网盘很像，虽然底层是对象存储，但是傻瓜管理界面还是树形结构，这种最简单才是最好用的。这里可以对单一对象进行相关设置（包括获取URL、读写权限，不展开），不过推荐还是使用一款官方application来可视化管理比较好，可以直接拖拽上传下载。GayHub地址：https://github.com/aliyun/oss-browser其实这里应该是和HexoEditor搭配才是完美的，可惜HexoEditor只支持七牛、腾讯云，不支持阿里云OSS。HexoEditor是一款Markdown的开发工具，预览内容与Hexo生成页面内容高度相似（可以配置主题，虽然我失败了，我的主题比较特殊），并且HexoEditor对图床的支持也8️⃣错，就是不支持阿里云，如下图：HexoEditor的GayHub地址：https://github.com/zhuzhuyule/HexoEditor Hexo中使用最后就可以在你的HexoEditor上编写Markdown博客辣，通过oss-browser进行备份，再次打开你的blog，应该会比原来快很多的吧！","categories":[{"name":"其他技术","slug":"其他技术","permalink":"https://matthew-han.github.io/categories/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"对象存储","slug":"对象存储","permalink":"https://matthew-han.github.io/tags/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/"},{"name":"存储服务","slug":"存储服务","permalink":"https://matthew-han.github.io/tags/%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1/"},{"name":"阿里云","slug":"阿里云","permalink":"https://matthew-han.github.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"}]},{"title":"Swagger初体验","slug":"Swagger初体验","date":"2019-07-16T09:48:15.000Z","updated":"2025-09-03T02:52:50.975Z","comments":true,"path":"post/faabc622-bd9c-11e9-b52a-878085b5c0f3/","permalink":"https://matthew-han.github.io/post/faabc622-bd9c-11e9-b52a-878085b5c0f3/","excerpt":"","text":"Swagger…现在好像又多了一层台味… 前言以前刚接触到Swagger，不知道他还能导出成Word、PDF文档，就觉得Postman+文档够用了，现在觉得代码中集成这样的框架，在初期能够方便很多。 功能丰富 ：支持多种注解，自动生成接口文档界面，支持在界面测试API接口功能； 条理清晰 ：开发过程中花一点写注释的时间，就可以及时的更新API文档，省心省力； 整合简单 ：通过添加pom依赖和简单配置，内嵌于应用中就可同时发布API接口文档界面，不需要部署独立服务。 Swagger集成项目Swagger本身是一种规范，而SpringFox-Swagger是专注于Spring生态的实现，Spring-Swagger-UI则是对Swagger-UI的封装。 代码整整合也非常的简单，首先是pom引入： pom引入123456789101112131415&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.swagger2markup&lt;/groupId&gt; &lt;artifactId&gt;swagger2markup&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt; 其中swagger2markup是用于Swagger导出PDF&#x2F;HTML的依赖，离线文档之后再更新，目前还有点问题。 在application.properties中加这么一句spring.resources.static-locations=classpath:/static/，不然swagger-ui.html这个页面会被拦截。 Configuration注入12345678910111213141516171819202122232425262728293031/** * @ClassName SwaggerConfiguration * @Description TODO * @Author MatthewHan * @Date 2019/7/16 16:15 * @Version 1.0 **/@Configurationpublic class SwaggerConfiguration &#123; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() // 这是注意的代码 .apis(RequestHandlerSelectors.basePackage(&quot;com.zrtg.ldapsync.common.action&quot;)) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title(&quot;ldap-sync接口文档&quot;) .description(&quot;用于大院LDAP服务器同步无纸化办公组织架构&quot;) .termsOfServiceUrl(&quot;http://gitlab.zrtg.com/996team/ldap-sync&quot;) .version(&quot;1.0&quot;) .build(); &#125;&#125; 其中basePackage中的一般配置controller的路径，paths属性进行过滤，apis属性可以设置扫描包，或者通过注解的方式标识；通过enable属性，可以在application-&#123;profile&#125;.properties文件中设置相应值，主要用于控制生产环境不生成接口文档。另外还有groupName()进行分组，比如高级客户、低端人口（雾）之类的分组。 apiInfo中包装了文档的title、description、version这些信息。 然后在Springboot的入口类中加上@EnableSwagger2表示开启Swagger2。 完成这些步骤后，发现其实访问https://localhost/swagger-ui.html并没有swagger页面，原因是在所映射的地址在SpringBoot静态资源文件夹下找不到。所以需要定义一个拦截器来放行。 实现WebMvcConfigurer1234567891011121314151617181920/** * @ClassName WebMvcConfiguration * @Description 用于Swagger UI显示 * @Author MatthewHan * @Date 2019/7/16 16:37 * @Version 1.0 **/@Configurationpublic class WebMvcConfiguration implements WebMvcConfigurer &#123; @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler(&quot;swagger-ui.html&quot;) .addResourceLocations(&quot;classpath:/META-INF/resources/&quot;); registry.addResourceHandler(&quot;/templates/**&quot;) .addResourceLocations(&quot;classpath:/META-INF/resources/templates/&quot;); &#125;&#125; 我们只需要重写addResourceHandlers方法即可，通过addResourceHandler添加映射路径，然后再通过addResourceLocations来指定路径。addResourceLocations指的是文件放置的目录，addResoureHandler指的是对外暴露的访问路径。 在controller中集成注解 注解 描述 @Api 修饰整个类，描述Controller的作用 @ApiOperation 描述一个类的一个方法，或者说一个接口 @ApiParam 单个参数描述 @ApiModel 用对象来接收参数 @ApiProperty 用对象接收参数时，描述对象的一个字段 @ApiResponse HTTP响应其中1个描述 @ApiResponses HTTP响应整体描述 @ApiIgnore 使用该注解忽略这个API @ApiError 发生错误返回的信息 @ApiImplicitParam 一个请求参数 @ApiImplicitParams 多个请求参数 最后通过浏览器来访问https://localhost/swagger-ui.html如下图： Method类型、相关描述、Example、StatusCode都会自动帮你生成。 小问题记录注解问题直接在通过@PathVariable注解的参数在Swagger中用了@ApiImplicitParam，发现在页面中请求是有问题的，这个注解应该对应的是func(@Param(&quot;arg&quot;) String arg)方法，实际上正确的用法是@ApiParam。类似下图代码： 123456789101112/*** 测试* 用于添加一个ou，例如：department，employee* @param ou* @return*/ @ApiOperation(value = &quot;添加一个OU&quot;) @ApiParam(name = &quot;ou&quot;, value = &quot;组织单元&quot;, required = true) @PostMapping(&quot;/add-ldap-ou/&#123;ou&#125;&quot;) public BaseResult&lt;String&gt; addLdapOu(@PathVariable(&quot;ou&quot;)String ou)&#123; ...&#125; 与Shiro集成的问题通过无拦截测试总结了如下的资源路径是swagger在渲染页面时的必需。如果工程中包含了Shiro安全框架，需要对swagger进行放行。 1234567891011// 设置拦截器Map&lt;String, String&gt; filterChainDefinitionMap = new LinkedHashMap&lt;&gt;();// swagger放行filterChainDefinitionMap.put(&quot;/swagger-ui.html&quot;, &quot;anon&quot;);filterChainDefinitionMap.put(&quot;/swagger-resources/**&quot;, &quot;anon&quot;);filterChainDefinitionMap.put(&quot;/v2/**&quot;, &quot;anon&quot;);filterChainDefinitionMap.put(&quot;/webjars/**&quot;, &quot;anon&quot;);filterChainDefinitionMap.put(&quot;/configuration/**&quot;, &quot;anon&quot;);ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean();shiroFilterFactoryBean.setFilterChainDefinitionMap(filterChainDefinitionMap); 在你的Shiro配置类中添加如上路径即可。 离线文档（后续更新）","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Swagger","slug":"Swagger","permalink":"https://matthew-han.github.io/tags/Swagger/"}]},{"title":"Shiro学习一","slug":"Shiro学习一","date":"2019-07-12T09:01:35.000Z","updated":"2025-09-03T02:52:50.975Z","comments":true,"path":"post/faabc626-bd9c-11e9-b52a-878085b5c0f3/","permalink":"https://matthew-han.github.io/post/faabc626-bd9c-11e9-b52a-878085b5c0f3/","excerpt":"","text":"前言新的公司让我去熟悉下Shiro框架,公司的项目的权限管理都是基于Shiro写的,照着前辈们的blog学习了一番，这里做点个人学习记录。 Shiro的整体架构图 首先是Shiro的几个组件 SecurityManager 即所有Subject的管理者，这是Shiro框架的核心组件，可以把他看做是一个Shiro框架的全局管理组件，用于调度各种Shiro框架的服务。 Authenticator 认证器，登入登出，对“Who are you？”进行核实。通常涉及用户名和密码。 Authorizer授权器，赋予主体有哪些权限，身份验证通过后，由这个组件对登录人员进行访问控制的筛查，比如“who can do what”， 或者“who can do which actions”。Shiro 采用“基于 Realm”的方法，即用户（又称 Subject）、用户组、角色和 permission 的聚合体。 Session Manager这个组件保证了异构客户端的访问，配置简单。它是基于POJO&#x2F;J2SE的，不跟任何的客户端或者协议绑定。 Subject即当前用户，在权限管理的应用程序里往往需要知道谁能够操作什么，谁拥有操作该程序的权利，shiro中则需要通过Subject来提供基础的当前用户信息，Subject 不仅仅代表某个用户，也可以是第三方进程、后台帐户（Daemon Account）或其他类似事物。 RealmsRealms也就是域，是用户的信息认证器和用户的权限人证器，我们需要自己来实现Realms来自定义的管理我们自己系统内部的权限规则。 通过ini文件来自定义RealmMaven依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-core&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt;&lt;/dependency&gt; shiro.ini 1234567891011121314151617181920212223242526# -----------------------------------------------------------------------------# Users and their (optional) assigned roles# username = password, role1, role2, ..., roleN# -----------------------------------------------------------------------------[users]#用户名(登陆账号)是root,密码是123,角色是admin管理员root = 123,adminuser001 = 123,productManageruser002 = 123,orderManager# -----------------------------------------------------------------------------# Roles with assigned permissions# roleName = perm1, perm2, ..., permN# -----------------------------------------------------------------------------[roles]#admin管理员权限拉满,什么都能做admin = *#产品经理只能做产品的管理productManager = addProduct,deleteProduct,editProduct,listProduct#订单管理员只能做订单的管理orderManager = addOrder,deleteOrder,editOrder,listOrder 这里分配了三种角色各自拥有不同的权限 admin 拥有所有权限 productManager addProduct deleteProduct editProduct listProduct orderManager addOrder deleteOrder editOrder listOrder Tutorial .java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105package shiro;import org.apache.shiro.SecurityUtils;import org.apache.shiro.authc.*;import org.apache.shiro.config.IniSecurityManagerFactory;import org.apache.shiro.mgt.SecurityManager;import org.apache.shiro.session.Session;import org.apache.shiro.subject.Subject;import org.apache.shiro.util.Factory;import org.slf4j.Logger;import org.slf4j.LoggerFactory;/** * Created by MatthewHan on 2018. */public class Tutorial &#123; private static final transient Logger log = LoggerFactory.getLogger(Tutorial.class); public static void main(String[] args) &#123; //step1.使用了IniSecurityManagerFactory类读取ini文件 Factory&lt;SecurityManager&gt; factory = new IniSecurityManagerFactory(&quot;classpath:shiro.ini&quot;); //step2.解析ini文件，返回一个Securitymanager对象，对象含有配置信息 SecurityManager securityManager = factory.getInstance(); //step3. SecurityUtils.setSecurityManager(securityManager); //获取当前使用的用户 Subject currentUser = SecurityUtils.getSubject(); //获取Session信息 Session session = currentUser.getSession(); session.setAttribute(&quot;oneKey&quot;,&quot;aValue&quot;); String value = (String)session.getAttribute(&quot;oneKey&quot;); if(value.equals(&quot;trueValue&quot;)) &#123; log.info(&quot;值正确！[&quot;+ value +&quot;]&quot;); &#125; else &#123; log.info(&quot;value有错误哦！您的value：[&quot;+ value+&quot;]&quot;); &#125; log.info(&quot;\\n**********************是否登陆成功*********************\\n&quot;); //登陆后的当前用户，这样我们就可以检查角色和权限： if(!currentUser.isAuthenticated()) &#123; String username = &quot;user001&quot;, password = &quot;1123&quot;; UsernamePasswordToken token = new UsernamePasswordToken(username, password); token.setRememberMe(true); try &#123; currentUser.login(token);//登陆 log.info(&quot;你居然登陆上了,牛逼&quot;); log.info(&quot;\\n**********************打印这些登陆用户的信息*********************\\n&quot;); //打印这些登陆用户的信息 log.info(&quot;用户[&quot; + currentUser.getPrincipal() + &quot;] 登陆成功！&quot;); //测试一个role String roleName = &quot;productManager&quot;; if (currentUser.hasRole(roleName)) &#123; log.info(&quot;这个角色：[&quot; + roleName + &quot;]&quot;); &#125; else &#123; log.info(&quot;emmmm,mere mortal!&quot;); &#125; log.info(&quot;\\n**********************测试不同类型的权限*********************\\n&quot;); //测试不同类型的权限 if (currentUser.isPermitted(&quot;addProduct&quot;)) &#123; log.info(&quot;您可以对产品进行管理&quot;); &#125; else &#123; log.info(&quot;你不配使用&quot;); &#125; //part2 if (currentUser.isPermitted(&quot;addOrder&quot;)) &#123; log.info(&quot;您可以对订单系统进行管理&quot;); &#125; else&#123; log.info(&quot;抱歉，你不配管理订单系统&quot;); &#125; &#125; catch (UnknownAccountException uae) &#123; log.info(&quot;没有这个用户名：&quot; + token.getPrincipal()); &#125; catch (IncorrectCredentialsException ice) &#123; log.info(&quot;这个账号&quot; + token.getPrincipal() + &quot;的密码是错的啦,try again?&quot;); &#125; catch (LockedAccountException lae) &#123; log.info(&quot;这个用户&quot; + token.getPrincipal() + &quot;已被封锁&quot; + &quot;请联系管理员解锁&quot;); &#125; catch (AuthenticationException ae) &#123; log.info(&quot;发生了一些未知的情况，请联系管理员！&quot;); &#125; &#125; //用户登出 currentUser.logout(); System.exit(0); &#125;&#125; 测试类Tutorial,通过UsernamePasswordToken创建的token对象来让Subject(当前对象)进行登陆验证,认证通过后,可以用getPrincipal()这个方法来获取当前对象的用户名. 角色相关验证方法 Subject方法 描述 hasRole(String roleName) 当用户拥有指定角色时，返回true hasRoles(List roleNames) 按照列表顺序返回相应的一个boolean值数组 hasAllRoles(Collection roleNames) 如果用户拥有所有指定角色时，返回true Subject方法 描述 checkRole(String roleName) 断言用户是否拥有指定角色 checkRoles(Collection roleNames) 断言用户是否拥有所有指定角色 checkRoles(String… roleNames) 对上一方法的方法重载 权限相关验证方法 Subject方法 说明 checkPermission(Permission p) 断言用户是否拥有制定权限 checkPermission(String perm) 断言用户是否拥有制定权限 checkPermissions(Collection perms) 断言用户是否拥有所有指定权限 checkPermissions(String… perms) 断言用户是否拥有所有指定权限 Subject方法 描述 isPermitted(Permission p) Subject拥有制定权限时，返回true isPermitted(List perms) 返回对应权限的boolean数组 isPermittedAll(Collection perms) Subject拥有所有制定权限时，返回true","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Shiro","slug":"Shiro","permalink":"https://matthew-han.github.io/tags/Shiro/"}]},{"title":"Spring-ldap","slug":"Spring-ldap","date":"2019-07-11T10:06:15.000Z","updated":"2025-09-03T02:52:50.975Z","comments":true,"path":"post/faabc621-bd9c-11e9-b52a-878085b5c0f3/","permalink":"https://matthew-han.github.io/post/faabc621-bd9c-11e9-b52a-878085b5c0f3/","excerpt":"","text":"背景经过了这么多年，集团内的各种系统紊乱复杂，结构数据互相同步，而LDAP服务器内的组织架构早已没人维护。现有需求需要无纸化办公的组织架构数据增量同步到LDAP服务器中。 简单记录下遇到并解决的问题和方法，万一以后又要维护了呢。 LDAP基本概念LDAP采用目录树的模型，下面是一些概念的解释： 目录树：在一个目录服务系统中，整个目录信息集可以表示为一个目录信息树，树中的每个节点是一个条目。 条目：每个条目就是一条记录，每个条目有自己的唯一可区别的名称（DN）。 对象类：与某个实体类型对应的一组属性，对象类是可以继承的，这样父类的必须属性也会被继承下来。 属性：描述条目的某个方面的信息，一个属性由一个属性类型和一个或多个属性值组成，属性有必须属性和非必须属性。 名词 全称 说明 dc Domain Component 域名的部分，其格式是将完整的域名分成几部分，如域名为example.com变成dc=example,dc=com（一条记录的所属位置）。 ou Organization Unit 组织单元，组织单元可以包含多种多个对象（entry），如组织单元名为employee，则ou=employee，那么employee下会有一大堆白给饭桶、精工骨干和划水健将这些实体。 cn Common Name 公共名称，如hmc999（一条记录的名称），则cn=hmc999，该条目可以在ou=employee下。 sn Surname 一般用来表达姓，如”韩”。 dn Distinguished Name 那上面的例子来说，对于hmc999这个实体的定位就是cn=hmc999,ou=employee,dc=example,dc=com，当然可能还会有国家、其他多级。 依赖引入SpringProject已经集成了LDAP组件，直接pom引入即可。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-ldap&lt;/artifactId&gt;&lt;/dependency&gt; 通过使用Spring LDAP类AttributesMapper和LdapTemplate可以很好地减少传统方式的代码量。首先我们可以通过AttributesMapper先构建一个实体，用来收集结果，简单样例如下： 12345678910111213141516171819202122public class DemoAttributeMapper implements AttributesMapper &#123;/** * 将单个Attributes转成单个对象 * @param attrs * @return * @throws NamingException */@Overridepublic Object mapFromAttributes(Attributes attrs) throws javax.naming.NamingException &#123; DemoModel demoModel = new DemoModel(); /** * 通过attr */ if (attrs.get(xxx.name()) != null) &#123; demoModel.setXxx(attrs.get(xxx.name()).get().toString()); &#125; ... return demoModel;&#125; 编写config类，LDAP服务配置在开发环境的application-dev.properties中，通过注解@Value注入。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Configurationpublic class LdapConfiguration &#123; private final Logger log = LoggerFactory.getLogger(this.getClass()); private LdapTemplate ldapTemplate; @Value(&quot;$&#123;spring.ldap.urls&#125;&quot;) private String url; @Value(&quot;$&#123;spring.ldap.base&#125;&quot;) private String base; @Value(&quot;$&#123;spring.ldap.username&#125;&quot;) private String userName; @Value(&quot;$&#123;spring.ldap.password&#125;&quot;) private String passWord; @Bean public LdapContextSource contextSource() &#123; LdapContextSource contextSource = new LdapContextSource(); Map&lt;String, Object&gt; config = new LinkedHashMap&lt;&gt;(16); contextSource.setUrl(url); contextSource.setBase(base); contextSource.setUserDn(userName); contextSource.setPassword(passWord); // 解决乱码的关键一句 config.put(&quot;java.naming.ldap.attributes.binary&quot;, &quot;objectGUID&quot;); contextSource.setPooled(true); contextSource.setBaseEnvironmentProperties(config); log.info(&quot; [ MatthewHan ] : LDAP-Config启动 &quot;); return contextSource; &#125; @Bean public LdapTemplate ldapTemplate() &#123; if (null == ldapTemplate) &#123; ldapTemplate = new LdapTemplate(contextSource()); &#125; return ldapTemplate; &#125;&#125; 需要注意的问题接着就是Ldaptemplate的方法用来增删改查，详细的懒得展开了，有几个点需要注意下： Ldaptemplate需要动态生成DN便于增删改查，因为很多操作都是基于构建baseDN，自己需要更是实际业务情况，编写工具类用于baseDN的生成。 更新操作方法rebind()，其实是先解绑当前实体，在重新绑定，如果该实体存在下级实体，就会throw错误，所以在不确定条目结构时，可以使用ModifyAttributes类来处理。 因为LDAP是树状结构模型，所以在绑定与解绑过程中，一定要注意它是否存在上下级关系，比如在ou=department下存在顶级部门、次级部门和下级部门，deId=003001是deId=003的子部门，如果要解绑整个部门（包括子部门）那么就不能使用unbind()直接解绑deId=003这个实体，但是可以先解绑最下级部门，再一级一级往上解绑。绑定也是一样的原理，先绑定最上级部门，然后再绑定其下级、最下级部门。题外话：讲道理应该有可以直接解绑该实体以及他的全部子实体吧！但是我好像没找到。。 遗留的一个问题，害怕会在项目中会引发墨菲定律的风险，已知一个实体的一个属性deId=003001，包括ou=employee，他的实际DN为deId=003001,deId=003,ou=department...，从DN中我们知道他是属于deId=003的子实体，但是可以通过配置AndFilter配置过滤器，从而使用Ldaptemplate的search方法去定位该实体，却不知道他的DN。。我在Ldaptemplate中未找到一个method，这是个未解决的问题。关于LDAP的内容，整个互联网上也不是太多，社区也不够活跃，希望以后能够知道答案。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Spring-ldap","slug":"Spring-ldap","permalink":"https://matthew-han.github.io/tags/Spring-ldap/"},{"name":"ldap","slug":"ldap","permalink":"https://matthew-han.github.io/tags/ldap/"}]}],"categories":[{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"中间件","slug":"中间件","permalink":"https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Java 技巧","slug":"Java-技巧","permalink":"https://matthew-han.github.io/categories/Java-%E6%8A%80%E5%B7%A7/"},{"name":"设计模式","slug":"设计模式","permalink":"https://matthew-han.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Java技术","slug":"Java技术","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"},{"name":"数据结构","slug":"Java技术/数据结构","permalink":"https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"点滴","slug":"点滴","permalink":"https://matthew-han.github.io/categories/%E7%82%B9%E6%BB%B4/"},{"name":"其他技术","slug":"其他技术","permalink":"https://matthew-han.github.io/categories/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"数组","slug":"数组","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"树","slug":"树","permalink":"https://matthew-han.github.io/tags/%E6%A0%91/"},{"name":"leetcode","slug":"leetcode","permalink":"https://matthew-han.github.io/tags/leetcode/"},{"name":"动态规划","slug":"动态规划","permalink":"https://matthew-han.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"记忆化递归","slug":"记忆化递归","permalink":"https://matthew-han.github.io/tags/%E8%AE%B0%E5%BF%86%E5%8C%96%E9%80%92%E5%BD%92/"},{"name":"Redis","slug":"Redis","permalink":"https://matthew-han.github.io/tags/Redis/"},{"name":"内存","slug":"内存","permalink":"https://matthew-han.github.io/tags/%E5%86%85%E5%AD%98/"},{"name":"队列","slug":"队列","permalink":"https://matthew-han.github.io/tags/%E9%98%9F%E5%88%97/"},{"name":"堆排序","slug":"堆排序","permalink":"https://matthew-han.github.io/tags/%E5%A0%86%E6%8E%92%E5%BA%8F/"},{"name":"位运算","slug":"位运算","permalink":"https://matthew-han.github.io/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"name":"设计模式","slug":"设计模式","permalink":"https://matthew-han.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"装饰器模式","slug":"装饰器模式","permalink":"https://matthew-han.github.io/tags/%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F/"},{"name":"分布式事务","slug":"分布式事务","permalink":"https://matthew-han.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"name":"Seata","slug":"Seata","permalink":"https://matthew-han.github.io/tags/Seata/"},{"name":"中间件","slug":"中间件","permalink":"https://matthew-han.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"字典树","slug":"字典树","permalink":"https://matthew-han.github.io/tags/%E5%AD%97%E5%85%B8%E6%A0%91/"},{"name":"JVM","slug":"JVM","permalink":"https://matthew-han.github.io/tags/JVM/"},{"name":"Java","slug":"Java","permalink":"https://matthew-han.github.io/tags/Java/"},{"name":"内存布局","slug":"内存布局","permalink":"https://matthew-han.github.io/tags/%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/"},{"name":"字节码","slug":"字节码","permalink":"https://matthew-han.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"},{"name":"类加载过程","slug":"类加载过程","permalink":"https://matthew-han.github.io/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B/"},{"name":"GC","slug":"GC","permalink":"https://matthew-han.github.io/tags/GC/"},{"name":"数据库","slug":"数据库","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySql","slug":"MySql","permalink":"https://matthew-han.github.io/tags/MySql/"},{"name":"广度优先搜索","slug":"广度优先搜索","permalink":"https://matthew-han.github.io/tags/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"二叉搜索树","slug":"二叉搜索树","permalink":"https://matthew-han.github.io/tags/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/"},{"name":"二叉树","slug":"二叉树","permalink":"https://matthew-han.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"stack","slug":"stack","permalink":"https://matthew-han.github.io/tags/stack/"},{"name":"深度优先搜索","slug":"深度优先搜索","permalink":"https://matthew-han.github.io/tags/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"栈","slug":"栈","permalink":"https://matthew-han.github.io/tags/%E6%A0%88/"},{"name":"二分法","slug":"二分法","permalink":"https://matthew-han.github.io/tags/%E4%BA%8C%E5%88%86%E6%B3%95/"},{"name":"几何","slug":"几何","permalink":"https://matthew-han.github.io/tags/%E5%87%A0%E4%BD%95/"},{"name":"数学","slug":"数学","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E5%AD%A6/"},{"name":"小顶堆","slug":"小顶堆","permalink":"https://matthew-han.github.io/tags/%E5%B0%8F%E9%A1%B6%E5%A0%86/"},{"name":"Queue","slug":"Queue","permalink":"https://matthew-han.github.io/tags/Queue/"},{"name":"虐猫","slug":"虐猫","permalink":"https://matthew-han.github.io/tags/%E8%99%90%E7%8C%AB/"},{"name":"虐待","slug":"虐待","permalink":"https://matthew-han.github.io/tags/%E8%99%90%E5%BE%85/"},{"name":"Shiro","slug":"Shiro","permalink":"https://matthew-han.github.io/tags/Shiro/"},{"name":"Session","slug":"Session","permalink":"https://matthew-han.github.io/tags/Session/"},{"name":"分布式","slug":"分布式","permalink":"https://matthew-han.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"序列化","slug":"序列化","permalink":"https://matthew-han.github.io/tags/%E5%BA%8F%E5%88%97%E5%8C%96/"},{"name":"笔记","slug":"笔记","permalink":"https://matthew-han.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Easy Coding","slug":"Easy-Coding","permalink":"https://matthew-han.github.io/tags/Easy-Coding/"},{"name":"集合","slug":"集合","permalink":"https://matthew-han.github.io/tags/%E9%9B%86%E5%90%88/"},{"name":"元素","slug":"元素","permalink":"https://matthew-han.github.io/tags/%E5%85%83%E7%B4%A0/"},{"name":"泛型","slug":"泛型","permalink":"https://matthew-han.github.io/tags/%E6%B3%9B%E5%9E%8B/"},{"name":"HashMap","slug":"HashMap","permalink":"https://matthew-han.github.io/tags/HashMap/"},{"name":"ArrayList","slug":"ArrayList","permalink":"https://matthew-han.github.io/tags/ArrayList/"},{"name":"百态","slug":"百态","permalink":"https://matthew-han.github.io/tags/%E7%99%BE%E6%80%81/"},{"name":"多线程","slug":"多线程","permalink":"https://matthew-han.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"并发","slug":"并发","permalink":"https://matthew-han.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"锁","slug":"锁","permalink":"https://matthew-han.github.io/tags/%E9%94%81/"},{"name":"张小龙","slug":"张小龙","permalink":"https://matthew-han.github.io/tags/%E5%BC%A0%E5%B0%8F%E9%BE%99/"},{"name":"公开课","slug":"公开课","permalink":"https://matthew-han.github.io/tags/%E5%85%AC%E5%BC%80%E8%AF%BE/"},{"name":"微信","slug":"微信","permalink":"https://matthew-han.github.io/tags/%E5%BE%AE%E4%BF%A1/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://matthew-han.github.io/tags/Mybatis/"},{"name":"数据库映射","slug":"数据库映射","permalink":"https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%A0%E5%B0%84/"},{"name":"线程池","slug":"线程池","permalink":"https://matthew-han.github.io/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"name":"生活","slug":"生活","permalink":"https://matthew-han.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"轨迹","slug":"轨迹","permalink":"https://matthew-han.github.io/tags/%E8%BD%A8%E8%BF%B9/"},{"name":"日记","slug":"日记","permalink":"https://matthew-han.github.io/tags/%E6%97%A5%E8%AE%B0/"},{"name":"消息","slug":"消息","permalink":"https://matthew-han.github.io/tags/%E6%B6%88%E6%81%AF/"},{"name":"消息队列","slug":"消息队列","permalink":"https://matthew-han.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"工具推荐","slug":"工具推荐","permalink":"https://matthew-han.github.io/tags/%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90/"},{"name":"生产力","slug":"生产力","permalink":"https://matthew-han.github.io/tags/%E7%94%9F%E4%BA%A7%E5%8A%9B/"},{"name":"教程","slug":"教程","permalink":"https://matthew-han.github.io/tags/%E6%95%99%E7%A8%8B/"},{"name":"redis","slug":"redis","permalink":"https://matthew-han.github.io/tags/redis/"},{"name":"集群","slug":"集群","permalink":"https://matthew-han.github.io/tags/%E9%9B%86%E7%BE%A4/"},{"name":"CORS","slug":"CORS","permalink":"https://matthew-han.github.io/tags/CORS/"},{"name":"Spring","slug":"Spring","permalink":"https://matthew-han.github.io/tags/Spring/"},{"name":"CurrentUser","slug":"CurrentUser","permalink":"https://matthew-han.github.io/tags/CurrentUser/"},{"name":"领域模型","slug":"领域模型","permalink":"https://matthew-han.github.io/tags/%E9%A2%86%E5%9F%9F%E6%A8%A1%E5%9E%8B/"},{"name":"DDD","slug":"DDD","permalink":"https://matthew-han.github.io/tags/DDD/"},{"name":"架构模式","slug":"架构模式","permalink":"https://matthew-han.github.io/tags/%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%BC%8F/"},{"name":"异常","slug":"异常","permalink":"https://matthew-han.github.io/tags/%E5%BC%82%E5%B8%B8/"},{"name":"日志","slug":"日志","permalink":"https://matthew-han.github.io/tags/%E6%97%A5%E5%BF%97/"},{"name":"代码风格","slug":"代码风格","permalink":"https://matthew-han.github.io/tags/%E4%BB%A3%E7%A0%81%E9%A3%8E%E6%A0%BC/"},{"name":"系统规范","slug":"系统规范","permalink":"https://matthew-han.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%A7%84%E8%8C%83/"},{"name":"面向对象","slug":"面向对象","permalink":"https://matthew-han.github.io/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"},{"name":"方法","slug":"方法","permalink":"https://matthew-han.github.io/tags/%E6%96%B9%E6%B3%95/"},{"name":"类","slug":"类","permalink":"https://matthew-han.github.io/tags/%E7%B1%BB/"},{"name":"学习计划","slug":"学习计划","permalink":"https://matthew-han.github.io/tags/%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/"},{"name":"工厂模式","slug":"工厂模式","permalink":"https://matthew-han.github.io/tags/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"},{"name":"Maven","slug":"Maven","permalink":"https://matthew-han.github.io/tags/Maven/"},{"name":"构建工具","slug":"构建工具","permalink":"https://matthew-han.github.io/tags/%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7/"},{"name":"单例模式","slug":"单例模式","permalink":"https://matthew-han.github.io/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"name":"适配器模式","slug":"适配器模式","permalink":"https://matthew-han.github.io/tags/%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/"},{"name":"快速排序","slug":"快速排序","permalink":"https://matthew-han.github.io/tags/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"name":"对象存储","slug":"对象存储","permalink":"https://matthew-han.github.io/tags/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/"},{"name":"存储服务","slug":"存储服务","permalink":"https://matthew-han.github.io/tags/%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1/"},{"name":"阿里云","slug":"阿里云","permalink":"https://matthew-han.github.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"},{"name":"Swagger","slug":"Swagger","permalink":"https://matthew-han.github.io/tags/Swagger/"},{"name":"Spring-ldap","slug":"Spring-ldap","permalink":"https://matthew-han.github.io/tags/Spring-ldap/"},{"name":"ldap","slug":"ldap","permalink":"https://matthew-han.github.io/tags/ldap/"}]}