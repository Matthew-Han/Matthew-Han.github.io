<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Espada</title>
  <icon>https://www.gravatar.com/avatar/1f0162ac2536ccb6c014d8841622b4d4</icon>
  <subtitle>酸萝卜 ♂ 别吃</subtitle>
  <link href="https://matthew-han.github.io/atom.xml" rel="self"/>
  
  <link href="https://matthew-han.github.io/"/>
  <updated>2025-09-05T09:47:25.608Z</updated>
  <id>https://matthew-han.github.io/</id>
  
  <author>
    <name>MatthewHan</name>
    <email>freedom233@foxmail.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>蓄水池抽样</title>
    <link href="https://matthew-han.github.io/post/0399dca0-c447-11ec-9a1f-a97b5b48cbc0/"/>
    <id>https://matthew-han.github.io/post/0399dca0-c447-11ec-9a1f-a97b5b48cbc0/</id>
    <published>2022-04-25T03:23:02.000Z</published>
    <updated>2025-09-05T09:47:25.608Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>水塘抽样算法，正好今天的「每日一题」是考这个算法，不写个笔记记录下感觉又快忘完了。</p></blockquote><h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>说白了就是有点像时间换空间？在一段超长且长度未知的数据流中，如果需要以一个相同的概率去实时抽样，则需要用到该算法。<br>如果有一个数组 <code>data</code> ，需要随机跳出一个元素，我们之前都是通过 <code>random.nextInt(data.length)</code> 来得到这个元素的下标，从而得到该元素值。但是遇到需要在大小为 $n$ 的数组中有 $k$ 个值是相同的元素，需要以相同概率取出其中一个元素这样的问题，那就不得不先预处理，将这 $k$ 个值相同元素都放到另外的空间中，然后在调用 <code>random</code> 函数进行抽取。但如果是水塘抽样则可以做到像迭代器一样，随时可以停止，在前面的抽样的过程中，保证每个元素时被以相同的概率抽到。<br>该算法的核心就是数学公式，在一次遍历中，可以做到保证每个需要被取出的元素抽到的概率是 $\frac1k$ 。<br>简单来说就是判断 <code>random.nextInt(cnt) == 0</code> 该条件是否成立， <code>cnt</code> 等于当前加入抽奖池的个数，当 <code>cnt</code> 为 $1$ 时， 第一个元素被选中的概率是 $\frac11$ ；当 <code>cnt</code> 为 $2$ 时，第 $2$ 个元素被选中概率是 $\frac12$ ；当 <code>cnt</code> 为 $3$ 是，第 $3$ 个元素被选中概率是 $\frac13$ ；而且它并不会影响之前的元素是否被选中。当第 $k$ 个元素的概率是 $\frac1k$，而第 $1$ 个元素被选中的概率就等于 $$\frac11 \times (1 - \frac12) \times (1 - \frac13) \times ··· \times (1 - \frac1k) &#x3D; \frac1k$$<br>所以每个元素被选中的概率都是 $\frac1k$。这样就完成了随机抽样，并且可以对持续的流进行抽样。</p><h1 id="Problem-Description"><a href="#Problem-Description" class="headerlink" title="Problem Description"></a>Problem Description</h1><p>给定一个由非重叠的轴对齐矩形的数组 <code>rects</code> ，其中 <code>rects[i] = [ai, bi, xi, yi]</code> 表示 <code>(ai, bi)</code> 是第 <code>i</code> 个矩形的左下角点，<code>(xi, yi)</code> 是第 <code>i</code> 个矩形的右上角角点。设计一个算法来挑选一个随机整数点内的空间所覆盖的一个给定的矩形。矩形周长上的一个点包含在矩形覆盖的空间中。</p><p>在一个给定的矩形覆盖的空间内任何整数点都有可能被返回。</p><p>请注意 ，整数点是具有整数坐标的点。</p><p>实现 <code>Solution</code> 类:</p><ul><li><code>Solution(int[][] rects)</code> 用给定的矩形数组 <code>rects</code> 初始化对象。</li><li><code>int[] pick()</code> 返回一个随机的整数点 <code>[u, v]</code> 在给定的矩形所覆盖的空间内。</li></ul><h2 id="note"><a href="#note" class="headerlink" title="note"></a>note</h2><ul><li><code>1 &lt;= rects.length &lt;= 100</code></li><li><code>rects[i].length == 4</code></li><li><code>-109 &lt;= ai &lt; xi &lt;= 109</code></li><li><code>-109 &lt;= bi &lt; yi &lt;= 109</code></li><li><code>xi - ai &lt;= 2000</code></li><li><code>yi - bi &lt;= 2000</code></li><li>所有的矩形不重叠。</li><li><code>pick</code> 最多被调用 <code>104</code> 次。</li></ul><h2 id="e-g"><a href="#e-g" class="headerlink" title="e.g."></a>e.g.</h2><p><img src="https://assets.leetcode.com/uploads/2021/07/24/lc-pickrandomrec.jpg" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">输入: </span><br><span class="line">[&quot;Solution&quot;,&quot;pick&quot;,&quot;pick&quot;,&quot;pick&quot;,&quot;pick&quot;,&quot;pick&quot;]</span><br><span class="line">[[[[-2,-2,-1,-1],[1,0,3,0]]],[],[],[],[],[]]</span><br><span class="line">输出: </span><br><span class="line">[null,[-1,-2],[2,0],[-2,-1],[3,0],[-2,-2]</span><br><span class="line"></span><br><span class="line">解释：</span><br><span class="line">Solution solution = new Solution([[-2, -2, 1, 1], [2, 2, 4, 6]]);</span><br><span class="line">solution.pick(); // 返回 [1, -2]</span><br><span class="line">solution.pick(); // 返回 [1, -1]</span><br><span class="line">solution.pick(); // 返回 [-1, -2]</span><br><span class="line">solution.pick(); // 返回 [-2, -2]</span><br><span class="line">solution.pick(); // 返回 [0, 0]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h1><p>只需要将所有点取出，利用 <code>TreeSet</code> 的堆排序类似二分查找随机到一个矩形，再对该矩形的 <code>x, y</code> 的最大最小值进行蓄水池抽样即可，注意边长上的点也是符合条件的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> max;</span><br><span class="line">    <span class="type">int</span>[][] rects;</span><br><span class="line">    TreeMap&lt;Integer, Integer&gt; map;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Solution</span><span class="params">(<span class="type">int</span>[][] rects)</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">prev</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">this</span>.rects = rects;</span><br><span class="line">        <span class="built_in">this</span>.map = <span class="keyword">new</span> <span class="title class_">TreeMap</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; rects.length; i++) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">curr</span> <span class="operator">=</span> (rects[i][<span class="number">2</span>] - rects[i][<span class="number">0</span>] + <span class="number">1</span>) * (rects[i][<span class="number">3</span>] - rects[i][<span class="number">1</span>] + <span class="number">1</span>);</span><br><span class="line">            map.put(curr + prev, i);</span><br><span class="line">            prev += curr;</span><br><span class="line">            <span class="built_in">this</span>.max = prev;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span>[] pick() &#123;</span><br><span class="line">        Map.Entry&lt;Integer, Integer&gt; e = map.higherEntry(<span class="keyword">new</span> <span class="title class_">Random</span>().nextInt(max));</span><br><span class="line">        <span class="type">Integer</span> <span class="variable">idx</span> <span class="operator">=</span> e.getValue();</span><br><span class="line">        <span class="type">int</span>[] rect = rects[idx];</span><br><span class="line">        <span class="type">int</span> <span class="variable">x</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">y</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> rect[<span class="number">0</span>]; i &lt;= rect[<span class="number">2</span>]; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (ThreadLocalRandom.current().nextInt(i - rect[<span class="number">0</span>] + <span class="number">1</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">                x = i;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> rect[<span class="number">1</span>]; i &lt;= rect[<span class="number">3</span>]; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (ThreadLocalRandom.current().nextInt(i - rect[<span class="number">1</span>] + <span class="number">1</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">                y = i;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">int</span>[]&#123;x, y&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="算法" scheme="https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="数据结构" scheme="https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    <category term="算法" scheme="https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>数据结构：树状数组</title>
    <link href="https://matthew-han.github.io/post/1c40fd80-b621-11ec-9548-87744b45139b/"/>
    <id>https://matthew-han.github.io/post/1c40fd80-b621-11ec-9548-87744b45139b/</id>
    <published>2022-04-07T03:16:26.000Z</published>
    <updated>2025-09-05T07:15:47.365Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>首先，树状数组的应用场景在哪里呢？这里摘抄三叶姐题解中的一段：</p><blockquote><p>针对不同的题目，我们有不同的方案可以选择（假设我们有一个数组）：</p><p>数组不变，求区间和：「前缀和」、「树状数组」、「线段树」<br>多次修改某个数（单点），求区间和：「树状数组」、「线段树」<br>多次修改某个区间，输出最终结果：「差分」<br>多次修改某个区间，求区间和：「线段树」、「树状数组」（看修改区间范围大小）<br>多次将某个区间变成同一个数，求区间和：「线段树」、「树状数组」（看修改区间范围大小）</p><p>作者：<a href="https://leetcode-cn.com/u/ac_oier/">宫水三叶</a></p></blockquote><p>看起来说前缀和搞不定的可以用树状数组来解决。</p><p>那么，树状数组是一种什么样的结构呢？首先它本身还是数组，不是像二叉树、字典树那样真正意义上的树了。因为没有必要做成那样的数据结构，它本身就是利用二进制的特性的来实现<strong>查询</strong>和<strong>更新</strong>操作的，数组结构已经完成可以满足<strong>分块</strong>处理的需求（太强了）。</p><p>假设有一个数组 <code>arr = &#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ,11, 12, 13, 14, 15, 16&#125;</code>，那么树状数组 <code>tree</code> 在实际的结构中可能存储的是如下的数据：</p><p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/BinaryIndexedTree/tree-array.png" alt="img"></p><p>他看来还是像一颗二叉树，其中（下标从 <code>1</code> 开始）</p><ul><li><code>tree[1] = arr[1]</code></li><li><code>tree[2] = arr[1] + arr[2]</code></li><li><code>tree[3] = arr[3]</code></li><li><code>tree[4] = tree[2] + tree[3] + arr[4] = arr[1] + arr[2] + arr[3] + arr[4]</code></li><li>…</li></ul><p>简单理解 <code>tree[i]</code> 就等于其子节点的和再加上对应数组坐标的值。那么这个结构能够帮助我们做什么呢？前面我们提到了树状数组本身就是利用二进制的特性。其中这里有个算法 <code>lowbit(int x)</code>，用于取出 <code>x</code> 的最低位 <code>1</code>。</p><p>比如 $9$ 的 二进制是 $1001$，他的 <code>lowbit</code> 就是 $1$，$10$ 的二进制是 $1010$，他的 <code>lowbit</code> 就是 $10$ 也就是 $2$。他的算法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">lowbit</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> x &amp; -x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我在 Intellij IDEA 中打了一个类名，GitHub 的 Copilot 就马上就帮我自动补全这个算法了。。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/BinaryIndexedTree/image-20220407154704044.png" style="zoom:50%;" /><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/BinaryIndexedTree/Xnip2022-04-07_16-04-41.png" style="zoom:50%;" /><p>如果有一个前缀和的数组 <code>a</code>，我们求 $l$ 到 $r$ 的区间怎么求呢？答案一般会是 <code>a[r] - a[l - 1] (l &gt;= 1)</code> 或者 <code>a[r + 1] - a[l]</code> 之类的，其实树状数组也是利用 <code>lowbit</code> 算了个前缀和，但是它的时间复杂度不是 $O(n)$，而是 $O(logn)$。</p><p>假如现在要做一个更新操作，将 $idx$ 为 $5$ 的位置更新成 $val$，如果是前缀和数组，就需要从 $5$ 到 $16$ 区间的所有前缀和都更新一遍，但是对于树状数组来说，它的过程就是如图上所示只需要把 $5、6、8、16$  这些节点更新了就行，因为他们的值都是由 $5$ 累加得到的。两者的代码:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">_updateByPre</span><span class="params">(<span class="type">int</span> idx, <span class="type">int</span> val)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> idx; i &lt; tree.length; i++) &#123;</span><br><span class="line">        tree[i] += val - arr[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">_updateByBinaryIndexedTree</span><span class="params">(<span class="type">int</span> idx, <span class="type">int</span> val)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> idx; i &lt; tree.length; i += lowbit(i)) &#123;</span><br><span class="line">        tree[i] += val - arr[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20200717113236761.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Jlc3Rzb3J0,size_16,color_FFFFFF,t_70" alt="img"></p><p>如果是查询呢？假设我想查找 $idx &#x3D; 15$ 的前缀和，对于前缀和数组可以在 $O(1)$ 的情况下直接得到结果，而树状数组还是得需要 $O(logn)$ 的时间复杂度。树状数组需要把 $15、14、12、8$ 这些节点的值都加起来才能得到 $idx &#x3D; 15$ 的前缀和。两者的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">_queryByPre</span><span class="params">(<span class="type">int</span> idx)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> tree[idx];</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">_queryByBinaryIndexedTree</span><span class="params">(<span class="type">int</span> idx)</span> &#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> idx; i &gt;= <span class="number">0</span>; i -= lowbit(i)) &#123;</span><br><span class="line">        sum += tree[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>应用在题目中，求区间的和树状数组怎么做呢？那就是查找到两个端点的前缀和然后相减。树状数组模板代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> 默认模板;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> &lt;a href=&quot;https://github.com/Matthew-Han&quot;&gt;Matthew Han&lt;/a&gt;</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2022/4/7 16:03 07</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 1.0</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BinaryIndexedTree</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span>[] tree;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">BinaryIndexedTree</span><span class="params">(<span class="type">int</span>[] arr)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.tree = <span class="keyword">new</span> <span class="title class_">int</span>[arr.length + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; arr.length; i++) &#123;</span><br><span class="line">            update(i + <span class="number">1</span>, arr[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">update</span><span class="params">(<span class="type">int</span> idx, <span class="type">int</span> delta)</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> idx; i &lt; tree.length; i += lowBit(i)) &#123;</span><br><span class="line">            tree[i] += delta;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">query</span><span class="params">(<span class="type">int</span> idx)</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">res</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> idx; i &gt; <span class="number">0</span>; i -= lowBit(i)) &#123;</span><br><span class="line">            res += tree[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">query</span><span class="params">(<span class="type">int</span> left, <span class="type">int</span> right)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> query(right + <span class="number">1</span>) - query(left);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">lowBit</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> x &amp; -x;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Arrays.toString(tree);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>利用 <code>update</code> 方法完成对原始数组初始化前缀和相加，其中注意不能从 <code>0</code> 开始，不然会无限循环，因为 <code>lowBit(0) = 0</code>。</p><h1 id="Problem-Description"><a href="#Problem-Description" class="headerlink" title="Problem Description"></a>Problem Description</h1><p>给你一个数组 <code>nums</code> ，请你完成两类查询。</p><ul><li>其中一类查询要求 更新 数组 <code>nums</code> 下标对应的值</li><li>另一类查询要求返回数组 <code>nums</code> 中索引 <code>left</code> 和索引 <code>right</code> 之间（ 包含 ）的 <code>nums</code> 元素的 和 ，其中 <code>left &lt;= right</code></li></ul><p>实现 <code>NumArray</code> 类：</p><ul><li><code>NumArray(int[] nums)</code> 用整数数组 <code>nums</code> 初始化对象</li><li><code>void update(int index, int val)</code> 将 <code>nums[index]</code> 的值 更新 为 <code>val</code></li><li><code>int sumRange(int left, int right)</code> 返回数组 nums 中索引 <code>left</code> 和索引 <code>right</code> 之间（ 包含 ）的 <code>nums</code> 元素的 和 （即，<code>nums[left] + nums[left + 1], ..., nums[right]</code>）</li></ul><h2 id="note"><a href="#note" class="headerlink" title="note"></a>note</h2><ul><li><code>1 &lt;= nums.length &lt;= 3 * 104</code></li><li><code>-100 &lt;= nums[i] &lt;= 100</code></li><li><code>0 &lt;= index &lt; nums.length</code></li><li><code>-100 &lt;= val &lt;= 100</code></li><li><code>0 &lt;= left &lt;= right &lt; nums.length</code></li><li>调用 <code>update</code> 和 <code>sumRange</code> 方法次数不大于 <code>3 * 104 </code></li></ul><h2 id="e-g"><a href="#e-g" class="headerlink" title="e.g."></a>e.g.</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">输入：</span><br><span class="line">[&quot;NumArray&quot;, &quot;sumRange&quot;, &quot;update&quot;, &quot;sumRange&quot;]</span><br><span class="line">[[[1, 3, 5]], [0, 2], [1, 2], [0, 2]]</span><br><span class="line">输出：</span><br><span class="line">[null, 9, null, 8]</span><br><span class="line"></span><br><span class="line">解释：</span><br><span class="line">NumArray numArray = new NumArray([1, 3, 5]);</span><br><span class="line">numArray.sumRange(0, 2); // 返回 1 + 3 + 5 = 9</span><br><span class="line">numArray.update(1, 2);   // nums = [1,2,5]</span><br><span class="line">numArray.sumRange(0, 2); // 返回 1 + 2 + 5 = 8</span><br></pre></td></tr></table></figure><h1 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h1><p>树状数组可以在比较小的时间复杂度下解决这一题：<a href="https://leetcode-cn.com/problems/range-sum-query-mutable/">#307 区域和检索 - 数组可修改</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NumArray</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span>[] nums;</span><br><span class="line">    BinaryIndexedTree bit;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">NumArray</span><span class="params">(<span class="type">int</span>[] nums)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.nums = nums;</span><br><span class="line">        <span class="built_in">this</span>.bit = <span class="keyword">new</span> <span class="title class_">BinaryIndexedTree</span>(nums);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">update</span><span class="params">(<span class="type">int</span> index, <span class="type">int</span> val)</span> &#123;</span><br><span class="line">        bit.update(index + <span class="number">1</span>, val - nums[index]);</span><br><span class="line">        nums[index] = val;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">sumRange</span><span class="params">(<span class="type">int</span> left, <span class="type">int</span> right)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> bit.query(left, right);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="算法" scheme="https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="数据结构" scheme="https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    <category term="数组" scheme="https://matthew-han.github.io/tags/%E6%95%B0%E7%BB%84/"/>
    
    <category term="树" scheme="https://matthew-han.github.io/tags/%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>力扣杯秋季编程大赛 2021 战队赛</title>
    <link href="https://matthew-han.github.io/post/25c59040-2fea-11ec-a701-53779506e8d2/"/>
    <id>https://matthew-han.github.io/post/25c59040-2fea-11ec-a701-53779506e8d2/</id>
    <published>2021-10-18T08:05:24.000Z</published>
    <updated>2025-09-03T02:52:50.977Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="0x00"><a href="#0x00" class="headerlink" title="0x00"></a>0x00</h1><p>第一次和小伙伴一起参加战队赛，根据以往经验以为只能做出来一题，结果还真就一题。但是第一题实在是太白给了，都不能算题，所以说相当于一题都没做出来。</p><p>坐牢 3 小时，不过我对第二题的印象很深刻，之前对于图中判环、跳环的问题一直处理不好，经此一役，不再害怕。</p><h1 id="0x01"><a href="#0x01" class="headerlink" title="0x01"></a>0x01</h1><h3 id="第-0-题：开幕式焰火"><a href="#第-0-题：开幕式焰火" class="headerlink" title="第 0 题：开幕式焰火"></a>第 0 题：开幕式焰火</h3><p>沾点白给了，一开始觉得应该没这么简单，还反复检查确认，多少沾点懦弱哥了，递归一套就完事了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Lcp44</span> &#123;</span><br><span class="line"></span><br><span class="line">    Set&lt;Integer&gt; set;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 开幕式火焰</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> root</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">numColor</span><span class="params">(TreeNode root)</span> &#123;</span><br><span class="line">        set = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;();</span><br><span class="line">        dfs(root);</span><br><span class="line">        <span class="keyword">return</span> set.size();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">dfs</span><span class="params">(TreeNode root)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (root == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        set.add(root.val);</span><br><span class="line">        dfs(root.left);</span><br><span class="line">        dfs(root.right);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="第-1-题：自行车炫技赛场"><a href="#第-1-题：自行车炫技赛场" class="headerlink" title="第 1 题：自行车炫技赛场"></a>第 1 题：自行车炫技赛场</h3><p>这题 byd 是真难读题啊，和小伙伴解题过程中碰到了一个小问题，解决了又来一个。不是 <code>Wrong Answer</code> 、<code>Time Limit Exceeded</code> 就是 <code>Runtime Error</code> 到比赛结束了都一致认为只要存在高度差速度就肯定会一直下降。其实，速度不一定会一直降的。可能会出现速度 <code>+1</code>、<code>-1</code> 一直重复走的情况。所以难点就是如何不走重复路，如果每次递归都开一个 <code>vis</code> 对象去判重的话，内存直接爆了，所以需要一个三维数组，三个向量分别是 <code>x</code>、 <code>y</code>、 <code>v</code> ，其中 <code>x</code>、<code>y</code> 是场地坐标，<code>v</code> 是速度。三个向量确定一个唯一值，重复跳出。我这里用的是 <code>HashSet</code>，比三维数组快一点。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span>[] dx = &#123;-<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>&#125;;</span><br><span class="line">    <span class="type">int</span>[] dy = &#123;<span class="number">0</span>, <span class="number">0</span>, -<span class="number">1</span>, <span class="number">1</span>&#125;;</span><br><span class="line">    List&lt;<span class="type">int</span>[]&gt; ans;</span><br><span class="line">    Set&lt;String&gt; mem;</span><br><span class="line">    <span class="type">boolean</span>[][] global;</span><br><span class="line">    <span class="type">int</span>[] p;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span>[][] bicycleYard(<span class="type">int</span>[] position, <span class="type">int</span>[][] terrain, <span class="type">int</span>[][] obstacle) &#123;</span><br><span class="line">        ans = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        mem = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;();</span><br><span class="line">        global = <span class="keyword">new</span> <span class="title class_">boolean</span>[terrain.length][terrain[<span class="number">0</span>].length];</span><br><span class="line">        p = position;</span><br><span class="line">        bfs(<span class="number">1</span>, position[<span class="number">0</span>], position[<span class="number">1</span>], terrain, obstacle);</span><br><span class="line">        <span class="type">int</span>[][] res = <span class="keyword">new</span> <span class="title class_">int</span>[ans.size()][<span class="number">2</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; ans.size(); i++) &#123;</span><br><span class="line">            res[i] = ans.get(i);</span><br><span class="line">        &#125;</span><br><span class="line">        Arrays.sort(res, (o1, o2) -&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span> (o1[<span class="number">0</span>] == o2[<span class="number">0</span>]) &#123;</span><br><span class="line">                <span class="keyword">return</span> Integer.compare(o1[<span class="number">1</span>], o2[<span class="number">1</span>]);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> Integer.compare(o1[<span class="number">0</span>], o2[<span class="number">0</span>]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">bfs</span><span class="params">(<span class="type">int</span> curr, <span class="type">int</span> x, <span class="type">int</span> y, <span class="type">int</span>[][] terrain, <span class="type">int</span>[][] obstacle)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (x &gt;= <span class="number">0</span> &amp;&amp; y &gt;= <span class="number">0</span> &amp;&amp; x &lt; terrain.length &amp;&amp; y &lt; terrain[<span class="number">0</span>].length) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">4</span>; i++) &#123;</span><br><span class="line">                <span class="type">int</span> <span class="variable">newX</span> <span class="operator">=</span> x + dx[i];</span><br><span class="line">                <span class="type">int</span> <span class="variable">newY</span> <span class="operator">=</span> y + dy[i];</span><br><span class="line">                <span class="keyword">if</span> (newX &gt;= <span class="number">0</span> &amp;&amp; newY &gt;= <span class="number">0</span> &amp;&amp; newX &lt; terrain.length &amp;&amp; newY &lt; terrain[<span class="number">0</span>].length) &#123;</span><br><span class="line">                    <span class="type">int</span> <span class="variable">next</span> <span class="operator">=</span> curr + terrain[x][y] - terrain[newX][newY] - obstacle[newX][newY];</span><br><span class="line">                    <span class="comment">// i, j, v 作为唯一 key</span></span><br><span class="line">                    <span class="type">String</span> <span class="variable">k</span> <span class="operator">=</span> newX + <span class="string">&quot;-&quot;</span> + newY + <span class="string">&quot;-&quot;</span> + next;</span><br><span class="line">                    <span class="keyword">if</span> (mem.contains(k)) &#123;</span><br><span class="line">                        <span class="keyword">continue</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                    mem.add(k);</span><br><span class="line">                    <span class="keyword">if</span> (next &gt;= <span class="number">1</span>) &#123;</span><br><span class="line">                        <span class="keyword">if</span> (next == <span class="number">1</span> &amp;&amp; (newX != p[<span class="number">0</span>] || newY != p[<span class="number">1</span>]) &amp;&amp; !global[newX][newY]) &#123;</span><br><span class="line">                            global[newX][newY] = <span class="literal">true</span>;</span><br><span class="line">                            ans.add(<span class="keyword">new</span> <span class="title class_">int</span>[]&#123;newX, newY&#125;);</span><br><span class="line">                        &#125;</span><br><span class="line">                        bfs(next, newX, newY, terrain, obstacle);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第一次组队参加战队赛，虽然结果不太理想，但是和小伙伴一起思考，一起交流的过程还是非常美妙的。想起了 OG 战队的 ceb 在 Ti8 Grand Finals 最后一场开始前的一句话：</p><blockquote><p>Lose together, win together, slay together, slay together, slay together.</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="算法" scheme="https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="数据结构" scheme="https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    <category term="算法" scheme="https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="leetcode" scheme="https://matthew-han.github.io/tags/leetcode/"/>
    
  </entry>
  
  <entry>
    <title>LeetCode #1986 完成任务的最少工作时间段</title>
    <link href="https://matthew-han.github.io/post/041e2f70-0c8a-11ec-8fd3-4363d76d2529/"/>
    <id>https://matthew-han.github.io/post/041e2f70-0c8a-11ec-8fd3-4363d76d2529/</id>
    <published>2021-09-03T07:39:05.000Z</published>
    <updated>2025-09-03T02:52:50.971Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Problem-Description"><a href="#Problem-Description" class="headerlink" title="Problem Description"></a>Problem Description</h1><p>你被安排了 <code>n</code> 个任务。任务需要花费的时间用长度为 <code>n</code> 的整数数组 <code>tasks</code> 表示，第 <code>i</code> 个任务需要花费 <code>tasks[i]</code> 小时完成。一个 <strong>工作时间段</strong> 中，你可以 <strong>至多</strong> 连续工作 <code>sessionTime</code> 个小时，然后休息一会儿。</p><p>你需要按照如下条件完成给定任务：</p><ul><li><p>如果你在某一个时间段开始一个任务，你需要在 <strong>同一个</strong> 时间段完成它。</p></li><li><p>完成一个任务后，你可以 <strong>立马</strong> 开始一个新的任务。</p></li><li><p>你可以按 <strong>任意顺序</strong> 完成任务。</p></li></ul><p>给你 <code>tasks</code> 和 <code>sessionTime</code> ，请你按照上述要求，返回完成所有任务所需要的 <strong>最少</strong> 数目的 工作时间段 。</p><p>测试数据保证 <code>sessionTime</code> 大于等于 <code>tasks[i]</code> 中的 <strong>最大值</strong> 。</p><h2 id="note"><a href="#note" class="headerlink" title="note"></a>note</h2><ul><li><code>n == tasks.length</code></li><li><code>1 &lt;= n &lt;= 14</code></li><li><code>1 &lt;= tasks[i] &lt;= 10</code></li><li><code>max(tasks[i]) &lt;= sessionTime &lt;= 15</code></li></ul><h2 id="e-g"><a href="#e-g" class="headerlink" title="e.g."></a>e.g.</h2><h3 id="示例-1："><a href="#示例-1：" class="headerlink" title="示例 1："></a><strong>示例 1：</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">输入：tasks = [1,2,3], sessionTime = 3</span><br><span class="line">输出：2</span><br><span class="line">解释：你可以在两个工作时间段内完成所有任务。</span><br><span class="line">- 第一个工作时间段：完成第一和第二个任务，花费 1 + 2 = 3 小时。</span><br><span class="line">- 第二个工作时间段：完成第三个任务，花费 3 小时。</span><br></pre></td></tr></table></figure><h3 id="示例-2："><a href="#示例-2：" class="headerlink" title="示例 2："></a><strong>示例 2：</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">输入：tasks = [3,1,3,1,1], sessionTime = 8</span><br><span class="line">输出：2</span><br><span class="line">解释：你可以在两个工作时间段内完成所有任务。</span><br><span class="line">- 第一个工作时间段：完成除了最后一个任务以外的所有任务，花费 3 + 1 + 3 + 1 = 8 小  时。</span><br><span class="line">- 第二个工作时间段，完成最后一个任务，花费 1 小时。</span><br></pre></td></tr></table></figure><h3 id="示例-3："><a href="#示例-3：" class="headerlink" title="示例 3："></a><strong>示例 3：</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：tasks = [1,2,3,4,5], sessionTime = 15</span><br><span class="line">输出：1</span><br><span class="line">解释：你可以在一个工作时间段以内完成所有任务。</span><br></pre></td></tr></table></figure><h1 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h1><p>第 256 场周赛周赛第三题，那天早上没爬起来，今天尝试做下，感觉应该是状态压缩的动态规划。不过动态规划始终不会写，就尝试先画递归树，发现重复元素的路径可以压缩（一直没学过状态压缩，难道这就是状态压缩？）就先写个桶记录元素和元素个数，这样就不会走重复路径了。</p><p>然后写了个有点别扭的回溯，居然一次过了，看来以后 dp 的题，全用记忆化递归做了是要。。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">ans</span> <span class="operator">=</span> <span class="number">0x3f3f3f3f</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">minSessions</span><span class="params">(<span class="type">int</span>[] tasks, <span class="type">int</span> sessionTime)</span> &#123;</span><br><span class="line">        <span class="type">int</span>[] bucket = <span class="keyword">new</span> <span class="title class_">int</span>[<span class="number">11</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> task : tasks) &#123;</span><br><span class="line">            bucket[task]++;</span><br><span class="line">        &#125;</span><br><span class="line">        dfs(bucket, <span class="number">0</span>, sessionTime, <span class="number">0</span>, tasks.length);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">dfs</span><span class="params">(<span class="type">int</span>[] bucket, <span class="type">int</span> sum, <span class="type">int</span> sessionTime, <span class="type">int</span> cnt, <span class="type">int</span> len)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (len == <span class="number">0</span>) &#123;</span><br><span class="line">            ans = Math.min(cnt + <span class="number">1</span>, ans);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">flag</span> <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt; bucket.length; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (bucket[i] &gt; <span class="number">0</span> &amp;&amp; i + sum &lt;= sessionTime) &#123;</span><br><span class="line">                flag = <span class="literal">false</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (flag) &#123;</span><br><span class="line">            dfs(bucket, <span class="number">0</span>, sessionTime, cnt + <span class="number">1</span>, len);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt; bucket.length; i++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (bucket[i] &gt; <span class="number">0</span> &amp;&amp; i + sum &lt;= sessionTime) &#123;</span><br><span class="line">                    bucket[i]--;</span><br><span class="line">                    dfs(bucket, i + sum, sessionTime, cnt, len - <span class="number">1</span>);</span><br><span class="line">                    bucket[i]++;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="算法" scheme="https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="数据结构" scheme="https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    <category term="算法" scheme="https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="leetcode" scheme="https://matthew-han.github.io/tags/leetcode/"/>
    
    <category term="动态规划" scheme="https://matthew-han.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    <category term="记忆化递归" scheme="https://matthew-han.github.io/tags/%E8%AE%B0%E5%BF%86%E5%8C%96%E9%80%92%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>LeetCode #1981 最小化目标值与所选元素的差</title>
    <link href="https://matthew-han.github.io/post/b26c6980-04af-11ec-b84f-7162fcaf05f2/"/>
    <id>https://matthew-han.github.io/post/b26c6980-04af-11ec-b84f-7162fcaf05f2/</id>
    <published>2021-08-24T07:48:40.000Z</published>
    <updated>2025-09-03T02:52:50.971Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Problem-Description"><a href="#Problem-Description" class="headerlink" title="Problem Description"></a>Problem Description</h1><p>给你一个大小为 <code>m x n</code> 的整数矩阵 <code>mat</code> 和一个整数 <code>target</code> 。</p><p>从矩阵的 <strong>每一行</strong> 中选择一个整数，你的目标是 <strong>最小化</strong> 所有选中元素之 <strong>和</strong> 与目标值 <code>target</code> 的 <strong>绝对差</strong> 。</p><p>返回 <strong>最小的绝对差</strong> 。</p><p><code>a</code> 和 <code>b</code> 两数字的 <strong>绝对差</strong> 是 <code>a - b</code> 的绝对值。</p><h2 id="note"><a href="#note" class="headerlink" title="note"></a>note</h2><ul><li><code>m == mat.length</code></li><li><code>n == mat[i].length</code></li><li><code>1 &lt;= m, n &lt;= 70</code></li><li><code>1 &lt;= mat[i][j] &lt;= 70</code></li><li><code>1 &lt;= target &lt;= 800</code></li></ul><h2 id="e-g"><a href="#e-g" class="headerlink" title="e.g."></a>e.g.</h2><h3 id="示例-1："><a href="#示例-1：" class="headerlink" title="示例 1："></a><strong>示例 1：</strong></h3><p><img src="https://assets.leetcode.com/uploads/2021/08/03/matrix1.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">输入：mat = [[1,2,3],[4,5,6],[7,8,9]], target = 13</span><br><span class="line">输出：0</span><br><span class="line">解释：一种可能的最优选择方案是：</span><br><span class="line">- 第一行选出 1</span><br><span class="line">- 第二行选出 5</span><br><span class="line">- 第三行选出 7</span><br><span class="line">所选元素的和是 13 ，等于目标值，所以绝对差是 0 。</span><br></pre></td></tr></table></figure><h3 id="示例-2："><a href="#示例-2：" class="headerlink" title="示例 2："></a><strong>示例 2：</strong></h3><p><img src="https://assets.leetcode.com/uploads/2021/08/03/matrix1-1.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">输入：mat = [[1],[2],[3]], target = 100</span><br><span class="line">输出：94</span><br><span class="line">解释：唯一一种选择方案是：</span><br><span class="line">- 第一行选出 1</span><br><span class="line">- 第二行选出 2</span><br><span class="line">- 第三行选出 3</span><br><span class="line">所选元素的和是 6 ，绝对差是 94 。</span><br></pre></td></tr></table></figure><h3 id="示例-3："><a href="#示例-3：" class="headerlink" title="示例 3："></a><strong>示例 3：</strong></h3><p><img src="https://assets.leetcode.com/uploads/2021/08/03/matrix1-3.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">输入：mat = [[1,2,9,8,7]], target = 6</span><br><span class="line">输出：1</span><br><span class="line">解释：最优的选择方案是选出第一行的 7 。</span><br><span class="line">绝对差是 1 。</span><br></pre></td></tr></table></figure><h1 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h1><p>第 255 场周赛第三题，一开始就看出来是 dp 了，不过一下子妹写出来，最后还是靠的记忆化递归过的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"></span><br><span class="line">    Map&lt;Integer, Set&lt;Integer&gt;&gt; map;</span><br><span class="line">    <span class="type">int</span> <span class="variable">ans</span> <span class="operator">=</span> <span class="number">0x3f3f3f3f</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 最小化目标值与所选元素的差</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> mat</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> target</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">minimizeTheDifference</span><span class="params">(<span class="type">int</span>[][] mat, <span class="type">int</span> target)</span> &#123;</span><br><span class="line">        map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span>[] ints : mat) &#123;</span><br><span class="line">            Arrays.sort(ints);</span><br><span class="line">        &#125;</span><br><span class="line">        dfs(mat, target, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">dfs</span><span class="params">(<span class="type">int</span>[][] mat, <span class="type">int</span> target, <span class="type">int</span> curr, <span class="type">int</span> step)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (step &gt;= mat.length) &#123;</span><br><span class="line">            ans = Math.min(Math.abs(target - curr), ans);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; mat[<span class="number">0</span>].length; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (curr + mat[step][i] - target &gt; ans) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (map.get(step) != <span class="literal">null</span> &amp;&amp; map.get(step).contains(curr + mat[step][i])) &#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            map.put(step, map.getOrDefault(step, <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;()));</span><br><span class="line">            map.get(step).add(curr + mat[step][i]);</span><br><span class="line">            dfs(mat, target, curr + mat[step][i], step + <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="算法" scheme="https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="数据结构" scheme="https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    <category term="算法" scheme="https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="leetcode" scheme="https://matthew-han.github.io/tags/leetcode/"/>
    
    <category term="动态规划" scheme="https://matthew-han.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    <category term="记忆化递归" scheme="https://matthew-han.github.io/tags/%E8%AE%B0%E5%BF%86%E5%8C%96%E9%80%92%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>Redis 笔记十</title>
    <link href="https://matthew-han.github.io/post/1e254360-eab9-11eb-9401-dda5e5a2198a/"/>
    <id>https://matthew-han.github.io/post/1e254360-eab9-11eb-9401-dda5e5a2198a/</id>
    <published>2021-07-22T06:50:36.000Z</published>
    <updated>2025-09-04T09:22:32.299Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Q：Redis主从同步与故障切换，有哪些坑？"><a href="#Q：Redis主从同步与故障切换，有哪些坑？" class="headerlink" title="Q：Redis主从同步与故障切换，有哪些坑？"></a>Q：Redis主从同步与故障切换，有哪些坑？</h2><h3 id="故障一：主从数据不一致"><a href="#故障一：主从数据不一致" class="headerlink" title="故障一：主从数据不一致"></a>故障一：主从数据不一致</h3><p>因为主从库间的命令复制是异步进行的。</p><p>一方面，主从库间的网络可能会有传输延迟，所以从库不能及时地收到主库发送的命令，从库上执行同步命令的时间就会被延后。</p><p>另一方面，即使从库及时收到了主库的命令，但是，也可能会因为正在处理其它复杂度高的命令（例如集合操作命令）而阻塞。</p><p><strong>解决方法</strong></p><p>首先，<strong>在硬件环境配置方面，我们要尽量保证主从库间的网络连接状况良好。</strong>例如，我们要避免把主从库部署在不同的机房，或者是避免把网络通信密集的应用（例如数据分析应用）和 Redis 主从库部署在一起。</p><p>另外，<strong>我们还可以开发一个外部程序来监控主从库间的复制进度。</strong></p><p>如果某个从库的进度差值大于我们预设的阈值，我们可以让客户端不再和这个从库连接进行数据读取，这样就可以减少读到不一致数据的情况。不过，为了避免出现客户端和所有从库都不能连接的情况，我们需要把复制进度差值的阈值设置得大一些。</p><h3 id="故障二：读取过期数据"><a href="#故障二：读取过期数据" class="headerlink" title="故障二：读取过期数据"></a>故障二：读取过期数据</h3><p>这个问题主要发生在从库读取数据。</p><p>首先，我们都知道 Redis 同时使用了两种策略来删除过期的数据，分别是惰性删除策略和定期删除策略。</p><p>其中定期删除策略是指，Redis 每隔一段时间（默认 100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除，这样就可以及时释放一些内存。</p><p>因为从库无法删除数据，所以读到过期的数据之后，不会采用惰性删除，会导致返回过期的数据。<strong>但是只是 Redis 3.2 之前的版本，在 3.2 版本后，Redis 做了改进，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值。</strong></p><p><font color=red><em>即使使用了 Redis 3.2 后的版本，还是会出现读到过期数据的情况</em></font></p><p>因为 Redis 的过期分为两种</p><ul><li>EXPIRE 和 PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；</li><li>EXPIREAT 和 PEXPIREAT：它们会直接把数据的过期时间设置为具体的一个时间点。</li></ul><p>我们分开来看，<strong>如果设定的是 xx 秒&#x2F;天 之类的过期，就会因为网络拥塞、延迟导致过期时间延后。</strong>主从库全量同步花费了 2 分钟才完成。等从库开始执行这条命令时，时间已经是 9 点 2 分了。而 EXPIRE 命令是把 testkey 的过期时间设置为当前时间的 60s 后，也就是 9 点 3 分。如果客户端在 9 点 2 分 30 秒时在从库上读取 testkey，仍然可以读到 testkey 的值。但是，testkey 实际上已经过期了。</p><blockquote><p>这也太拉胯了。。。讲道理从库同步主库数据（有需要过期的 kv）应该改成同步他的过期时间，而不是时长。</p></blockquote><p><strong>如果设定的是具体的过期日期，也会因为和主库的时钟不一致，从而产生问题。</strong></p><p>所以应对过期 key 的问题，需要：</p><ol start="0"><li>保证良好网络环境，以及使用程序监控从库复制进度，一旦从库复制进度超过阈值，不让客户端连接从库。</li><li>使用 Redis 3.2 及以上版本；尽量使用 EXPIREAT&#x2F;PEXPIREAT 命令设置过期时间，避免从库上的数据过期时间滞后。</li><li>另外，主从节点上的时钟要保持一致，具体的做法是，让主从节点和相同的 NTP 服务器（时间服务器）进行时钟同步。</li></ol><h3 id="故障三：不合理配置项导致的服务挂掉"><a href="#故障三：不合理配置项导致的服务挂掉" class="headerlink" title="故障三：不合理配置项导致的服务挂掉"></a>故障三：不合理配置项导致的服务挂掉</h3><h4 id="protected-mode-配置项"><a href="#protected-mode-配置项" class="headerlink" title="protected-mode 配置项"></a>protected-mode 配置项</h4><p>这个配置项的作用是限定哨兵实例能否被其他服务器访问。当这个配置项设置为 yes 时，哨兵实例只能在部署的服务器本地进行访问。当设置为 no 时，其他服务器也可以访问这个哨兵实例。</p><p>正因为这样，如果 protected-mode 被设置为 yes，而其余哨兵实例部署在其它服务器，那么，这些哨兵实例间就无法通信。当主库故障时，哨兵无法判断主库下线，也无法进行主从切换，最终 Redis 服务不可用。</p><p><strong>所以，我们在应用主从集群时，要注意将 protected-mode 配置项设置为 no，并且将 bind 配置项设置为其它哨兵实例的 IP 地址。</strong>这样一来，只有在 bind 中设置了 IP 地址的哨兵，才可以访问当前实例，既保证了实例间能够通信进行主从切换，也保证了哨兵的安全性。</p><h4 id="cluster-node-timeout-配置项"><a href="#cluster-node-timeout-配置项" class="headerlink" title="cluster-node-timeout 配置项"></a>cluster-node-timeout 配置项</h4><p>这个配置项设置了 Redis Cluster 中实例响应心跳消息的超时时间。</p><p>如果执行主从切换的实例超过半数，而主从切换时间又过长的话，就可能有半数以上的实例心跳超时，从而可能导致整个集群挂掉。所以，我建议你将 cluster-node-timeout 调大些（例如 10 到 20 秒）。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-92a397de1b796710a4deea103ddbbdd7b4d0d82b.jpg" alt="img" style="zoom:15%;" /><p>Q：我们把 slave-read-only 设置为 no，让从库也能直接删除数据，以此来避免读到过期数据，你觉得，这是一个好方法吗？</p><p>A：不太好，因为增加一个特性是为了解决 bug，但是采用从库也能写数据的方式无疑是会增加 bug，还是会产生数据不一致的情况。。</p><h2 id="Q：Redis支撑秒杀场景的关键技术和实践都有哪些"><a href="#Q：Redis支撑秒杀场景的关键技术和实践都有哪些" class="headerlink" title="Q：Redis支撑秒杀场景的关键技术和实践都有哪些"></a>Q：Redis支撑秒杀场景的关键技术和实践都有哪些</h2><h3 id="秒杀场景的负载特征对支撑系统的要求"><a href="#秒杀场景的负载特征对支撑系统的要求" class="headerlink" title="秒杀场景的负载特征对支撑系统的要求"></a>秒杀场景的负载特征对支撑系统的要求</h3><p>第一个特征是瞬时并发访问量非常高。</p><p>第二个特征是读多写少，而且读操作是简单的查询操作。</p><h3 id="Redis-可以在秒杀场景的哪些环节发挥作用？"><a href="#Redis-可以在秒杀场景的哪些环节发挥作用？" class="headerlink" title="Redis 可以在秒杀场景的哪些环节发挥作用？"></a>Redis 可以在秒杀场景的哪些环节发挥作用？</h3><p>我们一般可以把秒杀活动分成三个阶段。在每一个阶段，Redis 所发挥的作用也不一样。第一阶段是秒杀活动前。在这个阶段，用户会不断刷新商品详情页，这会导致详情页的瞬时请求量剧增。这个阶段的应对方案，一般是尽量把商品详情页的页面元素静态化，然后使用 CDN 或是浏览器把这些静态化的元素缓存起来。</p><p>秒杀开始什么环节可以在 Redis 中进行？</p><ol start="0"><li>大量高并发的库存查验请求，这个环节使用 Redis 保存库存量，请求可以直接从 Redis 中读取库存并进行查验。</li><li><strong>库存扣减操作，不能交给后端数据库处理。</strong><ol><li>额外的开销。Redis 中保存了库存量，而库存量的最新值又是数据库在维护，所以数据库更新后，还需要和 Redis 进行同步，这个过程增加了额外的操作逻辑，也带来了额外的开销。</li><li>下单量超过实际库存量，出现超售。由于数据库的处理速度较慢，不能及时更新库存余量，这就会导致大量库存查验的请求读取到旧的库存值，并进行下单。此时，就会出现下单数量大于实际的库存量，导致出现超售，这就不符合业务层的要求了。</li></ol></li><li>库存的扣减在 Redis 中进行。而且，为了避免请求查询到旧的库存值，库存查验和库存扣减这两个操作需要保证原子性。</li></ol><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-d53e0969044146e12634e4bbda50673722f64806.jpg" alt="img" style="zoom:15%;" /><h3 id="Redis-的哪些方法可以支撑秒杀场景？"><a href="#Redis-的哪些方法可以支撑秒杀场景？" class="headerlink" title="Redis 的哪些方法可以支撑秒杀场景？"></a>Redis 的哪些方法可以支撑秒杀场景？</h3><ul><li>支持高并发。这个很简单，Redis 本身高速处理请求的特性就可以支持高并发。而且，如果有多个秒杀商品，我们也可以使用切片集群，用不同的实例保存不同商品的库存，这样就避免，使用单个实例导致所有的秒杀请求都集中在一个实例上的问题了。不过，需要注意的是，当使用切片集群时，我们要先用 CRC 算法计算不同秒杀商品 key 对应的 Slot，然后，我们在分配 Slot 和实例对应关系时，才能把不同秒杀商品对应的 Slot 分配到不同实例上保存。</li><li>保证库存查验和库存扣减原子性执行。针对这条要求，我们就可以使用 Redis 的原子操作或是分布式锁这两个功能特性来支撑了。</li></ul><h4 id="基于原子操作支撑秒杀场景"><a href="#基于原子操作支撑秒杀场景" class="headerlink" title="基于原子操作支撑秒杀场景"></a>基于原子操作支撑秒杀场景</h4><p>虽然 Redis 具有原子性的加减，但是还有一步是查验操作，需要【查询 + 加减库存】，所以需要搞个 lua 脚本实现原子性操作。</p><h4 id="基于分布式锁来支撑秒杀场景"><a href="#基于分布式锁来支撑秒杀场景" class="headerlink" title="基于分布式锁来支撑秒杀场景"></a>基于分布式锁来支撑秒杀场景</h4><p>先让客户端向 Redis 申请分布式锁，只有拿到锁的客户端才能执行库存查验和库存扣减。这样一来，大量的秒杀请求就会在争夺分布式锁时被过滤掉。而且，库存查验和扣减也不用使用原子操作了，因为多个并发客户端只有一个客户端能够拿到锁，已经保证了客户端并发访问的互斥性。</p><p>所以，可以使用切片集群中的不同实例来分别保存分布式锁和商品库存信息。使用这种保存方式后，秒杀请求会首先访问保存分布式锁的实例。如果客户端没有拿到锁，这些客户端就不会查询商品库存，这就可以减轻保存库存信息的实例的压力了。</p><h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><ol start="0"><li>前端静态页面的设计。秒杀页面上能静态化处理的页面元素，我们都要尽量静态化，这样可以充分利用 CDN 或浏览器缓存服务秒杀开始前的请求。</li><li>请求拦截和流控。在秒杀系统的接入层，对恶意请求进行拦截，避免对系统的恶意攻击，例如使用黑名单禁止恶意 IP 进行访问。如果 Redis 实例的访问压力过大，为了避免实例崩溃，我们也需要在接入层进行限流，控制进入秒杀系统的请求数量。</li><li>库存信息过期时间处理。Redis 中保存的库存信息其实是数据库的缓存，为了避免缓存击穿问题，我们不要给库存信息设置过期时间。</li><li>数据库订单异常处理。如果数据库没能成功处理订单，可以增加订单重试功能，保证订单最终能被成功处理。</li></ol><h2 id="Q：如何应对数据倾斜"><a href="#Q：如何应对数据倾斜" class="headerlink" title="Q：如何应对数据倾斜"></a>Q：如何应对数据倾斜</h2><p>数据倾斜有两类。</p><ul><li>数据量倾斜：在某些情况下，实例上的数据分布不均衡，某个实例上的数据特别多。</li><li>数据访问倾斜：虽然每个集群实例上的数据量相差不大，但是某个实例上的数据是热点数据，被访问得非常频繁。</li></ul><h3 id="数据量倾斜的成因和应对方法"><a href="#数据量倾斜的成因和应对方法" class="headerlink" title="数据量倾斜的成因和应对方法"></a>数据量倾斜的成因和应对方法</h3><p>那么，数据量倾斜是怎么产生的呢？这主要有三个原因，分别是某个实例上保存了 <strong>bigkey</strong>、<strong>Slot</strong> 分配不均衡以及 <strong>Hash Tag</strong>。</p><h4 id="bigkey-导致倾斜"><a href="#bigkey-导致倾斜" class="headerlink" title="bigkey 导致倾斜"></a>bigkey 导致倾斜</h4><p>第一个原因是，某个实例上正好保存了 bigkey。bigkey 的 value 值很大（String 类型），或者是 bigkey 保存了大量集合元素（集合类型），会导致这个实例的数据量增加，内存资源消耗也相应增加。</p><p>解决：</p><p>一个根本的应对方法是，我们在业务层生成数据时，要尽量避免把过多的数据保存在同一个键值对中。</p><p>此外，如果 bigkey 正好是集合类型，我们还有一个方法，就是把 bigkey 拆分成很多个小的集合类型数据，分散保存在不同的实例上。</p><h4 id="Slot-分配不均衡导致倾斜"><a href="#Slot-分配不均衡导致倾斜" class="headerlink" title="Slot 分配不均衡导致倾斜"></a>Slot 分配不均衡导致倾斜</h4><p>如果集群运维人员没有均衡地分配 Slot，就会有大量的数据被分配到同一个 Slot 中，而同一个 Slot 只会在一个实例上分布（该实例配置较高），这就会导致，大量数据被集中到一个实例上，造成数据倾斜。</p><p>在 Redis Cluster 中，我们可以使用 3 个命令完成 Slot 迁移。</p><ul><li>CLUSTER SETSLOT：使用不同的选项进行三种设置，分别是设置 Slot 要迁入的目标实例，Slot 要迁出的源实例，以及 Slot 所属的实例。</li><li>CLUSTER GETKEYSINSLOT：获取某个 Slot 中一定数量的 key。</li><li>MIGRATE：把一个 key 从源实例实际迁移到目标实例。</li></ul><h4 id="Hash-Tag-导致倾斜"><a href="#Hash-Tag-导致倾斜" class="headerlink" title="Hash Tag 导致倾斜"></a>Hash Tag 导致倾斜</h4><p>Hash Tag 是指加在键值对 key 中的一对花括号{}。这对括号会把 key 的一部分括起来，客户端在计算 key 的 CRC16 值时，只对 Hash Tag 花括号中的 key 内容进行计算。如果没用 Hash Tag 的话，客户端计算整个 key 的 CRC16 的值。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-bb5c8da729e6cf481825356a4e84551c75643804.jpg" alt="img" style="zoom:15%;" /><p>其中，user:profile:{3231}和 user:order:{3231}的 Hash Tag 一样，都是 3231，它们的 CRC16 计算值对 16384 取模后的值也是一样的，所以就对应映射到了相同的 Slot 1024 中。user:profile:{5328}和 user:order:{5328}也是相同的映射结果。</p><h3 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h3><p>通常来说，热点数据以服务读操作为主，在这种情况下，我们可以采用热点数据多副本的方法来应对。</p><p>这个方法的具体做法是，我们把热点数据复制多份，在每一个数据副本的 key 中增加一个随机前缀，让它和其它副本数据不会被映射到同一个 Slot 中。</p><p>热点数据多副本方法只能针对只读的热点数据。如果热点数据是有读有写的话，就不适合采用多副本方法了，因为要保证多副本间的数据一致性，会带来额外的开销。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-cae93449e7f9deeff622059d9103508fb882521e.jpg" alt="img" style="zoom:15%;" />]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="中间件" scheme="https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Redis" scheme="https://matthew-han.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis 笔记九</title>
    <link href="https://matthew-han.github.io/post/ed60b400-e908-11eb-9a84-25c4901703d0/"/>
    <id>https://matthew-han.github.io/post/ed60b400-e908-11eb-9a84-25c4901703d0/</id>
    <published>2021-07-20T03:16:51.000Z</published>
    <updated>2025-09-04T09:22:32.306Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Q：单机上的锁和分布式锁的联系与区别"><a href="#Q：单机上的锁和分布式锁的联系与区别" class="headerlink" title="Q：单机上的锁和分布式锁的联系与区别"></a>Q：单机上的锁和分布式锁的联系与区别</h2><p>对于在单机上运行的多线程程序来说，锁本身可以用一个变量表示。</p><ul><li>变量值为 0 时，表示没有线程获取锁；</li><li>变量值为 1 时，表示已经有线程获取到锁了。</li></ul><p>和单机上的锁类似，分布式锁同样可以用一个变量来实现。客户端加锁和释放锁的操作逻辑，也和单机上的加锁和释放锁操作逻辑一致：加锁时同样需要判断锁变量的值，根据锁变量值来判断能否加锁成功；释放锁时需要把锁变量值设置为 0，表明客户端不再持有锁。</p><p>但是，和线程在单机上操作锁不同的是，在分布式场景下，锁变量需要由一个共享存储系统来维护，只有这样，多个客户端才可以通过访问共享存储系统来访问锁变量。相应的，加锁和释放锁的操作就变成了读取、判断和设置共享存储系统中的锁变量值。</p><p>这样一来，我们就可以得出实现分布式锁的两个要求。</p><ul><li>要求一：分布式锁的加锁和释放锁的过程，涉及多个操作。所以，在实现分布式锁时，我们需要保证这些锁操作的原子性；</li><li>要求二：共享存储系统保存了锁变量，如果共享存储系统发生故障或宕机，那么客户端也就无法进行锁操作了。在实现分布式锁时，我们需要考虑保证共享存储系统的可靠性，进而保证锁的可靠性。</li></ul><h2 id="Q：基于单个-Redis-节点实现分布式锁"><a href="#Q：基于单个-Redis-节点实现分布式锁" class="headerlink" title="Q：基于单个 Redis 节点实现分布式锁"></a>Q：基于单个 Redis 节点实现分布式锁</h2><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-363a31c71fc91f862b2702c906d2860605fe2bfc.jpg?wh=2820*2250" alt="img" style="zoom:15%;" /><p>在图中，客户端 A 和 C 同时请求加锁。因为 Redis 使用单线程处理请求，所以，即使客户端 A 和 C 同时把加锁请求发给了 Redis，Redis 也会串行处理它们的请求。</p><p>我们假设 Redis 先处理客户端 A 的请求，读取 lock_key 的值，发现 lock_key 为 0，所以，Redis 就把 lock_key 的 value 置为 1，表示已经加锁了。紧接着，Redis 处理客户端 C 的请求，此时，Redis 会发现 lock_key 的值已经为 1 了，所以就返回加锁失败的信息。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-0d88c0b64070d9e4e621835af006d68e6ae26d9b.jpg?wh=3000*2250" alt="img" style="zoom:15%;" /><p>当客户端 A 持有锁时，锁变量 lock_key 的值为 1。客户端 A 执行释放锁操作后，Redis 将 lock_key 的值置为 0，表明已经没有客户端持有锁了。</p><p>要想保证操作的原子性，有两种通用的方法，分别是使用 Redis 的单命令操作和使用 Lua 脚本。</p><p>首先是 SETNX 命令，它用于设置键值对的值。具体来说，就是这个命令在执行时会判断键值对是否存在，如果不存在，就设置键值对的值，如果存在，就不做任何设置。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 加锁</span><br><span class="line">SETNX lock_key 1</span><br><span class="line">// 业务逻辑</span><br><span class="line">DO THINGS</span><br><span class="line">// 释放锁</span><br><span class="line">DEL lock_key</span><br></pre></td></tr></table></figure><p>对于释放锁操作来说，我们可以在执行完业务逻辑后，使用 DEL 命令删除锁变量。不过，你不用担心锁变量被删除后，其他客户端无法请求加锁了。因为 SETNX 命令在执行时，如果要设置的键值对（也就是锁变量）不存在，SETNX 命令会先创建键值对，然后设置它的值。所以，释放锁之后，再有客户端请求加锁时，SETNX 命令会创建保存锁变量的键值对，并设置锁变量的值，完成加锁。</p><p>总结来说，我们就可以用 SETNX 和 DEL 命令组合来实现加锁和释放锁操作。下面的伪代码示例显示了锁操作的过程，你可以看下。</p><h3 id="使用-SETNX-和-DEL-命令组合实现分布锁，存在两个潜在的风险。"><a href="#使用-SETNX-和-DEL-命令组合实现分布锁，存在两个潜在的风险。" class="headerlink" title="使用 SETNX 和 DEL 命令组合实现分布锁，存在两个潜在的风险。"></a>使用 SETNX 和 DEL 命令组合实现分布锁，存在两个潜在的风险。</h3><p><strong>风险一</strong>：假如某个客户端在执行了 SETNX 命令、加锁之后，紧接着却在操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。因此，锁就一直被这个客户端持有，其它客户端无法拿到锁，也无法访问共享数据和执行后续操作，这会给业务应用带来影响。</p><p><strong>解决</strong>：针对这个问题，一个有效的解决方法是，给锁变量设置一个过期时间。这样一来，即使持有锁的客户端发生了异常，无法主动地释放锁，Redis 也会根据锁变量的过期时间，在锁变量过期后，把它删除。其它客户端在锁变量过期后，就可以重新请求加锁，这就不会出现无法加锁的问题了。</p><p><strong>风险二</strong>：如果客户端 A 执行了 SETNX 命令加锁后，假设客户端 B 执行了 DEL 命令释放锁，此时，客户端 A 的锁就被误释放了。如果客户端 C 正好也在申请加锁，就可以成功获得锁，进而开始操作共享数据。这样一来，客户端 A 和 C 同时在对共享数据进行操作，数据就会被修改错误，这也是业务层不能接受的。</p><p><strong>解决</strong>：要能区分来自不同客户端的锁操作，可以在锁变量的值上想想办法。在使用 SETNX 命令进行加锁的方法中，我们通过把锁变量值设置为 1 或 0，表示是否加锁成功。1 和 0 只有两种状态，无法表示究竟是哪个客户端进行的锁操作。所以，我们在加锁操作时，可以让每个客户端给锁变量设置一个唯一值，这里的唯一值就可以用来标识当前操作的客户端。在释放锁操作时，客户端需要判断，当前锁变量的值是否和自己的唯一标识相等，只有在相等的情况下，才能释放锁。这样一来，就不会出现误释放锁的问题了。SET 命令在执行时还可以带上 EX 或 PX 选项，用来设置键值对的过期时间。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SET key value [EX seconds | PX milliseconds]  [NX]</span><br><span class="line">// 例子</span><br><span class="line">// 加锁, unique_value作为客户端唯一性的标识</span><br><span class="line">SET lock_key unique_value NX PX 10000</span><br></pre></td></tr></table></figure><p><strong>NX：类似 SETNX，当不存在才 set 一个 kv</strong></p><p>虽然使用 SET 命令和 Lua 脚本在 Redis 单节点上实现分布式锁。但是现在只用了一个 Redis 实例来保存锁变量，如果这个 Redis 实例发生故障宕机了，那么锁变量就没有了。此时，客户端也无法进行锁操作了，这就会影响到业务的正常执行。所以，我们在实现分布式锁时，还需要保证锁的可靠性。那怎么提高呢？这就要提到基于多个 Redis 节点实现分布式锁的方式了。</p><h3 id="基于多个-Redis-节点实现高可靠的分布式锁"><a href="#基于多个-Redis-节点实现高可靠的分布式锁" class="headerlink" title="基于多个 Redis 节点实现高可靠的分布式锁"></a>基于多个 Redis 节点实现高可靠的分布式锁</h3><p>Redlock 算法的基本思路，是让客户端和多个独立的 Redis 实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁了，否则加锁失败。这样一来，即使有单个 Redis 实例发生故障，因为锁变量在其它实例上也有保存，所以，客户端仍然可以正常地进行锁操作，锁变量并不会丢失。</p><p><strong>第一步是，客户端获取当前时间。</strong></p><p><strong>第二步是，客户端按顺序依次向 N 个 Redis 实例执行加锁操作。</strong></p><p>这里的加锁操作和在单实例上执行的加锁操作一样，使用 SET 命令，带上 NX，EX&#x2F;PX 选项，以及带上客户端的唯一标识。当然，如果某个 Redis 实例发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给加锁操作设置一个超时时间。</p><p>如果客户端在和一个 Redis 实例请求加锁时，一直到超时都没有成功，那么此时，客户端会和下一个 Redis 实例继续请求加锁。加锁操作的超时时间需要远远地小于锁的有效时间，一般也就是设置为几十毫秒。</p><p><strong>第三步是，一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时。</strong></p><p>客户端只有在满足下面的这两个条件时，才能认为是加锁成功。</p><ul><li>条件一：客户端从超过半数（大于等于 N&#x2F;2+1）的 Redis 实例上成功获取到了锁；</li><li>条件二：客户端获取锁的总耗时没有超过锁的有效时间。</li></ul><p>在满足了这两个条件后，我们需要重新计算这把锁的有效时间，计算的结果是锁的最初有效时间减去客户端为获取锁的总耗时。</p><h2 id="Q：Redis-与事务"><a href="#Q：Redis-与事务" class="headerlink" title="Q：Redis 与事务"></a>Q：Redis 与事务</h2><p>事务的执行过程包含三个步骤，Redis 提供了 MULTI、EXEC 两个命令来完成这三个步骤。</p><p>第一步，客户端要使用一个命令显式地表示一个事务的开启。在 Redis 中，这个命令就是 MULTI。</p><p>第二步，客户端把事务中本身要执行的具体操作（例如增删改数据）发送给服务器端。这些操作就是 Redis 本身提供的数据读写命令，例如 GET、SET 等。不过，这些命令虽然被客户端发送到了服务器端，但 Redis 实例只是把这些命令暂存到一个命令队列中，并不会立即执行。</p><p>第三步，客户端向服务器端发送提交事务的命令，让数据库实际执行第二步中发送的具体操作。Redis 提供的 EXEC 命令就是执行事务提交的。当服务器端收到 EXEC 命令后，才会实际执行命令队列中的所有命令。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">开启事务</span></span><br><span class="line">127.0.0.1:6379&gt; MULTI</span><br><span class="line">OK</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">将a:stock减1，</span></span><br><span class="line">127.0.0.1:6379&gt; DECR a:stock</span><br><span class="line">QUEUED</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">将b:stock减1</span></span><br><span class="line">127.0.0.1:6379&gt; DECR b:stock</span><br><span class="line">QUEUED</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">实际执行事务</span></span><br><span class="line">127.0.0.1:6379&gt; EXEC</span><br><span class="line">1) (integer) 4</span><br><span class="line">2) (integer) 9</span><br></pre></td></tr></table></figure><h2 id="Q：Redis-与原子性"><a href="#Q：Redis-与原子性" class="headerlink" title="Q：Redis 与原子性"></a>Q：Redis 与原子性</h2><p>先说个结论：虽然在这门课中声称是事务，但是 Redis 有个锤子的事务，原子性说白了也没法保障的，拉的一批。</p><ul><li><p>情况一：在执行 EXEC 命令前，客户端发送的操作命令本身就有错误（比如语法错误，使用了不存在的命令），在命令入队时就被 Redis 实例判断出来了。<strong>那么整个事务就会被放弃，这个勉强算半个事务。</strong></p></li><li><p>情况二：事务操作入队时，命令和操作的数据类型不匹配，但 Redis 实例没有检查出错误。<strong>例如出现了一条命令成功，一条失败的情况，那么并不会回滚，而是成功的命令就成功的执行了。</strong></p><ul><li><p>Redis 中并没有提供回滚机制。虽然 Redis 提供了 DISCARD 命令，但是，这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。</p></li><li><p>可以像如下这样主动地终结事务，反正就是没什么卵用。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">读取a:stock的值4</span></span><br><span class="line">127.0.0.1:6379&gt; GET a:stock</span><br><span class="line">&quot;4&quot;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">开启事务</span></span><br><span class="line">127.0.0.1:6379&gt; MULTI </span><br><span class="line">OK</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">发送事务的第一个操作，对a:stock减1</span></span><br><span class="line">127.0.0.1:6379&gt; DECR a:stock</span><br><span class="line">QUEUED</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">执行DISCARD命令，主动放弃事务</span></span><br><span class="line">127.0.0.1:6379&gt; DISCARD</span><br><span class="line">OK</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">再次读取a:stock的值，值没有被修改</span></span><br><span class="line">127.0.0.1:6379&gt; GET a:stock</span><br><span class="line">&quot;4&quot;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>情况三：在执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败。在这种情况下，如果 Redis 开启了 AOF 日志，那么，只会有部分的事务操作被记录到 AOF 日志中。<strong>我们需要使用 redis-check-aof 工具检查 AOF 日志文件，这个工具可以把未完成的事务操作从 AOF 文件中去除。</strong>使用 AOF 恢复实例后，事务操作不会再被执行，从而保证了原子性。</p></li></ul><blockquote><p>总结：你看这个 Redis 啊？才搞几个命令就不回滚了，真的太逊了。这个 Redis 就是逊啦。</p></blockquote><h2 id="Q：Redis-与一致性"><a href="#Q：Redis-与一致性" class="headerlink" title="Q：Redis 与一致性"></a>Q：Redis 与一致性</h2><p>可以理解一致性就是，应用系统从一个正确的状态到另一个正确的状态，而 ACID 就是说事务能够通过 AID 来保证这个 C 的过程。C 是目的，AID 都是手段。</p><p>所以个人感觉一致性拉胯</p><h2 id="Q：Redis-与隔离性"><a href="#Q：Redis-与隔离性" class="headerlink" title="Q：Redis 与隔离性"></a>Q：Redis 与隔离性</h2><p>事务的隔离性保证，会受到和事务一起执行的并发操作的影响。而事务执行又可以分成命令入队（EXEC 命令执行前）和命令实际执行（EXEC 命令执行后）两个阶段，所以，我们就针对这两个阶段，分成两种情况来分析：</p><ul><li>并发操作在 EXEC 命令前执行，此时，隔离性的保证要使用 WATCH 机制来实现，否则隔离性无法保证；</li><li>并发操作在 EXEC 命令后执行，此时，隔离性可以保证。</li></ul><p>WATCH 机制：在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行，隔离性也得到了保证。</p><ul><li>情况一：一个事务的 EXEC 命令还没有执行时，事务的命令操作是暂存在命令队列中的。此时，如果有其它的并发操作，我们就需要看事务是否使用了 WATCH 机制。<ul><li>开启了 WATCH 机制（可以保证隔离性）：<img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-7ca1e4b12fe0dcd21ef9a9b13172ea4d044698ed.jpg" alt="img" style="zoom:15%;" /></li><li>未开启 WATCH 机制（无法保证隔离性）：<img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-c2252825080ed3d9a92ab17d313136202511341c.jpg" alt="img" style="zoom:15%;" /></li></ul></li><li>情况二：并发操作在 EXEC 命令之后被服务器端接收并执行。因为 Redis 是用单线程执行命令，而且，EXEC 命令执行后，Redis 会保证先把命令队列中的所有命令执行完。所以，在这种情况下，并发操作不会破坏事务的隔离性。<ul><li><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-f71276031be1b7be328bd5d4af477a7e7d40fee4.jpg" alt="img" style="zoom:15%;" /></li></ul></li></ul><h2 id="Q：Redis-与持久性"><a href="#Q：Redis-与持久性" class="headerlink" title="Q：Redis 与持久性"></a>Q：Redis 与持久性</h2><p>如果 Redis 没有使用 RDB 或 AOF，那么事务的持久化属性肯定得不到保证。如果 Redis 使用了 RDB 模式，那么，在一个事务执行后，而下一次的 RDB 快照还未执行前，如果发生了实例宕机，这种情况下，事务修改的数据也是不能保证持久化的。</p><p>如果 Redis 采用了 AOF 模式，因为 AOF 模式的三种配置选项 no、everysec 和 always 都会存在数据丢失的情况，所以，事务的持久性属性也还是得不到保证。</p><p>所以，不管 Redis 采用什么持久化模式，事务的持久性属性是得不到保证的。</p><h2 id="小结："><a href="#小结：" class="headerlink" title="小结："></a>小结：</h2><p>Redis 通过 MULTI、EXEC、DISCARD 和 WATCH 四个命令来支持事务机制。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-3ca8592719eb0e01868ab0ab6398a897b64968af.jpg" alt="img" style="zoom:20%;" /><h3 id="小问题"><a href="#小问题" class="headerlink" title="小问题"></a>小问题</h3><p>Q：在执行事务时，如果 Redis 实例发生故障，而 Redis 使用了 RDB 机制，那么，事务的原子性还能得到保证吗？</p><p>A：可能能，RDB一般没这么快生成，所以理论上可以回滚到上一个 RDB 的版本。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="中间件" scheme="https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Redis" scheme="https://matthew-han.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis 笔记八</title>
    <link href="https://matthew-han.github.io/post/61c327b0-e841-11eb-88f0-e9ea35f6ec9b/"/>
    <id>https://matthew-han.github.io/post/61c327b0-e841-11eb-88f0-e9ea35f6ec9b/</id>
    <published>2021-07-19T03:28:27.000Z</published>
    <updated>2025-09-04T09:22:32.297Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Q：什么是缓存污染"><a href="#Q：什么是缓存污染" class="headerlink" title="Q：什么是缓存污染"></a>Q：什么是缓存污染</h2><p>那什么是缓存污染呢？在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。这种情况，就是缓存污染。</p><h3 id="如何解决缓存污染？"><a href="#如何解决缓存污染？" class="headerlink" title="如何解决缓存污染？"></a>如何解决缓存污染？</h3><h4 id="LRU-的不足："><a href="#LRU-的不足：" class="headerlink" title="LRU 的不足："></a>LRU 的不足：</h4><p>因为只看数据的访问时间，使用 LRU 策略在处理扫描式单次查询操作时，无法解决缓存污染。所谓的扫描式单次查询操作，就是指应用对大量的数据进行一次全体读取，每个数据都会被读取，而且只会被读取一次。此时，因为这些被查询的数据刚刚被访问过，所以 LRU 字段值都很大。</p><h4 id="LFU-的优化"><a href="#LFU-的优化" class="headerlink" title="LFU 的优化"></a>LFU 的优化</h4><p>LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。</p><p>当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。</p><p>为了避免操作链表的开销，Redis 在实现 LRU 策略时使用了两个近似方法：</p><ul><li>Redis 是用 RedisObject 结构来保存数据的，RedisObject 结构中设置了一个 lru 字段，用来记录数据的访问时间戳；</li><li>Redis 并没有为所有的数据维护一个全局的链表，而是通过随机采样方式，选取一定数量（例如 10 个）的数据放入候选集合，后续在候选集合中根据 lru 字段值的大小进行筛选。</li></ul><p>在此基础上，Redis 在实现 LFU 策略的时候，只是把原来 24bit 大小的 lru 字段，又进一步拆分成了两部分。</p><ol start="0"><li>ldt 值：lru 字段的前 16bit，表示数据的访问时间戳；</li><li>counter 值：lru 字段的后 8bit，表示数据的访问次数。</li></ol><p><strong>总结一下：当 LFU 策略筛选数据时，Redis 会在候选集合中，根据数据 lru 字段的后 8bit 选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据 lru 字段的前 16bit 值大小，选择访问时间最久远的数据进行淘汰。</strong></p><h4 id="Redis-只使用了-8bit-记录数据的访问次数，而-8bit-记录的最大值是-255"><a href="#Redis-只使用了-8bit-记录数据的访问次数，而-8bit-记录的最大值是-255" class="headerlink" title="Redis 只使用了 8bit 记录数据的访问次数，而 8bit 记录的最大值是 255"></a>Redis 只使用了 8bit 记录数据的访问次数，而 8bit 记录的最大值是 255</h4><p>Redis 也注意到了这个问题。因此，在实现 LFU 策略时，Redis 并没有采用数据每被访问一次，就给对应的 counter 值加 1 的计数规则，而是采用了一个更优化的计数规则。</p><p>简单来说，LFU 策略实现的计数规则是：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">double</span> r = (<span class="type">double</span>)rand()/RAND_MAX;</span><br><span class="line">...</span><br><span class="line"><span class="type">double</span> p = <span class="number">1.0</span>/(baseval*server.lfu_log_factor+<span class="number">1</span>);</span><br><span class="line"><span class="keyword">if</span> (r &lt; p) counter++;</span><br></pre></td></tr></table></figure><p>以下是记录了当 lfu_log_factor 取不同值时，在不同的实际访问次数情况下，计数器的值是如何变化的。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-3062001c9c445f09a748198bbad85a925124591e.jpg" alt="img" style="zoom:15%;" /><p>正是因为使用了<strong>非线性递增的计数器方法</strong>，即使缓存数据的访问次数成千上万，LFU 策略也可以有效地区分不同的访问次数，从而进行合理的数据筛选。从刚才的表中，我们可以看到，当 lfu_log_factor 取值为 10 时，百、千、十万级别的访问次数对应的 counter 值已经有明显的区分了。</p><p>我们在应用 LFU 策略时，一般可以将 lfu_log_factor 取值为 10。</p><p>在实际业务应用中，LRU 和 LFU 两个策略都有应用。LRU 和 LFU 两个策略关注的数据访问特征各有侧重，LRU 策略更加关注数据的时效性，而 LFU 策略更加关注数据的访问频次。通常情况下，实际应用的负载具有较好的时间局部性，所以 LRU 策略的应用会更加广泛。但是，在扫描式查询的应用场景中，LFU 策略就可以很好地应对缓存污染问题了。</p><h2 id="Q：Redis如何应对并发访问"><a href="#Q：Redis如何应对并发访问" class="headerlink" title="Q：Redis如何应对并发访问"></a>Q：Redis如何应对并发访问</h2><p>这里是指的是多条 Redis 命令不具备原子性，Redis 是单线程执行单条指令时当然不会被发生竞争的问题。</p><p>为了保证并发访问的正确性，Redis 提供了两种方法，分别是加锁和原子操作。</p><p>原子操作是另一种提供并发访问控制的方法。原子操作是指执行过程保持原子性的操作，而且原子操作执行时并不需要再加锁，实现了无锁操作。这样一来，既能保证并发控制，还能减少对系统并发性能的影响。</p><h3 id="并发访问中需要对什么进行控制？"><a href="#并发访问中需要对什么进行控制？" class="headerlink" title="并发访问中需要对什么进行控制？"></a>并发访问中需要对什么进行控制？</h3><p>并发访问控制对应的操作主要是数据修改操作。当客户端需要修改数据时，基本流程分成两步：</p><ol start="0"><li>客户端先把数据读取到本地，在本地进行修改；</li><li>客户端修改完数据后，再写回 Redis。</li></ol><p>我们把这个流程叫做“读取 - 修改 - 写回”操作（Read-Modify-Write，简称为 RMW 操作）。当有多个客户端对同一份数据执行 RMW 操作的话，我们就需要让 RMW 操作涉及的代码以原子性方式执行。访问同一份数据的 RMW 操作代码，就叫做临界区代码。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-60369294d82adaa9e2f69a3a5c5185c14f12d55a.jpg" alt="img" style="zoom:15%;" /><p>可以看到，客户端 A 在 t1 时读取库存值 10 并扣减 1，在 t2 时，客户端 A 还没有把扣减后的库存值 9 写回 Redis，而在此时，客户端 B 读到库存值 10，也扣减了 1，B 记录的库存值也为 9 了。等到 t3 时，A 往 Redis 写回了库存值 9，而到 t4 时，B 也写回了库存值 9。如果按正确的逻辑处理，客户端 A 和 B 对库存值各做了一次扣减，库存值应该为 8。所以，这里的库存值明显更新错了。</p><h3 id="Redis-的两种原子操作方法"><a href="#Redis-的两种原子操作方法" class="headerlink" title="Redis 的两种原子操作方法"></a>Redis 的两种原子操作方法</h3><p>为了实现并发控制要求的临界区代码互斥执行，Redis 的原子操作采用了两种方法：</p><ol start="0"><li>把多个操作在 Redis 中实现成一个操作，也就是单命令操作；</li><li>把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本。</li></ol><p>我们先来看下 Redis 本身的单命令操作。Redis 是使用单线程来串行处理客户端的请求操作命令的，所以，当 Redis 执行某个命令操作时，其他命令是无法执行的，这相当于命令操作是互斥执行的。当然，Redis 的快照生成、AOF 重写这些操作，可以使用后台线程或者是子进程执行，也就是和主线程的操作并行执行。不过，这些操作只是读取数据，不会修改数据，所以，我们并不需要对它们做并发控制。</p><p><strong>Redis 提供了 INCR&#x2F;DECR 命令，把这三个操作转变为一个原子操作了。INCR&#x2F;DECR 命令可以对数据进行增值 &#x2F; 减值操作，而且它们本身就是单个命令操作，Redis 在执行它们时，本身就具有互斥性。</strong></p><p>所以，如果我们执行的 RMW 操作是对数据进行增减值的话，Redis 提供的原子操作 INCR 和 DECR 可以直接帮助我们进行并发控制。</p><h3 id="lua-脚本"><a href="#lua-脚本" class="headerlink" title="lua 脚本"></a>lua 脚本</h3><p>Redis 的 Lua 脚本可以包含多个操作，这些操作都会以原子性的方式执行，绕开了单命令操作的限制。不过，如果把很多操作都放在 Lua 脚本中原子执行，会导致 Redis 执行脚本的时间增加，同样也会降低 Redis 的并发性能。所以建议在编写 Lua 脚本时，避免把不需要做并发控制的操作写入脚本中。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="中间件" scheme="https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Redis" scheme="https://matthew-han.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis 笔记七</title>
    <link href="https://matthew-han.github.io/post/ba05d6d0-e53e-11eb-908d-87267ebfe3de/"/>
    <id>https://matthew-han.github.io/post/ba05d6d0-e53e-11eb-908d-87267ebfe3de/</id>
    <published>2021-07-15T07:31:53.000Z</published>
    <updated>2025-09-06T11:21:41.577Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Q：缓存异常（上）：解决缓存和数据库的数据不一致问题"><a href="#Q：缓存异常（上）：解决缓存和数据库的数据不一致问题" class="headerlink" title="Q：缓存异常（上）：解决缓存和数据库的数据不一致问题"></a>Q：缓存异常（上）：解决缓存和数据库的数据不一致问题</h1><h3 id="缓存和数据库的数据不一致是如何发生的？"><a href="#缓存和数据库的数据不一致是如何发生的？" class="headerlink" title="缓存和数据库的数据不一致是如何发生的？"></a>缓存和数据库的数据不一致是如何发生的？</h3><p>首先，我们得清楚“数据的一致性”具体是啥意思。其实，这里的“一致性”包含了两种情况：</p><ul><li><p>缓存中有数据，那么，缓存的数据值需要和数据库中的值相同；</p></li><li><p>缓存中本身没有数据，那么，数据库中的值必须是最新值。</p></li></ul><p>不符合这两种情况的，就属于缓存和数据库的数据不一致问题了。</p><p>对于读写缓存来说，如果要对数据进行增删改，就需要在缓存中进行，同时还要根据采取的写回策略，决定是否同步写回到数据库中。</p><ul><li>同步直写策略：写缓存时，也同步写数据库，缓存和数据库中的数据一致；</li><li>异步写回策略：写缓存时不同步写数据库，等到数据从缓存中淘汰时，再写回数据库。使用这种策略时，如果数据还没有写回数据库，缓存就发生了故障，那么，此时，数据库就没有最新的数据了。</li></ul><h4 id="新增数据"><a href="#新增数据" class="headerlink" title="新增数据"></a>新增数据</h4><p>如果是新增数据，数据会直接写到数据库中，不用对缓存做任何操作，此时，缓存中本身就没有新增数据，而数据库中是最新值，这种情况符合我们刚刚所说的一致性的第 2 种情况，所以，此时，缓存和数据库的数据是一致的。</p><h4 id="删改数据"><a href="#删改数据" class="headerlink" title="删改数据"></a>删改数据</h4><p>情况一：</p><p>我们假设应用先删除缓存，再更新数据库，如果缓存删除成功，但是数据库更新失败，那么，应用再访问数据时，缓存中没有数据，就会发生缓存缺失。然后，应用再访问数据库，但是数据库中的值为旧值，应用就访问到旧值了。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-854bce262c60eb54ec8b66c63ef2ad7486d73ef7.jpg" alt="img" style="zoom:15%;" /><p>应用要把数据 X 的值从 10 更新为 3，先在 Redis 缓存中删除了 X 的缓存值，但是更新数据库却失败了。如果此时有其他并发的请求访问 X，会发现 Redis 中缓存缺失，紧接着，请求就会访问数据库，读到的却是旧值 10。</p><p>情况二：</p><p>我们先更新数据库，再删除缓存中的值。应用要把数据 X 的值从 10 更新为 3，先成功更新了数据库，然后在 Redis 缓存中删除 X 的缓存，但是这个操作却失败了，这个时候，数据库中 X 的新值为 3，Redis 中的 X 的缓存值为 10，这肯定是不一致的。如果刚好此时有其他客户端也发送请求访问 X，会先在 Redis 中查询，该客户端会发现缓存命中，但是读到的却是旧值 10。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-e3435dcb86f9e2d236ec15f049b6e8192b775d72.jpg" alt="img" style="zoom:15%;" /><p>总结：</p><p>在更新数据库和删除缓存值的过程中，无论这两个操作的执行顺序谁先谁后，只要有一个操作失败了，就会导致客户端读取到旧值。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-9f4855399ff31fee5a5ac407a59e62d897644818.jpg" alt="img" style="zoom:15%;" /><h3 id="如何解决数据不一致问题？"><a href="#如何解决数据不一致问题？" class="headerlink" title="如何解决数据不一致问题？"></a>如何解决数据不一致问题？</h3><blockquote><p>首先，没有银弹，没有完美的解决方案和手段，无法做到 100% 解决一致性问题。只能是根据业务的实际情况去选择相对最优的方案。</p></blockquote><h4 id="重试机制"><a href="#重试机制" class="headerlink" title="重试机制"></a>重试机制</h4><p>具体来说，可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。</p><p>如果能够成功地删除或更新，我们就要把这些值从消息队列中去除，以免重复操作，此时，我们也可以保证数据库和缓存的数据一致了。否则的话，我们还需要再次进行重试。如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-4b56b498c159cecba3c57006c5fe47999794b5c7.jpg" alt="img" style="zoom:15%;" /><p>说白了就是把需要更新的数据的消息存在 MQ 中，只有成功操作了（更新 Redis、数据库），才在 MQ 中消费弹出。</p><p>当然引进了 MQ 是为了解决一致性的问题，但是还是会引来新的问题，就是 MQ 的消费与执行的一致性。。。</p><h4 id="高并发下的问题"><a href="#高并发下的问题" class="headerlink" title="高并发下的问题"></a>高并发下的问题</h4><p>在高并发的场景下，无论先更新 Redis 还是先更新 database 都会有一点的时间差，这段时间差，如果有其他线程进行读写数据，依然存在数据不一致的问题。</p><p>因为 Redis 的 database 两者的操作就不符合原子性，所以直接躺平吧。</p><h2 id="Q：缓存异常（下）：解决缓存雪崩、击穿、穿透难题"><a href="#Q：缓存异常（下）：解决缓存雪崩、击穿、穿透难题" class="headerlink" title="Q：缓存异常（下）：解决缓存雪崩、击穿、穿透难题"></a>Q：缓存异常（下）：解决缓存雪崩、击穿、穿透难题</h2><blockquote><p>沾点老八股了</p></blockquote><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>缓存雪崩是指大量的应用请求无法在 Redis 缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增。</p><p><strong>说白了就是大量 kv 在同一时刻过期，而该时刻正是业务高峰期。</strong></p><p><strong>当然 Redis 的突然宕机也会造成缓存雪崩。</strong></p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-03e2219415811640c931ab71fdcaeb6a86bee38f.jpg" alt="img" style="zoom:15%;" /><h4 id="事前应对"><a href="#事前应对" class="headerlink" title="事前应对"></a>事前应对</h4><ul><li>避免给大量的数据设置相同的过期时间。如果业务层的确要求有些数据同时失效。</li><li>可以在用 EXPIRE 命令给每个数据设置过期时间时，给这些数据的过期时间增加一个较小的随机数（例如，随机增加 1~3 分钟），这样一来，不同数据的过期时间有所差别，但差别又不会太大，既避免了大量数据同时过期，同时也保证了这些数据基本在相近的时间失效，仍然能满足业务需求。</li></ul><h4 id="事后应对"><a href="#事后应对" class="headerlink" title="事后应对"></a>事后应对</h4><p>通过服务降级，来应对缓存雪崩。</p><p>所谓的服务降级，是指发生缓存雪崩时，针对不同的数据采取不同的处理方式。</p><ul><li>当业务应用访问的是非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；</li><li>当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。</li></ul><p>当 Redis 出现突然宕机的情况</p><ul><li>在业务系统中实现服务熔断或请求限流机制。</li><li>主从节点切换恢复 Redis 服务</li></ul><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。缓存击穿的情况，经常发生在热点数据过期失效时。</p><p>说白了就是热点 key，本身的流量就大，但是 Redis 里却没有数据</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-b9e9d004817c8b84cb1e1d8aeb19d0580d2e712a.jpg" alt="img" style="zoom:15%;" /><h4 id="如何对敌？"><a href="#如何对敌？" class="headerlink" title="如何对敌？"></a>如何对敌？</h4><p>为了避免缓存击穿给数据库带来的激增压力，我们的解决方法也比较直接，<strong>对于访问特别频繁的热点数据，我们就不设置过期时间了。</strong>这样一来，对热点数据的访问请求，都可以在缓存中进行处理，而 Redis 数万级别的高吞吐量可以很好地应对大量的并发请求访问。</p><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>缓存穿透是指要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。</p><p>跟缓存雪崩、缓存击穿这两类问题相比，缓存穿透的影响更大一些。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-73a11dbf64448ffcb0e793a789ed67515caf9ac9.jpg" alt="img" style="zoom:15%;" /><p>那么，缓存穿透会发生在什么时候呢？一般来说，有两种情况。</p><ul><li>业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；</li><li>恶意攻击：专门访问数据库中没有的数据。</li></ul><h4 id="如何对敌？-1"><a href="#如何对敌？-1" class="headerlink" title="如何对敌？"></a>如何对敌？</h4><p><strong>第一种方案是，缓存空值或缺省值。</strong></p><p>一旦发生缓存穿透，我们就可以针对查询的数据，在 Redis 中缓存一个空值或是和业务层协商确定的缺省值（例如，库存的缺省值可以设为 0）。紧接着，应用发送的后续请求再进行查询时，就可以直接从 Redis 中读取空值或缺省值，返回给业务应用了，避免了把大量请求发送给数据库处理，保持了数据库的正常运行。</p><p><strong>使用布隆过滤器快速判断数据是否存在</strong></p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-416bdd26610adf1ac6cfbc3e600fcbe512eb72b5.jpg" alt="img" style="zoom:15%;" /><p>我们可以在把数据写入数据库时，使用布隆过滤器做个标记。当缓存缺失后，应用查询数据库时，可以通过查询布隆过滤器快速判断数据是否存在。如果不存在，就不用再去数据库中查询了。</p><p><strong>在请求入口的前端进行请求检测</strong></p><p>前端拦截恶意的请求</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-2ff5c4527331cecaff4a44e62ea5149d215b9780.jpg" alt="img" style="zoom:25%;" /><ul><li>针对缓存雪崩，合理地设置数据过期时间，以及搭建高可靠缓存集群；</li><li>针对缓存击穿，在缓存访问非常频繁的热点数据时，不要设置过期时间；</li><li>针对缓存穿透，提前在入口前端实现恶意请求检测，或者规范数据库的数据删除操作，避免误删除。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="中间件" scheme="https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Redis" scheme="https://matthew-han.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis 笔记六</title>
    <link href="https://matthew-han.github.io/post/1cae1360-e47c-11eb-8456-9d0bf7563314/"/>
    <id>https://matthew-han.github.io/post/1cae1360-e47c-11eb-8456-9d0bf7563314/</id>
    <published>2021-07-14T08:18:47.000Z</published>
    <updated>2025-09-06T04:13:54.321Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Q：什么是内存碎片"><a href="#Q：什么是内存碎片" class="headerlink" title="Q：什么是内存碎片"></a>Q：什么是内存碎片</h1><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-b7e68251e007c60af39783483e9f7a7e1e93d3f5.jpg" alt="img" style="zoom:15%;" /><p>我们可以把这些分散的空座位叫作“车厢座位碎片”，知道了这一点，操作系统的内存碎片就很容易理解了。虽然操作系统的剩余内存空间总量足够，<strong>但是应用申请的是一块连续地址空间的 N 字节</strong>，但在剩余的内存空间中，没有大小为 <strong>N</strong> 字节的连续空间了，那么，这些剩余空间就是内存碎片（比如上图中的“空闲 2 字节”和“空闲 1 字节”，就是这样的碎片）。</p><h1 id="Q：内存碎片是如何形成的"><a href="#Q：内存碎片是如何形成的" class="headerlink" title="Q：内存碎片是如何形成的"></a>Q：内存碎片是如何形成的</h1><p>其实，内存碎片的形成有内因和外因两个层面的原因。简单来说，内因是操作系统的内存分配机制，外因是 Redis 的负载特征。</p><h2 id="内因：内存分配器的分配策略"><a href="#内因：内存分配器的分配策略" class="headerlink" title="内因：内存分配器的分配策略"></a>内因：内存分配器的分配策略</h2><p>Redis 可以使用 libc、jemalloc、tcmalloc 多种内存分配器来分配内存，默认使用 jemalloc。</p><p>jemalloc 的分配策略之一，是按照一系列固定的大小划分内存空间，例如 8 字节、16 字节、32 字节、48 字节，…, 2KB、4KB、8KB 等。当程序申请的内存最接近某个固定值时，jemalloc 会给它分配相应大小的空间。</p><p>这样的分配方式本身是为了减少分配次数。例如，Redis 申请一个 20 字节的空间保存数据，jemalloc 就会分配 32 字节，此时，如果应用还要写入 10 字节的数据，Redis 就不用再向操作系统申请空间了，因为刚才分配的 32 字节已经够用了，这就避免了一次分配操作。</p><h2 id="外因：键值对大小不一样和删改操作"><a href="#外因：键值对大小不一样和删改操作" class="headerlink" title="外因：键值对大小不一样和删改操作"></a>外因：键值对大小不一样和删改操作</h2><p>应用 A 保存 6 字节数据，jemalloc 按分配策略分配 8 字节。如果应用 A 不再保存新数据，那么，这里多出来的 2 字节空间就是内存碎片了。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-9e03668425b59fa47a79ca78645c4d916780e2ff.jpg" alt="img" style="zoom:15%;" /><p>第二个外因是，这些键值对会被修改和删除，这会导致空间的扩容和释放。具体来说，一方面，如果修改后的键值对变大或变小了，就需要占用额外的空间或者释放不用的空间。另一方面，删除的键值对就不再需要内存空间了，此时，就会把空间释放出来，形成空闲空间。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-cd062c22994d9906bb53ae0112ed2e5e79f4b7e9.jpg" alt="img" style="zoom:15%;" /><p>一开始，应用 A、B、C、D 分别保存了 3、1、2、4 字节的数据，并占据了相应的内存空间。然后，应用 D 删除了 1 个字节，这个 1 字节的内存空间就空出来了。紧接着，应用 A 修改了数据，从 3 字节变成了 4 字节。为了保持 A 数据的空间连续性，操作系统就需要把 B 的数据拷贝到别的空间，比如拷贝到 D 刚刚释放的空间中。此时，应用 C 和 D 也分别删除了 2 字节和 1 字节的数据，整个内存空间上就分别出现了 2 字节和 1 字节的空闲碎片。如果应用 E 想要一个 3 字节的连续空间，显然是不能得到满足的。因为，虽然空间总量够，但却是碎片空间，并不是连续的。</p><h2 id="如何判断是否有内存碎片？"><a href="#如何判断是否有内存碎片？" class="headerlink" title="如何判断是否有内存碎片？"></a>如何判断是否有内存碎片？</h2><p>Redis 自身提供了 INFO 命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">INFO memory</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Memory</span></span><br><span class="line">used_memory:1073741736</span><br><span class="line">used_memory_human:1024.00M</span><br><span class="line">used_memory_rss:1997159792</span><br><span class="line">used_memory_rss_human:1.86G</span><br><span class="line">…</span><br><span class="line">mem_fragmentation_ratio:1.86</span><br></pre></td></tr></table></figure><p>这里有一个 mem_fragmentation_ratio 的指标，它表示的就是 Redis 当前的内存碎片率。那么，这个碎片率是怎么计算的呢？其实，就是上面的命令中的两个指标 used_memory_rss 和 used_memory 相除的结果。</p><p><code>mem_fragmentation_ratio = used_memory_rss/ used_memory</code></p><ul><li>used_memory_rss 是操作系统实际分配给 Redis 的物理内存空间，里面就包含了碎片；</li><li>used_memory 是 Redis 为了保存数据实际申请使用的空间。</li></ul><p>经验之谈：</p><ul><li>mem_fragmentation_ratio 大于 1 但小于 1.5。这种情况是合理的。这是因为，刚才介绍的那些因素是难以避免的。毕竟，内因的内存分配器是一定要使用的，分配策略都是通用的，不会轻易修改；而外因由 Redis 负载决定，也无法限制。所以，存在内存碎片也是正常的。</li><li>mem_fragmentation_ratio 大于 1.5 。这表明内存碎片率已经超过了 50%。一般情况下，这个时候，我们就需要采取一些措施来降低内存碎片率了。</li><li>mem_fragmentation_ratio 小于 1，发生了 swap</li></ul><blockquote><p>Matthew Han：mem_fragmentation_ratio 小于 1的情况，还可能会触发内存淘汰机制，删除大量的 key，阻塞主线程。</p></blockquote><h1 id="如何清理内存碎片？"><a href="#如何清理内存碎片？" class="headerlink" title="如何清理内存碎片？"></a>如何清理内存碎片？</h1><ol start="0"><li>直接重启 Redis 实例（但是没有持久化AOF、RDB，数据就会丢失）</li><li>从 4.0-RC3 版本以后，Redis 自身提供了一种内存碎片自动清理的方法。</li></ol><p>内存碎片清理，简单来说，就是“搬家让位，合并空间”。</p><blockquote><p>Matthew Han：沾点 JVM GC 的标记 -整理了</p></blockquote><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-2d9ed7f9b6be42e8e45a92e7d69a07dd2091c6b2.jpg" alt="img" style="zoom:15%;" /><p>需要注意的是：<strong>碎片清理是有代价的</strong>，操作系统需要把多份数据拷贝到新位置，把原有空间释放出来，这会带来时间开销。</p><p>首先，Redis 需要启用自动内存碎片清理，可以把 activedefrag 配置项设置为 yes，命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config set activedefrag yes</span><br></pre></td></tr></table></figure><p>我们可以通过设置参数，来控制碎片清理的开始和结束时机，以及占用的 CPU 比例，从而减少碎片清理对 Redis 本身请求处理的性能影响。</p><p>这两个参数分别设置了触发内存清理的一个条件，如果同时满足这两个条件，就开始清理。在清理的过程中，只要有一个条件不满足了，就停止自动清理。</p><ul><li>active-defrag-ignore-bytes 100mb：表示内存碎片的字节数达到 100MB 时，开始清理；</li><li>active-defrag-threshold-lower 10：表示内存碎片空间占操作系统分配给 Redis 的总空间比例达到 10% 时，开始清理。</li></ul><p>为了尽可能减少碎片清理对 Redis 正常请求处理的影响，自动内存碎片清理功能在执行时，还会监控清理操作占用的 CPU 时间，而且还设置了两个参数，分别用于控制清理操作占用的 CPU 时间比例的上、下限，既保证清理工作能正常进行，又避免了降低 Redis 性能。这两个参数具体如下：</p><ul><li>active-defrag-cycle-min 25： 表示自动清理过程所用 CPU 时间的比例不低于 25%，保证清理能正常开展；</li><li>active-defrag-cycle-max 75：表示自动清理过程所用 CPU 时间的比例不高于 75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞 Redis，导致响应延迟升高。</li></ul><h1 id="Q：缓冲区引发的惨案"><a href="#Q：缓冲区引发的惨案" class="headerlink" title="Q：缓冲区引发的惨案"></a>Q：缓冲区引发的惨案</h1><h2 id="客户端输入和输出缓冲区"><a href="#客户端输入和输出缓冲区" class="headerlink" title="客户端输入和输出缓冲区"></a>客户端输入和输出缓冲区</h2><p>为了避免客户端和服务器端的请求发送和处理速度不匹配，服务器端给每个连接的客户端都设置了一个输入缓冲区和输出缓冲区，我们称之为客户端输入缓冲区和输出缓冲区。</p><p>输入缓冲区会先把客户端发送过来的命令暂存起来，Redis 主线程再从输入缓冲区中读取命令，进行处理。当 Redis 主线程处理完数据后，会把结果写入到输出缓冲区，再通过输出缓冲区返回给客户端。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-74493064a498e0d1b5514152b723f98269b44e41.jpg" alt="img" style="zoom:15%;" /><h2 id="如何应对输入缓冲区溢出？"><a href="#如何应对输入缓冲区溢出？" class="headerlink" title="如何应对输入缓冲区溢出？"></a>如何应对输入缓冲区溢出？</h2><ul><li>写入了 bigkey，比如一下子写入了多个百万级别的集合类型数据；</li><li>服务器端处理请求的速度过慢，例如，Redis 主线程出现了间歇性阻塞，无法及时处理正常发送的请求，导致客户端发送的请求在缓冲区越积越多。</li></ul><p>避免输入缓冲区溢出。我们可以从两个角度去考虑如何避免，一是把缓冲区调大，二是从数据命令的发送和处理速度入手。</p><p><strong>输入缓冲区没法调大</strong></p><h2 id="如何应对输出缓冲区溢出？"><a href="#如何应对输出缓冲区溢出？" class="headerlink" title="如何应对输出缓冲区溢出？"></a>如何应对输出缓冲区溢出？</h2><ul><li>服务器端返回 bigkey 的大量结果；</li><li>执行了 MONITOR 命令；</li><li>缓冲区大小设置得不合理。</li></ul><p>和输入缓冲区不同，我们可以通过 client-output-buffer-limit 配置项，来设置输出缓冲区的大小。</p><h2 id="主从集群中的缓冲区"><a href="#主从集群中的缓冲区" class="headerlink" title="主从集群中的缓冲区"></a>主从集群中的缓冲区</h2><blockquote><p>全量同步</p></blockquote><p>在全量复制过程中，主节点在向从节点传输 RDB 文件的同时，会继续接收客户端发送的写命令请求。这些写命令就会先保存在复制缓冲区中，等 RDB 文件传输完成后，再发送给从节点去执行。主节点上会为每个从节点都维护一个复制缓冲区，来保证主从节点间的数据同步。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-fd374c2d1c0d9102a97268ce7e05a83242a5d929.jpg" alt="img" style="zoom:15%;" /><p>复制缓冲区一旦发生溢出，主节点也会直接关闭和从节点进行复制操作的连接，导致全量复制失败。</p><h2 id="复制积压缓冲区的溢出问题"><a href="#复制积压缓冲区的溢出问题" class="headerlink" title="复制积压缓冲区的溢出问题"></a>复制积压缓冲区的溢出问题</h2><blockquote><p>增量同步</p></blockquote><p>我们再来看下增量复制时使用的缓冲区，这个缓冲区称为复制积压缓冲区。主节点在把接收到的写命令同步给从节点时，同时会把这些写命令写入复制积压缓冲区。一旦从节点发生网络闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区中，读取断连期间主节点接收到的写命令，进而进行增量同步。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-03a3039183306e5adbfad71841cc02bc0c676001.jpg" alt="img" style="zoom:15%;" /><p>其实他就是 repl_backlog_buffer，复制积压缓冲区是一个大小有限的环形缓冲区。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="中间件" scheme="https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Redis" scheme="https://matthew-han.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis 笔记五</title>
    <link href="https://matthew-han.github.io/post/3414aaf0-e46d-11eb-9597-7d5c165039f4/"/>
    <id>https://matthew-han.github.io/post/3414aaf0-e46d-11eb-9597-7d5c165039f4/</id>
    <published>2021-07-14T06:32:04.000Z</published>
    <updated>2025-09-06T04:08:29.702Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Q：如何应对变慢的Redis（总结）"><a href="#Q：如何应对变慢的Redis（总结）" class="headerlink" title="Q：如何应对变慢的Redis（总结）"></a>Q：如何应对变慢的Redis（总结）</h1><blockquote><p>个人总结版本</p></blockquote><ol start="0"><li>AOF 重写问题，比如设置了 everysec ，上一次还妹写完，下一次又来了</li><li>发生了 swap 内存交换</li><li>查看基线性能</li><li>查看延迟的绝对值</li><li>是否有慢查询</li><li>是否会出现同一时刻大批量 kv 的过期</li><li>是否存在 bigkey</li><li>是否存在透明大页</li><li>是否出现频繁切换 socket，需要绑核</li><li>主从集群下是否主库过大，导致 RDB 载入阻塞</li></ol><blockquote><p>老师总结版本</p></blockquote><ol start="0"><li>获取 Redis 实例在当前环境下的基线性能。</li><li>是否用了慢查询命令？如果是的话，就使用其他命令替代慢查询命令，或者把聚合计算命令放在客户端做。</li><li>是否对过期 key 设置了相同的过期时间？对于批量删除的 key，可以在每个 key 的过期时间上加一个随机数，避免同时删除。</li><li>是否存在 bigkey？ 对于 bigkey 的删除操作，如果你的 Redis 是 4.0 及以上的版本，可以直接利用异步线程机制减少主线程阻塞；如果是 Redis 4.0 以前的版本，可以使用 SCAN 命令迭代删除；对于 bigkey 的集合查询和聚合操作，可以使用 SCAN 命令在客户端完成。</li><li>Redis AOF 配置级别是什么？业务层面是否的确需要这一可靠性级别？如果我们需要高性能，同时也允许数据丢失，可以将配置项 no-appendfsync-on-rewrite 设置为 yes，避免 AOF 重写和 fsync 竞争磁盘 IO 资源，导致 Redis 延迟增加。当然， 如果既需要高性能又需要高可靠性，最好使用高速固态盘作为 AOF 日志的写入盘。</li><li>Redis 实例的内存使用是否过大？发生 swap 了吗？如果是的话，就增加机器内存，或者是使用 Redis 集群，分摊单机 Redis 的键值对数量和内存压力。同时，要避免出现 Redis 和其他内存需求大的应用共享机器的情况。</li><li>在 Redis 实例的运行环境中，是否启用了透明大页机制？如果是的话，直接关闭内存大页机制就行了。</li><li>是否运行了 Redis 主从集群？如果是的话，把主库实例的数据量大小控制在 2~4GB，以免主从复制时，从库因加载大的 RDB 文件而阻塞。</li><li>是否使用了多核 CPU 或 NUMA 架构的机器运行 Redis 实例？使用多核 CPU 时，可以给 Redis 实例绑定物理核；使用 NUMA 架构时，注意把 Redis 实例和网络中断处理程序运行在同一个 CPU Socket 上。</li></ol><h1 id="Q：如何应对变慢的Redis（SUB：Redis-自身）"><a href="#Q：如何应对变慢的Redis（SUB：Redis-自身）" class="headerlink" title="Q：如何应对变慢的Redis（SUB：Redis 自身）"></a>Q：如何应对变慢的Redis（SUB：Redis 自身）</h1><ol start="0"><li>如何判断 Redis 是不是真的变慢了。一个最直接的方法，<strong>就是查看 Redis 的响应延迟。</strong></li><li><strong>看基线性能。</strong>基于当前环境下的 Redis 基线性能做判断。所谓的基线性能，就是一个系统在低压力、无干扰下的基本性能，这个性能只由当前的软硬件配置决定。</li></ol><h2 id="如何应对-Redis-变慢？"><a href="#如何应对-Redis-变慢？" class="headerlink" title="如何应对 Redis 变慢？"></a>如何应对 Redis 变慢？</h2><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-9fa20e213cd4bd80a6d464fdb25d3a4e520a7f68.jpg" alt="img" style="zoom:15%;" /><h3 id="Redis-自身操作特性的影响"><a href="#Redis-自身操作特性的影响" class="headerlink" title="Redis 自身操作特性的影响"></a>Redis 自身操作特性的影响</h3><ol start="0"><li><p><strong>慢查询命令</strong></p><ol><li><p>例子：Value 类型为 String 时，GET&#x2F;SET 操作主要就是操作 Redis 的哈希表索引。这个操作复杂度基本是固定的，即 $O(1)$。但是，当 Value 类型为 Set 时，SORT、SUNION&#x2F;SMEMBERS 操作复杂度分别为 $O(N+M*log(M))$ 和 $O(N)$。其中，$N$ 为 Set 中的元素个数，$M$ 为 SORT 操作返回的元素个数。这个复杂度就增加了很多。</p></li><li><p>解决手段</p><ol><li><p>用其他高效命令代替。比如说，如果你需要返回一个 SET 中的所有成员时，不要使用 SMEMBERS 命令，而是要使用 SSCAN 多次迭代返回，避免一次返回大量数据，造成线程阻塞。</p></li><li><p>当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。</p></li><li><p>keys 命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">redis&gt; </span><span class="language-bash">KEYS *name*</span></span><br><span class="line">1) &quot;lastname&quot;</span><br><span class="line">2) &quot;firstname&quot;</span><br></pre></td></tr></table></figure><p><strong>因为 KEYS 命令需要遍历存储的键值对</strong>，所以操作延时高。如果你不了解它的实现而使用了它，就会导致 Redis 性能变慢。所以，<strong>KEYS 命令一般不被建议用于生产环境中。</strong></p></li></ol></li></ol></li><li><p><strong>过期 key 操作（删除操作是阻塞的，Redis 4.0 后可以用异步线程机制来减少阻塞影响）</strong></p><ol><li>默认情况下，Redis 每 100 毫秒会删除一些过期 key。具体算法：<ol><li>采样 ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 个数的 key，并将其中过期的 key 全部删除；</li><li>如果超过 25% 的 key 过期了，则重复删除的过程，直到过期 key 的比例降至 25% 以下。</li></ol></li><li>频繁使用带有相同时间参数的 EXPIREAT 命令设置过期 key</li><li>解决手段：如果一批 key 的确是同时过期，你还可以在 EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数，这样，既保证了 key 在一个邻近时间范围内被删除，又避免了同时过期造成的压力。</li></ol><blockquote><p>说白了就是不要出现同一时刻大量 key 过期导致的雪崩。</p></blockquote></li></ol><h1 id="Q：如何应对变慢的Redis（SUB：文件系统：AOF）"><a href="#Q：如何应对变慢的Redis（SUB：文件系统：AOF）" class="headerlink" title="Q：如何应对变慢的Redis（SUB：文件系统：AOF）"></a>Q：如何应对变慢的Redis（SUB：文件系统：AOF）</h1><p><strong>always 策略并不使用后台子线程来执行。</strong></p><p>当主线程使用后台子线程执行了一次 fsync，需要再次把新接收的操作记录写回磁盘时，如果主线程发现上一次的 fsync 还没有执行完，那么它就会阻塞。所以，如果后台子线程执行的 fsync 频繁阻塞的话（比如 AOF 重写占用了大量的磁盘 IO 带宽），主线程也会阻塞，导致 Redis 性能变慢。</p><h1 id="Q：如何应对变慢的Redis（SUB：操作系统-swap）"><a href="#Q：如何应对变慢的Redis（SUB：操作系统-swap）" class="headerlink" title="Q：如何应对变慢的Redis（SUB：操作系统 swap）"></a>Q：如何应对变慢的Redis（SUB：操作系统 swap）</h1><p>内存 swap 是操作系统里将内存数据在内存和磁盘间来回换入和换出的机制。</p><p>通常，触发 swap 的原因主要是物理机器内存不足，对于 Redis 而言，有两种常见的情况：</p><ul><li>Redis 实例自身使用了大量的内存，导致物理机器的可用内存不足；</li><li>Redis 实例在同一台机器上运行的其他进程，在进行大量的文件读写操作。文件读写本身会占用系统内存，这会导致分配给 Redis 实例的内存量变少，进而触发 Redis 发生 swap。</li></ul><p>针对这个问题，我也给你提供一个解决思路：增加机器的内存或者使用 Redis 集群。</p><h1 id="Q：如何应对变慢的Redis（SUB：操作系统内存大页）"><a href="#Q：如何应对变慢的Redis（SUB：操作系统内存大页）" class="headerlink" title="Q：如何应对变慢的Redis（SUB：操作系统内存大页）"></a>Q：如何应对变慢的Redis（SUB：操作系统内存大页）</h1><p>除了内存 swap，还有一个和内存相关的因素，即内存大页机制（Transparent Huge Page, THP），也会影响 Redis 性能。</p><p>Linux 内核从 2.6.38 开始支持内存大页机制，该机制支持 2MB 大小的内存页分配，而常规的内存页分配是按 4KB 的粒度来执行的。</p><p>如果采用了内存大页，那么，即使客户端请求只修改 100B 的数据，Redis 也需要拷贝 2MB 的大页。相反，如果是常规内存页机制，只用拷贝 4KB。两者相比，你可以看到，当客户端请求修改或新写入数据较多时，内存大页机制将导致大量的拷贝，这就会影响 Redis 正常的访存操作，最终导致性能变慢。</p><p>出现问题之后该机制可以关闭。</p><h1 id="Q：缓存满了怎么办"><a href="#Q：缓存满了怎么办" class="headerlink" title="Q：缓存满了怎么办"></a>Q：缓存满了怎么办</h1><p>Redis 有一个重要机制，即缓存数据的淘汰机制。</p><p>可以设置一个最大容量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CONFIG SET maxmemory 4gb</span><br></pre></td></tr></table></figure><h2 id="Redis-缓存有哪些淘汰策略？"><a href="#Redis-缓存有哪些淘汰策略？" class="headerlink" title="Redis 缓存有哪些淘汰策略？"></a>Redis 缓存有哪些淘汰策略？</h2><ul><li>在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis 4.0 后新增）四种。</li><li>在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）三种。</li></ul><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-dc8c6cac077386a7e3ea23bcd4de3059a3718e5f.jpg" alt="img" style="zoom:30%;" /><p>3.0 之后的默认情况下，Redis 在使用的内存空间超过 maxmemory 值时，并不会淘汰数据，也就是设定的 <strong>noeviction</strong> 策略。对应到 Redis 缓存，也就是指，一旦缓存被写满了，再有写请求来时，Redis 不再提供服务，而是直接返回错误。</p><p><em><em>volatile</em> 这种淘汰策略。它们筛选的候选数据范围，被限制在已经设置了过期时间的键值对上。</em>*</p><ul><li>volatile-ttl 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。</li><li>volatile-random 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。</li><li>volatile-lru 会使用 LRU 算法筛选设置了过期时间的键值对。</li><li>volatile-lfu 会使用 LFU 算法选择设置了过期时间的键值对。</li></ul><p><em><em>allkeys</em> 这种淘汰策略的备选淘汰数据范围，就扩大到了所有键值对，无论这些键值对是否设置了过期时间。</em>*</p><ul><li>allkeys-random 策略，从所有键值对中随机选择并删除数据；</li><li>allkeys-lru 策略，使用 LRU 算法在所有数据中进行筛选。</li><li>allkeys-lfu 策略，使用 LFU 算法在所有数据中进行筛选。</li></ul><p>在 Redis 中，LRU 算法被做了简化，以减轻数据淘汰对缓存性能的影响。具体来说，Redis 默认会记录每个数据的最近一次访问的时间戳（由键值对数据结构 RedisObject 中的 lru 字段记录）。然后，Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="中间件" scheme="https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Redis" scheme="https://matthew-han.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis 笔记四</title>
    <link href="https://matthew-han.github.io/post/20dc2440-e2dd-11eb-b58c-3b03d3077551/"/>
    <id>https://matthew-han.github.io/post/20dc2440-e2dd-11eb-b58c-3b03d3077551/</id>
    <published>2021-07-12T06:48:13.000Z</published>
    <updated>2025-09-06T04:03:37.492Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Q：异步机制"><a href="#Q：异步机制" class="headerlink" title="Q：异步机制"></a>Q：异步机制</h1><h2 id="Redis-实例有哪些阻塞点？"><a href="#Redis-实例有哪些阻塞点？" class="headerlink" title="Redis 实例有哪些阻塞点？"></a>Redis 实例有哪些阻塞点？</h2><p>Redis 实例在运行时，要和许多对象进行交互，这些不同的交互就会涉及不同的操作，下面我们来看看和 Redis 实例交互的对象，以及交互时会发生的操作。</p><pre><code>0. 客户端：网络 IO，键值对增删改查操作，数据库操作；0. 磁盘：生成 RDB 快照，记录 AOF 日志，AOF 日志重写；0. 主从节点：主库生成、传输 RDB 文件，从库接收 RDB 文件、清空数据库、加载 RDB 文件；0. 切片集群实例：向其他实例传输哈希槽信息，数据迁移。</code></pre><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-65fb622ac8af7fb29b8a40d875fc07bd9500966f.jpg" alt="img" style="zoom:15%;" /><h3 id="0-和客户端交互时的阻塞点"><a href="#0-和客户端交互时的阻塞点" class="headerlink" title="0. 和客户端交互时的阻塞点"></a>0. 和客户端交互时的阻塞点</h3><p>网络 IO 有时候会比较慢，但是 Redis 使用了 IO 多路复用机制，避免了主线程一直处在等待网络连接或请求到来的状态，所以，网络 IO 不是导致 Redis 阻塞的因素。</p><p>Redis 中涉及集合的操作复杂度通常为 $O(N)$，我们要在使用时重视起来。例如集合元素全量查询操作 HGETALL、SMEMBERS，以及集合的聚合统计操作，例如求交、并和差集。这些操作可以作为 Redis 的第一个阻塞点：<strong>集合全量查询和聚合操作</strong>。</p><p><strong>bigkey 删除操作就是 Redis 的第二个阻塞点</strong>。删除操作对 Redis 实例性能的负面影响很大，而且在实际业务开发时容易被忽略，所以一定要重视它。既然频繁删除键值对都是潜在的阻塞点了，那么，在 Redis 的数据库级别操作中，清空数据库（例如 FLUSHDB 和 FLUSHALL 操作）必然也是一个潜在的阻塞风险，因为它涉及到删除和释放所有的键值对。所以，这就是 Redis 的第三个阻塞点：<strong>清空数据库</strong>。</p><h3 id="1-和磁盘交互时的阻塞点"><a href="#1-和磁盘交互时的阻塞点" class="headerlink" title="1. 和磁盘交互时的阻塞点"></a>1. 和磁盘交互时的阻塞点</h3><p>Redis 的第四个阻塞点了：AOF 日志同步写。</p><h3 id="2-主从节点交互时的阻塞点"><a href="#2-主从节点交互时的阻塞点" class="headerlink" title="2. 主从节点交互时的阻塞点"></a>2. 主从节点交互时的阻塞点</h3><p>在主从集群中，主库需要生成 RDB 文件，并传输给从库。主库在复制的过程中，创建和传输 RDB 文件都是由子进程来完成的，不会阻塞主线程。<strong>但是，对于从库来说，它在接收了 RDB 文件后，需要使用 FLUSHDB 命令清空当前数据库，这就正好撞上了刚才我们分析的第三个阻塞点</strong>。此外，从库在清空当前数据库后，还需要把 RDB 文件加载到内存，这个过程的快慢和 RDB 文件的大小密切相关，RDB 文件越大，加载过程越慢，所以，<strong>加载 RDB 文件就成为了 Redis 的第五个阻塞点</strong>。</p><h3 id="3-切片集群实例交互时的阻塞点"><a href="#3-切片集群实例交互时的阻塞点" class="headerlink" title="3. 切片集群实例交互时的阻塞点"></a>3. 切片集群实例交互时的阻塞点</h3><p>当我们部署 Redis 切片集群时，每个 Redis 实例上分配的哈希槽信息需要在不同实例间进行传递，同时，当需要进行负载均衡或者有实例增删时，数据会在不同的实例间进行迁移。不过，哈希槽的信息量不大，而数据迁移是渐进式执行的，所以，一般来说，这两类操作对 Redis 主线程的阻塞风险不大。</p><p>除非迁移的是 bigkey。</p><p><strong>五个阻塞点：</strong></p><ol start="0"><li>集合全量查询和聚合操作；</li><li>bigkey 删除；</li><li>清空数据库；</li><li>AOF 日志同步写；</li><li>从库加载 RDB 文件。</li></ol><h2 id="哪些阻塞点可以异步执行？"><a href="#哪些阻塞点可以异步执行？" class="headerlink" title="哪些阻塞点可以异步执行？"></a>哪些阻塞点可以异步执行？</h2><p>如果一个操作能被异步执行，就意味着，它并不是 Redis 主线程的关键路径上的操作。我再解释下关键路径上的操作是啥。这就是说，客户端把请求发送给 Redis 后，等着 Redis 返回数据结果的操作。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-c24c620a61da2f7fb089987c99d79c0f9bfe1a26.jpg" alt="img" style="zoom:15%;" /><p>对于 Redis 来说，<strong>读操作是典型的关键路径操作</strong>，因为客户端发送了读操作之后，就会等待读取的数据返回，以便进行后续的数据处理。而 Redis 的第一个阻塞点“集合全量查询和聚合操作”都涉及到了读操作，所以，它们是不能进行异步操作了。</p><p>我们再来看看删除操作。删除操作并不需要给客户端返回具体的数据结果，所以不算是关键路径操作。而我们刚才总结的第二个阻塞点“bigkey 删除”，和第三个阻塞点“清空数据库”，都是对数据做删除，并不在关键路径上。因此，我们可以使用后台子线程来异步执行删除操作。</p><p>对于第四个阻塞点“AOF 日志同步写”来说，为了保证数据可靠性，Redis 实例需要保证 AOF 日志中的操作记录已经落盘，这个操作虽然需要实例等待，但它并不会返回具体的数据结果给实例。所以，我们也可以启动一个子线程来执行 AOF 日志的同步写，而不用让主线程等待 AOF 日志的写完成。</p><p><strong>对于 Redis 的五大阻塞点来说，除了“集合全量查询和聚合操作”和“从库加载 RDB 文件”，其他三个阻塞点涉及的操作都不在关键路径上，所以，我们可以使用 Redis 的异步子线程机制来实现 bigkey 删除，清空数据库，以及 AOF 日志同步写。</strong></p><h2 id="异步的子线程机制"><a href="#异步的子线程机制" class="headerlink" title="异步的子线程机制"></a>异步的子线程机制</h2><p>Redis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-9e362e8f1902958f3abfcc63cc1f9ffe75bc2c95.jpg" alt="img" style="zoom:15%;" /><p>异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能，Redis 也提供了新的命令来执行这两个操作。</p><ul><li><p>键值对删除：当你的集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，我建议你使用 UNLINK 命令。</p></li><li><p>清空数据库：可以在 FLUSHDB 和 FLUSHALL 命令后加上 ASYNC 选项，这样就可以让后台子线程异步地清空数据库，如下所示：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FLUSHDB ASYNC</span><br><span class="line">FLUSHALL AYSNC</span><br></pre></td></tr></table></figure></li></ul><h1 id="Q：CPU-与-Redis"><a href="#Q：CPU-与-Redis" class="headerlink" title="Q：CPU 与 Redis"></a>Q：CPU 与 Redis</h1><h2 id="主流的-CPU-架构"><a href="#主流的-CPU-架构" class="headerlink" title="主流的 CPU 架构"></a>主流的 CPU 架构</h2><p>一个 CPU 处理器中一般有多个运行核心，我们把一个运行核心称为一个物理核，每个物理核都可以运行应用程序。每个物理核都拥有私有的一级缓存（Level 1 cache，简称 L1 cache），包括一级指令缓存和一级数据缓存，以及私有的二级缓存（Level 2 cache，简称 L2 cache）。不同的物理核还会共享一个共同的三级缓存（Level 3 cache，简称为 L3 cache）。</p><p>另外，现在主流的 CPU 处理器中，每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-268b727271cd8da1cf2db62c8620805c13d87c7e.jpg" alt="img" style="zoom:15%;" /><p>在主流的服务器上，一个 CPU 处理器会有 10 到 20 多个物理核。同时，为了提升服务器的处理能力，服务器上通常还会有多个 CPU 处理器（也称为多 CPU Socket），每个处理器有自己的物理核（包括 L1、L2 缓存），L3 缓存，以及连接的内存，同时，不同处理器间通过总线连接。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-64cab13df3aa69439287b908360c8da6dac29edd.jpg" alt="img" style="zoom:15%;" /><p>在多 CPU 架构上，应用程序可以在不同的处理器上运行。在刚才的图中，Redis 可以先在 Socket 1 上运行一段时间，然后再被调度到 Socket 2 上运行。</p><p>但是，有个地方需要注意一下：如果应用程序先在一个 Socket 上运行，并且把数据保存到了内存，然后被调度到另一个 Socket 上运行，此时，应用程序再进行内存访问时，就需要访问之前 Socket 上连接的内存，这种访问属于远端内存访问。和访问 Socket 直接连接的内存相比，远端内存访问会增加应用程序的延迟。</p><p>在多 CPU 架构下，一个应用程序访问所在 Socket 的本地内存和访问远端内存的延迟并不一致，所以，我们也把这个架构称为非统一内存访问架构（Non-Uniform Memory Access，NUMA 架构）。</p><h2 id="CPU-多核对-Redis-性能的影响"><a href="#CPU-多核对-Redis-性能的影响" class="headerlink" title="CPU 多核对 Redis 性能的影响"></a>CPU 多核对 Redis 性能的影响</h2><p>CPU 的 context switch 次数比较多会影响 Redis 的读写性能。</p><p>context switch 是指线程的上下文切换，这里的上下文就是线程的运行时信息。在 CPU 多核的环境中，一个线程先在一个 CPU 核上运行，之后又切换到另一个 CPU 核上运行，这时就会发生 context switch。</p><p>如果在 CPU 多核场景下，Redis 实例被频繁调度到不同 CPU 核上运行的话，那么，对 Redis 实例的请求处理时间影响就更大了。每调度一次，一些请求就会受到运行时信息、指令和数据重新加载过程的影响，这就会导致某些请求的延迟明显高于其他请求。</p><p>我们可以使用 taskset 命令把一个程序绑定在一个核上运行。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">taskset -c 0 ./redis-server</span><br></pre></td></tr></table></figure><h2 id="CPU-的-NUMA-架构对-Redis-性能的影响"><a href="#CPU-的-NUMA-架构对-Redis-性能的影响" class="headerlink" title="CPU 的 NUMA 架构对 Redis 性能的影响"></a>CPU 的 NUMA 架构对 Redis 性能的影响</h2><p>如果网络中断处理程序和 Redis 实例各自所绑的 CPU 核不在同一个 CPU Socket 上，那么，Redis 实例读取网络数据时，就需要跨 CPU Socket 访问内存，这个过程会花费较多时间。</p><p>所以，为了避免 Redis 跨 CPU Socket 访问网络数据，我们最好把网络中断程序和 Redis 实例绑在同一个 CPU Socket 上，这样一来，Redis 实例就可以直接从本地内存读取网络数据了。</p><p>在 CPU 的 NUMA 架构下，对 CPU 核的编号规则，并不是先把一个 CPU Socket 中的所有逻辑核编完，再对下一个 CPU Socket 中的逻辑核编码，而是先给每个 CPU Socket 中每个物理核的第一个逻辑核依次编号，再给每个 CPU Socket 中的物理核的第二个逻辑核依次编号。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">lscpu</span><br><span class="line"></span><br><span class="line">Architecture: x86_64</span><br><span class="line">...</span><br><span class="line">NUMA node0 CPU(s): 0-5,12-17</span><br><span class="line">NUMA node1 CPU(s): 6-11,18-23</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h2 id="绑核的风险和解决方案"><a href="#绑核的风险和解决方案" class="headerlink" title="绑核的风险和解决方案"></a>绑核的风险和解决方案</h2><p>把 Redis 实例和物理核绑定，可以让主线程、子进程、后台线程共享使用 2 个逻辑核，可以在一定程度上缓解 CPU 资源竞争。但是，因为只用了 2 个逻辑核，它们相互之间的 CPU 竞争仍然还会存在。</p><p>另一种方案：修改 Redis 源码（略）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="中间件" scheme="https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Redis" scheme="https://matthew-han.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis 笔记三</title>
    <link href="https://matthew-han.github.io/post/04c289c0-e2dd-11eb-9088-bdddfe01ee68/"/>
    <id>https://matthew-han.github.io/post/04c289c0-e2dd-11eb-9088-bdddfe01ee68/</id>
    <published>2021-07-12T06:47:26.000Z</published>
    <updated>2025-09-06T03:56:05.538Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Q：万金油的-String-不一定好用"><a href="#Q：万金油的-String-不一定好用" class="headerlink" title="Q：万金油的 String 不一定好用"></a>Q：万金油的 String 不一定好用</h1><p>场景：</p><p>开发一个图片存储系统，要求这个系统能快速地记录图片 ID 和图片在存储系统中保存时的 ID（可以直接叫作图片存储对象 ID）。同时，还要能够根据图片 ID 快速查找到图片存储对象 ID。</p><p>用 10 位数来表示图片 ID 和图片存储对象 ID，例如，图片 ID 为 1101000051，它在存储系统中对应的 ID 号是 3301000051。</p><p><strong>初始设计：</strong></p><p>图片 ID 和图片存储对象 ID 正好一一对应，是典型的“键 - 单值”模式。所谓的“单值”，就是指键值对中的值就是一个值，而不是一个集合，这和 String 类型提供的“一个键对应一个值的数据”的保存形式刚好契合。</p><p>刚开始，我们保存了 1 亿张图片，大约用了 6.4GB 的内存。但是，随着图片数据量的不断增加，我们的 Redis 内存使用量也在增加，结果就遇到了大内存 Redis 实例因为生成 RDB 而响应变慢的问题。很显然，String 类型并不是一种好的选择，我们还需要进一步寻找能节省内存开销的数据类型方案。</p><h2 id="内存使用量大的原因"><a href="#内存使用量大的原因" class="headerlink" title="内存使用量大的原因"></a>内存使用量大的原因</h2><p>String 类型并不是适用于所有场合的，它有一个明显的短板，就是它保存数据时所消耗的内存空间较多。</p><p>其实，除了记录实际数据，String 类型还需要额外的内存空间记录数据长度、空间使用等信息，这些信息也叫作元数据。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-0f63d2438a538cc91cd4fdc033c87f9dff484657.jpg" alt="img" style="zoom:15%;" /><p>反正就是除了本身的应存的数据之外，还保留很多其他的元数据，所以占用内存较大。</p><h2 id="如何优化"><a href="#如何优化" class="headerlink" title="如何优化"></a>如何优化</h2><p>在保存单值的键值对时，可以采用基于 Hash 类型的二级编码方法。这里说的二级编码，就是把一个单值的数据拆分成两部分，前一部分作为 Hash 集合的 key，后一部分作为 Hash 集合的 value，这样一来，我们就可以把单值数据保存到 Hash 集合中了。</p><p>以图片 ID 1101000060 和图片存储对象 ID 3302000080 为例，我们可以把图片 ID 的前 7 位（1101000）作为 Hash 类型的键，把图片 ID 的最后 3 位（060）和图片存储对象 ID 分别作为 Hash 类型值中的 key 和 value。</p><p>二级编码一定要把图片 ID 的前 7 位作为 Hash 类型的键，把最后 3 位作为 Hash 类型值中的 key 吗？其实，二级编码方法中采用的 ID 长度是有讲究的。</p><p>Redis Hash 类型的两种底层实现结构，分别是压缩列表和哈希表。那么，Hash 类型底层结构什么时候使用压缩列表，什么时候使用哈希表呢？其实，Hash 类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash 类型就会用哈希表来保存数据了。</p><p>这两个阈值分别对应以下两个配置项：</p><ul><li><p>hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。</p></li><li><p>hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度。</p></li></ul><p>如果我们往 Hash 集合中写入的元素个数超过了 hash-max-ziplist-entries，或者写入的单个元素大小超过了 hash-max-ziplist-value，Redis 就会自动把 Hash 类型的实现结构由压缩列表转为哈希表。一旦从压缩列表转为了哈希表，Hash 类型就会一直用哈希表进行保存，而不会再转回压缩列表了。在节省内存空间方面，哈希表就没有压缩列表那么高效了。</p><p>为了能充分使用压缩列表的精简内存布局，我们一般要控制保存在 Hash 集合中的元素个数。所以，在刚才的二级编码中，我们只用图片 ID 最后 3 位作为 Hash 集合的 key，也就保证了 Hash 集合的元素个数不超过 1000，同时，我们把 hash-max-ziplist-entries 设置为 1000，这样一来，Hash 集合就可以一直使用压缩列表来节省内存空间了。</p><h2 id="个人总结"><a href="#个人总结" class="headerlink" title="个人总结"></a>个人总结</h2><p>这篇就是说了 String 在大量的键值对方面内存容量上有点拉胯，可以抽取出这些 key 的共性，再搞一个集合类型作为 value。当然如果 key 各个都不太一样就不太好搞了。</p><p>另外，教你了怎么采用压缩列表能够更大程度的节省空间。然后这个何时采用压缩列表何时采用其他的数据结构，配置项可配的。</p><p>另外，压缩列表是一块连续内存，对 CPU cache 也友好，CPU 命中率也不错，所以读取速度也非常快。</p><h1 id="Q：有一亿个keys要统计，应该用哪种集合"><a href="#Q：有一亿个keys要统计，应该用哪种集合" class="headerlink" title="Q：有一亿个keys要统计，应该用哪种集合"></a>Q：有一亿个keys要统计，应该用哪种集合</h1><ul><li>在移动应用中，需要统计每天的新增用户数和第二天的留存用户数；</li><li>在电商网站的商品评论中，需要统计评论列表中的最新评论；</li><li>在签到打卡中，需要统计一个月内连续打卡的用户数；</li><li>在网页访问记录中，需要统计独立访客（Unique Visitor，UV）量。</li></ul><h2 id="聚合统计"><a href="#聚合统计" class="headerlink" title="聚合统计"></a>聚合统计</h2><blockquote><p>统计手机 App 每天的新增用户数和第二天的留存用户数</p></blockquote><p>所谓的聚合统计，就是指统计多个集合元素的聚合结果，包括：统计多个集合的共有元素（交集统计）；把两个集合相比，统计其中一个集合独有的元素（差集统计）；统计多个集合的所有元素（并集统计）。</p><p>我们还需要把每一天登录的用户 ID，记录到一个新集合中，我们把这个集合叫作每日用户 Set，它有两个特点：key 是 user:id 以及当天日期，例如 <code>user:id:20200803</code>；value 是 Set 集合，记录当天登录的用户 ID。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-7cbaddb64afe43cc42fe5b2c2519a13dfe2ad8b3.jpg" alt="img" style="zoom:15%;" /><p>当要计算 8 月 4 日的留存用户时，我们只需要再计算 <code>user:id:20200803</code> 和 <code>user:id:20200804</code> 两个 Set 的交集，就可以得到同时在这两个集合中的用户 ID 了，这些就是在 8 月 3 日登录，并且在 8 月 4 日留存的用户。</p><p>执行的命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SINTERSTORE user:id:rem user:id:20200803 user:id:20200804</span><br></pre></td></tr></table></figure><p>Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞。所以，分享一个小建议：<strong>你可以从主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计</strong>，这样就可以规避阻塞主库实例和其他从库实例的风险了。</p><h2 id="排序统计"><a href="#排序统计" class="headerlink" title="排序统计"></a>排序统计</h2><blockquote><p>电商网站上提供最新评论列表</p></blockquote><p>List 是按照元素进入 List 的顺序进行排序的，而 Sorted Set 可以根据元素的权重来排序，我们可以自己来决定每个元素的权重值。比如说，我们可以根据元素插入 Sorted Set 的时间确定权重值，先插入的元素权重小，后插入的元素权重大。</p><p>这样会出现翻页过程中，新插入元素，导致第二页出现重复数据的情况（其实这种情况因被允许，我看很多网站其实都是存在该现象）</p><p><strong>如果不想出现这样的情况，就用 Sorted Set，因为他的取的权重还是老的，所以不会出现新的元素。除非你又获取了新的元素，拿到的新的权重，不然就是老的权重。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZRANGEBYSCORE comments N-9 N</span><br></pre></td></tr></table></figure><h2 id="二值状态统计"><a href="#二值状态统计" class="headerlink" title="二值状态统计"></a>二值状态统计</h2><blockquote><p>签到打卡的场景</p></blockquote><p>Bitmap 提供了 GETBIT&#x2F;SETBIT 操作，使用一个偏移值 offset 对 bit 数组的某一个 bit 位进行读和写。不过，需要注意的是，Bitmap 的偏移量是从 0 开始算的，也就是说 offset 的最小值是 0。当使用 SETBIT 对一个 bit 位进行写操作时，这个 bit 位会被设置为 1。Bitmap 还提供了 BITCOUNT 操作，用来统计这个 bit 数组中所有“1”的个数。</p><p>那么，具体该怎么用 Bitmap 进行签到统计呢？</p><p>借助一个具体的例子来说明。假设我们要统计 ID 3000 的用户在 2020 年 8 月份的签到情况，就可以按照下面的步骤进行操作。</p><p>第一步，执行下面的命令，记录该用户 8 月 3 号已签到。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SETBIT uid:sign:3000:202008 2 1</span><br></pre></td></tr></table></figure><p>第二步，检查该用户 8 月 3 日是否签到。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GETBIT uid:sign:3000:202008 3</span><br></pre></td></tr></table></figure><p>第三步，统计该用户在 8 月份的签到次数。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BITCOUNT uid:sign:3000:202008</span><br></pre></td></tr></table></figure><p>所以，如果只需要统计数据的二值状态，例如商品有没有、用户在不在等，就可以使用 Bitmap，因为它只用一个 bit 位就能表示 0 或 1。在记录海量数据时，Bitmap 能够有效地节省内存空间。</p><h2 id="基数统计"><a href="#基数统计" class="headerlink" title="基数统计"></a>基数统计</h2><blockquote><p>统计网页的 UV</p></blockquote><p>网页 UV 的统计有个独特的地方，就是需要去重，一个用户一天内的多次访问只能算作一次。在 Redis 的集合类型中，Set 类型默认支持去重，所以看到有去重需求时，我们可能第一时间就会想到用 Set 类型。</p><p>我们来结合一个例子看一看用 Set 的情况。有一个用户 user1 访问 page1 时，你把这个信息加到 Set 中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SADD page1:uv user1</span><br></pre></td></tr></table></figure><p>但是，如果 page1 非常火爆，UV 达到了千万，这个时候，一个 Set 就要记录千万个用户 ID。对于一个搞大促的电商网站而言，这样的页面可能有成千上万个，如果每个页面都用这样的一个 Set，就会消耗很大的内存空间。</p><p>这时候，就要用到 Redis 提供的 HyperLogLog 了。HyperLogLog 是一种用于统计基数的数据集合类型，它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。</p><p>在统计 UV 时，你可以用 PFADD 命令（用于向 HyperLogLog 中添加新元素）把访问页面的每个用户都添加到 HyperLogLog 中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PFADD page1:uv user1 user2 user3 user4 user5</span><br></pre></td></tr></table></figure><p>接下来，就可以用 PFCOUNT 命令直接获得 page1 的 UV 值了，这个命令的作用就是返回 HyperLogLog 的统计结果。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PFCOUNT page1:uv</span><br></pre></td></tr></table></figure><p>**HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%**。这也就意味着，你使用 HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-7d9ae33f5295299379b8c4e81a9585cc3578a6e3.jpg" alt="img" style="zoom:15%;" /><h1 id="Q：GEO-是怎么搞定位置信息服务的"><a href="#Q：GEO-是怎么搞定位置信息服务的" class="headerlink" title="Q：GEO 是怎么搞定位置信息服务的"></a>Q：GEO 是怎么搞定位置信息服务的</h1><p>实际上，GEO 类型的底层数据结构就是用 Sorted Set 来实现的。</p><p>为了能高效地对经纬度进行比较，Redis 采用了业界广泛使用的 GeoHash 编码方法，这个方法的基本原理就是“二分区间，区间编码”。</p><p>就是每次划分成两个区间，左 0 右 1。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-087bd587b868ff5cdac6653f2641c76ea1d0284a.jpg" alt="img" style="zoom:15%;" /><p>对纬度的编码方式，和对经度的一样，只是纬度的范围是[-90，90]，下面这张表显示了对纬度值 39.86 的编码过程。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-c3949ea4fcbebaa9be76a403eab0dca873bed72f.jpg" alt="img" style="zoom:15%;" /><p>对进度和维度进行 N 次的二分法。</p><p>我们刚刚计算的经纬度（116.37，39.86）的各自编码值是 11010 和 10111，组合之后，第 0 位是经度的第 0 位 1，第 1 位是纬度的第 0 位 1，第 2 位是经度的第 1 位 1，第 3 位是纬度的第 1 位 0，以此类推，就能得到最终编码值 1110011101，如下图所示：</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-797b10532d5aea64340fc6512912f6caaec0826e.jpg" alt="img" style="zoom:15%;" /><p>地理空间被划分成了一个个方格</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-d69993567d8f774b9d38c9983b0710399e07d2f1.jpg" alt="img" style="zoom:15%;" /><p>不同位的做 GEOHASH 编码，可以得到精度不同的方格。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-ebc4cadde7c394f18ffe17cd251725a9d30435e3.jpg" alt="img" style="zoom:15%;" /><h2 id="如何操作-GEO-类型？"><a href="#如何操作-GEO-类型？" class="headerlink" title="如何操作 GEO 类型？"></a>如何操作 GEO 类型？</h2><p>在使用 GEO 类型时，我们经常会用到两个命令，分别是 GEOADD 和 GEORADIUS。</p><p>GEOADD 命令：用于把一组经纬度信息和相对应的一个 ID 记录到 GEO 类型集合中；</p><p>GEORADIUS 命令：会根据输入的经纬度位置，查找以这个经纬度为中心的一定范围内的其他元素。</p><p>以叫车应用的车辆匹配场景为例，假设车辆 ID 是 33，经纬度位置是（116.034579，39.030452），我们可以用一个 GEO 集合保存所有车辆的经纬度，集合 key 是 cars:locations。执行下面的这个命令，就可以把 ID 号为 33 的车辆的当前经纬度位置存入 GEO 集合中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GEOADD cars:locations 116.034579 39.030452 33</span><br></pre></td></tr></table></figure><p>LBS 应用执行下面的命令时，Redis 会根据输入的用户的经纬度信息（116.054579，39.030452 ），查找以这个经纬度为中心的 5 公里内的车辆信息，并返回给 LBS 应用。当然， 你可以修改“5”这个参数，来返回更大或更小范围内的车辆信息。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="中间件" scheme="https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Redis" scheme="https://matthew-han.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis 笔记二</title>
    <link href="https://matthew-han.github.io/post/d9851020-dfd0-11eb-9b07-0d08f44604fc/"/>
    <id>https://matthew-han.github.io/post/d9851020-dfd0-11eb-9b07-0d08f44604fc/</id>
    <published>2021-07-08T09:42:46.000Z</published>
    <updated>2025-09-06T01:44:39.800Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Q：什么是主从模式"><a href="#Q：什么是主从模式" class="headerlink" title="Q：什么是主从模式"></a>Q：什么是主从模式</h1><p>那我们总说的 Redis 具有高可靠性，又是什么意思呢？</p><p>其实，这里有两层含义：一是数据尽量少丢失，二是服务尽量少中断。AOF 和 RDB 保证了前者，而对于后者，Redis 的做法就是增加副本冗余量，将一份数据同时保存在多个实例上。即使有一个实例出现了故障，需要过一段时间才能恢复，其他实例也可以对外提供服务，不会影响业务使用。</p><p>实际上，Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。</p><ul><li>读操作：主库、从库都可以接收；</li><li>写操作：首先到主库执行，然后，主库将写操作同步给从库。</li></ul><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-f6b36750619c4a34b531c6beeb5f6107b8705ed7.jpg" alt="img" style="zoom:15%;" /><h1 id="Q：主从之间什么时候进行第一次同步"><a href="#Q：主从之间什么时候进行第一次同步" class="headerlink" title="Q：主从之间什么时候进行第一次同步"></a>Q：主从之间什么时候进行第一次同步</h1><p>当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。</p><p>例如，现在有实例 1（ip：172.16.19.3）和实例 2（ip：172.16.19.5），我们在实例 2 上执行以下这个命令后，实例 2 就变成了实例 1 的从库，并从实例 1 上复制数据：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">replicaof 172.16.19.3 6379</span><br></pre></td></tr></table></figure><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-5f7f97d340f941db18d36b83b7d761a4b14d0cd3.jpg" alt="img" style="zoom:15%;" /><p>简单来说就是以下流程：</p><ol start="0"><li><p>第一阶段，主从库间建立连接、协商同步的过程，主要是为全量复制做准备</p></li><li><p>第二阶段，主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件。</p></li><li><p>第三阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。</p></li></ol><p>也就是说从库全量复制完了之后，之后都是增量同步。查考下文的<code>repl_backlog_buffer</code>。</p><h1 id="Q：主从级联模式分担全量复制时的主库压力"><a href="#Q：主从级联模式分担全量复制时的主库压力" class="headerlink" title="Q：主从级联模式分担全量复制时的主库压力"></a>Q：主从级联模式分担全量复制时的主库压力</h1><p>一主多从的模式下，所有的从库都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。</p><p>那么，有没有好的解决方法可以分担主库压力呢？</p><p>主 - 从 - 从模式。这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">replicaof 所选从库的IP 6379</span><br></pre></td></tr></table></figure><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-3d64bc4ebc575fbf4625e7416cbe700d95c5126d.jpg" alt="img" style="zoom:15%;" /><h1 id="Q：主从库间网络断了怎么办？"><a href="#Q：主从库间网络断了怎么办？" class="headerlink" title="Q：主从库间网络断了怎么办？"></a>Q：主从库间网络断了怎么办？</h1><p>采用增量模式同步</p><p>当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。</p><p>repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-b527fa3a57208c9d98e80b5e47c155deed6034c2.jpg" alt="img" style="zoom:15%;" /><p>不过，有一个地方我要强调一下，因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-cfb066dafe6cd4a1a9abb9ab740b9012f643a5fc.jpg" alt="img" style="zoom:15%;" /><p>所以恢复的过程精髓在于 repl_backlog_buffer，对于该值不能太小，导致圆环被覆写。</p><h1 id="Q：哨兵机制的基本流程"><a href="#Q：哨兵机制的基本流程" class="headerlink" title="Q：哨兵机制的基本流程"></a>Q：哨兵机制的基本流程</h1><p>哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-9431ebeb5f750462fa55476508d7f58970e47d3d.jpg" alt="img" style="zoom:15%;" /><p>在监控和选主这两个任务中，哨兵需要做出两个决策：</p><ul><li>在监控任务中，哨兵需要判断主库是否处于下线状态；</li><li>在选主任务中，哨兵也要决定选择哪个从库实例作为主库。</li></ul><h2 id="主观下线与客观下线"><a href="#主观下线与客观下线" class="headerlink" title="主观下线与客观下线"></a>主观下线与客观下线</h2><p>哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”。</p><p>哨兵机制通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。</p><p>在判断主库是否下线时，不能由一个哨兵说了算，只有大多数的哨兵实例，都判断主库已经“主观下线”了，主库才会被标记为“客观下线”</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-450fda1ef8def065305ce5b0399898df76d8f29b.jpg" alt="img" style="zoom:15%;" /><p>简单来说，“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N&#x2F;2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。</p><p>所以最好采用奇数个（大于等于 3）个哨兵节点。</p><h2 id="如何筛选-打分？"><a href="#如何筛选-打分？" class="headerlink" title="如何筛选 + 打分？"></a>如何筛选 + 打分？</h2><ol><li>选择优先级最高的<ol><li>用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。比如，你有两个从库，它们的内存大小不一样，你可以手动给内存大的实例设置一个高优先级。在选主时，哨兵会给优先级高的从库打高分，如果有一个从库优先级最高，那么它就是新主库了。如果从库的优先级都一样，那么哨兵开始第二轮打分。</li></ol></li><li>和旧主库同步程度最接近的从库得分高。<ol><li>repl_backlog_buffer 中的位置，而从库会用 slave_repl_offset 这个值记录当前的复制进度。就像下图所示，旧主库的 master_repl_offset 是 1000，从库 1、2 和 3 的 slave_repl_offset 分别是 950、990 和 900，那么，从库 2 就应该被选为新主库。</li><li>如右图：<img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-3add115cf107998d46fe4d2557eb413c187a868a.jpg" alt="img" style="zoom:15%;" /></li></ol></li><li>ID 号小的从库得分高。<ol><li>在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库。</li><li>也就是保证一定能选出一个从库来当新主库</li></ol></li></ol><h1 id="Q：哨兵之间的选举"><a href="#Q：哨兵之间的选举" class="headerlink" title="Q：哨兵之间的选举"></a>Q：哨兵之间的选举</h1><h2 id="基于-pub-sub-机制的哨兵集群组成"><a href="#基于-pub-sub-机制的哨兵集群组成" class="headerlink" title="基于 pub&#x2F;sub 机制的哨兵集群组成"></a>基于 pub&#x2F;sub 机制的哨兵集群组成</h2><p>哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub&#x2F;sub 机制，也就是发布 &#x2F; 订阅机制。</p><p>只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换。</p><p>在主从集群中，主库上有一个名为 <code>__sentinel__:hello</code> 的频道，不同哨兵就是通过它来相互发现，实现互相通信的。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-1445b2836e76b28630155c904f2719081b472358.jpg" alt="img" style="zoom:15%;" /><p>这样哨兵节点之间就完成了彼此的通信建立。</p><h2 id="基于-pub-sub-机制的哨兵集群与主从库连接"><a href="#基于-pub-sub-机制的哨兵集群与主从库连接" class="headerlink" title="基于 pub&#x2F;sub 机制的哨兵集群与主从库连接"></a>基于 pub&#x2F;sub 机制的哨兵集群与主从库连接</h2><p>这是由哨兵向主库发送 INFO 命令来完成的。就像下图所示，哨兵 2 给主库发送 INFO 命令，主库接受到这个命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列表中的连接信息，和每个从库建立连接，并在这个连接上持续地对从库进行监控。哨兵 1 和 3 可以通过相同的方法和从库建立连接。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-c56175b0ddb16be4a21802fbf1ad6d57e23b66ae.jpg" alt="img" style="zoom:15%;" /><h2 id="基于-pub-sub-机制的客户端事件通知"><a href="#基于-pub-sub-机制的客户端事件通知" class="headerlink" title="基于 pub&#x2F;sub 机制的客户端事件通知"></a>基于 pub&#x2F;sub 机制的客户端事件通知</h2><p>哨兵就是一个运行在特定模式下的 Redis 实例，只不过它并不服务请求操作，只是完成监控、选主和通知的任务。所以，每个哨兵实例也提供 pub&#x2F;sub 机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。</p><p>有了 pub&#x2F;sub 机制，哨兵和哨兵之间、哨兵和从库之间、哨兵和客户端之间就都能建立起连接了。</p><h2 id="由哪个哨兵执行主从切换？"><a href="#由哪个哨兵执行主从切换？" class="headerlink" title="由哪个哨兵执行主从切换？"></a>由哪个哨兵执行主从切换？</h2><p>切换新主库需要选出一个 leader 来进行操作。</p><p>具体步骤（个人总结）：</p><ol><li>先判断主观下线，发送主观下线的命令，等待其他哨兵节点回应。</li><li>收到其他哨兵节点的回应，当主观下线的票数大于 N &#x2F; 2 + 1 时，标记主库是客观下线的事实，此时，这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。</li><li>发送这个命令时会先投自己一票，并且只能投一次赞成票，后面接收到这个选 leader 的命令都是否决票</li><li>在投票过程中，任何一个想成为 Leader 的哨兵，要满足两个条件：第一，拿到半数以上的赞成票；第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。</li></ol><p>投票选 leader 中的细节：</p><p>其他哨兵收到投票请求后，由于自己还没有询问进入判定“客观下线”的流程，所以该哨兵是可以直接投票给“先做事”的哨兵，不会投 leader 票给自己。</p><p>存在的问题（我在群里的提问）：</p><blockquote><p>我提出的问题：假如哨兵集群主库挂了，所有哨兵实例在同一时刻判断主观下线，然后同时接收到其他哨兵的消息，都到了客观下线的这一步，然后同时给自己投上一票 leader 票，是不是就没法选出 leader 了。。这种小概率会发生吗？</p></blockquote><p>收到群友们的热心解答：</p><div><img float:left src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/image-20210708161819035.png" alt="image-20210708161819035" style="zoom:25%;" /><img float:left src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/image-20210708162028283.png" alt="image-20210708162028283" style="zoom:25%;" /><img float:left src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/image-20210708162146118.png" alt="image-20210708162146118" style="zoom:25%;" /></div><ul><li><p>Q：假设有一个 Redis 集群，是“一主四从”，同时配置了包含 5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例都发生故障了，此时，Redis 主库如果有故障，还能正确地判断主库“客观下线”吗？如果可以的话，还能进行主从库自动切换吗？</p></li><li><p>A：这种情况，无论投票是怎么样，都没选出 leader 进行主从切换，因为哨兵实例数太少了，不满足大于等于 3。</p></li></ul><p>最后，一个经验：要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds。在项目中，因为这个值在不同的哨兵实例上配置不一致，导致哨兵集群一直没有对有故障的主库形成共识，也就没有及时切换主库，最终的结果就是集群服务不稳定。</p><h1 id="Q：切片集群（Redis-官网集群模式）"><a href="#Q：切片集群（Redis-官网集群模式）" class="headerlink" title="Q：切片集群（Redis 官网集群模式）"></a>Q：切片集群（Redis 官网集群模式）</h1><h2 id="Redis-如何保存更多数据？"><a href="#Redis-如何保存更多数据？" class="headerlink" title="Redis 如何保存更多数据？"></a>Redis 如何保存更多数据？</h2><ul><li>纵向扩展：升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 CPU。就像下图中，原来的实例内存是 8GB，硬盘是 50GB，纵向扩展后，内存增加到 24GB，磁盘增加到 150GB。</li><li>横向扩展：横向增加当前 Redis 实例的个数，就像下图中，原来使用 1 个 8GB 内存、50GB 磁盘的实例，现在使用三个相同配置的实例。</li></ul><h2 id="数据切片和实例的对应分布关系"><a href="#数据切片和实例的对应分布关系" class="headerlink" title="数据切片和实例的对应分布关系"></a>数据切片和实例的对应分布关系</h2><p>具体来说，Redis Cluster 方案采用哈希槽（Hash Slot，接下来我会直接称之为 Slot），来处理数据和实例之间的映射关系。在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。</p><p>具体的映射过程分为两大步：首先根据键值对的 key，按照CRC16 算法计算一个 16 bit 的值；然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。</p><p>手动指定每个实例上的哈希槽数量：使用 cluster meet 命令手动建立实例间的连接，形成集群，再使用 cluster addslots 命令，指定每个实例上的哈希槽个数。</p><p><strong>在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。</strong></p><h2 id="客户端如何定位数据？"><a href="#客户端如何定位数据？" class="headerlink" title="客户端如何定位数据？"></a>客户端如何定位数据？</h2><p>Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。</p><p>客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。</p><p>在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：</p><ul><li>在集群中，实例有新增或删除，Redis 需要重新分配哈希槽；</li><li>为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。</li></ul><blockquote><p>说白了就是，客户端先存一个默认值（默认该值在某个实例上），但是哈希槽会移动，所以请求的结果不一定会直接得到数据，需要对返回的结果进行二次请求。</p></blockquote><p>Redis Cluster 方案提供了一种重定向机制，所谓的“重定向”，就是指，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令。</p><h3 id="MOVED命令"><a href="#MOVED命令" class="headerlink" title="MOVED命令"></a>MOVED命令</h3><p>实例给客户端返回下面的 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET hello:key</span><br><span class="line">(error) MOVED 13320 172.16.19.5:6379</span><br></pre></td></tr></table></figure><p>其中，MOVED 命令表示，客户端请求的键值对所在的哈希槽 13320，实际是在 172.16.19.5 这个实例上。通过返回的 MOVED 命令，就相当于把哈希槽所在的新实例的信息告诉给客户端了。这样一来，客户端就可以直接和 172.16.19.5 连接，并发送操作请求了。</p><p><strong>会改变本地缓存，下次会直接请求正确的实例，如果哈希槽没变的话。</strong></p><h3 id="ASK-命令"><a href="#ASK-命令" class="headerlink" title="ASK 命令"></a>ASK 命令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET hello:key</span><br><span class="line">(error) ASK 13320 172.16.19.5:6379</span><br></pre></td></tr></table></figure><p>这个结果中的 ASK 命令就表示，客户端请求的键值对所在的哈希槽 13320，在 172.16.19.5 这个实例上，但是这个哈希槽正在迁移。此时，客户端需要先给 172.16.19.5 这个实例发送一个 ASKING 命令。这个命令的意思是，让这个实例允许执行客户端接下来发送的命令。然后，客户端再向这个实例发送 GET 命令，以读取数据。</p><p>不同点：</p><p>客户端ASK重定向命令和 MOVED 命令不同，ASK 命令并不会更新客户端缓存的哈希槽分配信息。所以，在上图中，如果客户端再次请求 Slot 2 中的数据，它还是会给实例 2 发送请求。这也就是说，<strong>ASK 命令的作用只是让客户端能给新实例发送一次请求，而不像 MOVED 命令那样，会更改本地缓存，让后续所有命令都发往新实例</strong>。</p><h2 id="Redis-Cluster-不采用把-key-直接映射到实例的方式，而采用哈希槽的方式原因"><a href="#Redis-Cluster-不采用把-key-直接映射到实例的方式，而采用哈希槽的方式原因" class="headerlink" title="Redis Cluster 不采用把 key 直接映射到实例的方式，而采用哈希槽的方式原因"></a>Redis Cluster 不采用把 key 直接映射到实例的方式，而采用哈希槽的方式原因</h2><blockquote><p>摘自评论区 @Kaito</p></blockquote><ol start="0"><li>整个集群存储key的数量是无法预估的，key的数量非常多时，直接记录每个key对应的实例映射关系，这个映射表会非常庞大，这个映射表无论是存储在服务端还是客户端都占用了非常大的内存空间。</li><li>Redis Cluster采用无中心化的模式（无proxy，客户端与服务端直连），客户端在某个节点访问一个key，如果这个key不在这个节点上，这个节点需要有纠正客户端路由到正确节点的能力（MOVED响应），这就需要节点之间互相交换路由表，每个节点拥有整个集群完整的路由关系。如果存储的都是key与实例的对应关系，节点之间交换信息也会变得非常庞大，消耗过多的网络资源，而且就算交换完成，相当于每个节点都需要额外存储其他节点的路由表，内存占用过大造成资源浪费。</li><li>当集群在扩容、缩容、数据均衡时，节点之间会发生数据迁移，迁移时需要修改每个key的映射关系，维护成本高。</li><li>而在中间增加一层哈希槽，可以把数据和节点解耦，key通过Hash计算，只需要关心映射到了哪个哈希槽，然后再通过哈希槽和节点的映射表找到节点，相当于消耗了很少的CPU资源，不但让数据分布更均匀，还可以让这个映射表变得很小，利于客户端和服务端保存，节点之间交换信息时也变得轻量。</li><li>当集群在扩容、缩容、数据均衡时，节点之间的操作例如数据迁移，都以哈希槽为基本单位进行操作，简化了节点扩容、缩容的难度，便于集群的维护和管理。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="中间件" scheme="https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Redis" scheme="https://matthew-han.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis 笔记一</title>
    <link href="https://matthew-han.github.io/post/8b513a00-dfd0-11eb-b078-eb0d993c7e2d/"/>
    <id>https://matthew-han.github.io/post/8b513a00-dfd0-11eb-b078-eb0d993c7e2d/</id>
    <published>2021-07-08T09:40:34.000Z</published>
    <updated>2025-09-06T01:45:22.813Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Q：Redis-变慢的原因一"><a href="#Q：Redis-变慢的原因一" class="headerlink" title="Q：Redis 变慢的原因一"></a>Q：Redis 变慢的原因一</h1><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-4cf5fc6e06152e409de6fa33b92b4445745aa77e.jpg" alt="img" style="zoom: 25%;" /><blockquote><p>类似 Java GC  S0&#x2F;S1 的复制算法</p></blockquote><p>这里存在一个问题，哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。对于追求“快”的 Redis 来说，这是不太能接受的。</p><p>所以，Redis 会对哈希表做 rehash 操作。rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。那具体怎么做呢？</p><p>其实，为了使 rehash 操作更高效，Redis 默认使用了两个全局哈希表：哈希表 1 和哈希表 2。一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步：</p><p>给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；</p><p>把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；</p><p>释放哈希表 1 的空间。</p><p>到此，我们就可以从哈希表 1 切换到哈希表 2，用增大的哈希表 2 保存更多数据，而原来的哈希表 1 留作下一次 rehash 扩容备用。</p><h1 id="Q：渐进式-rehash-拷贝"><a href="#Q：渐进式-rehash-拷贝" class="headerlink" title="Q：渐进式 rehash 拷贝"></a>Q：渐进式 rehash 拷贝</h1><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-d050b609a1772189306e6bd2d584dab60549b591.jpg" alt="img" style="zoom: 25%;" /><p>简单来说就是在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。</p><p>因为在进行渐进式 rehash 的过程中， 字典会同时使用 ht[0] 和 ht[1] 两个哈希表， 所以在渐进式 rehash 进行期间， 字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行： 比如说， 要在字典里面查找一个键的话， 程序会先在 ht[0] 里面进行查找， 如果没找到的话， 就会继续到 ht[1] 里面进行查找， 诸如此类。</p><p>另外， 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 ht[1] 里面， 而 ht[0] 则不再进行任何添加操作： 这一措施保证了 ht[0] 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。</p><p><strong>Redis 会执行定时任务，定时任务中就包含了 rehash 操作。所谓的定时任务，就是按照一定频率（例如每 100ms&#x2F; 次）执行的任务。</strong></p><h1 id="Q：Redis-的几种数据结构"><a href="#Q：Redis-的几种数据结构" class="headerlink" title="Q：Redis 的几种数据结构"></a>Q：Redis 的几种数据结构</h1><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/image-20210706164818950.png" alt="image-20210706164818950" style="zoom:25%;" /><p>大类型下对应多种实现转换规则是基于一个key的数据大小和元素个数，配置文件中可配。</p><h1 id="Q：为什么说-Redis-单线程这么快"><a href="#Q：为什么说-Redis-单线程这么快" class="headerlink" title="Q：为什么说 Redis 单线程这么快"></a>Q：为什么说 Redis 单线程这么快</h1><p>我们通常说，Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。</p><p>多线程的坏处：</p><ol start="0"><li><p>为了保证共享资源的正确性，就需要有额外的机制进行保证，而这个额外的机制，就会带来额外的开销。</p></li><li><p>并发访问控制也是难点，降低系统代码的易调试性和可维护性</p></li></ol><p>单线程快的原因：</p><ol start="0"><li>高效的数据结构（哈希表、跳表）</li><li>多路复用机制</li></ol><h2 id="什么是多路复用机制？"><a href="#什么是多路复用机制？" class="headerlink" title="什么是多路复用机制？"></a>什么是多路复用机制？</h2><p>基本 IO 模型与阻塞点：以 Get 请求为例，为了处理一个 Get 请求，需要监听客户端请求（bind&#x2F;listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结果，即向 socket 中写回数据（send）。</p><p>但是，在这里的网络 IO 操作中，有潜在的阻塞点，分别是 accept() 和 recv()。当 Redis 监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept() 函数这里，导致其他客户端无法和 Redis 建立连接。类似的，当 Redis 通过 recv() 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。</p><p>这就导致 Redis 整个线程阻塞，无法处理其他客户端请求，效率很低。不过，幸运的是，socket 网络模型本身支持<strong>非阻塞模式</strong>。</p><p>针对监听套接字，我们可以设置非阻塞模式：当 Redis 调用 accept() 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待。但是，你要注意的是，调用 accept() 时，已经存在监听套接字了。</p><p>Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select&#x2F;epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</p><p>也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。</p><p>现在，我们知道了，Redis 单线程是指它对网络 IO 和数据读写的操作采用了一个线程，而采用单线程的一个核心原因是避免多线程开发的并发控制问题。单线程的 Redis 也能获得高性能，跟多路复用的 IO 模型密切相关，因为这避免了 accept() 和 send()&#x2F;recv() 潜在的网络 IO 操作阻塞点。</p><h1 id="Q：AOF"><a href="#Q：AOF" class="headerlink" title="Q：AOF"></a>Q：AOF</h1><p>AOF 写日志是主线程发起，在命令执行后才记录日志，所以不会阻塞当前的写操作。</p><p>其次，AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。</p><h2 id="三种写回策略"><a href="#三种写回策略" class="headerlink" title="三种写回策略"></a>三种写回策略</h2><p>也就是 AOF 配置项 appendfsync 的三个可选值。</p><ul><li>Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</li><li>Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；</li><li>No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。</li></ul><p>我们一定要小心 AOF 文件过大带来的性能问题。如何解决？利用 AOF 重写机制</p><p>重写机制具有“多变一”功能。所谓的“多变一”，也就是说，旧日志文件中的多条命令，在重写后的新日志中变成了一条命令。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-1054c824c2aab81296cfa052ae13fe89884f9b3f.jpg" alt="img" style="zoom:15%;" /><h2 id="AOF-重写会阻塞吗？"><a href="#AOF-重写会阻塞吗？" class="headerlink" title="AOF 重写会阻塞吗？"></a>AOF 重写会阻塞吗？</h2><p><strong>和 AOF 日志由主线程写回不同</strong>，重写过程是由后台子进程 bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。</p><p>我把重写的过程总结为“一个拷贝，两处日志”。</p><p>“一个拷贝”就是指，每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。此时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。</p><p>“两处日志”又是什么呢？</p><p>因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。</p><p>而第二处日志，就是指新的 AOF 重写日志。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。</p><p><strong>主线程 fork 子线程的一瞬间是会发生阻塞的</strong></p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-474b0b86db4987b658825492e6597c29ad491413.jpg" alt="img" style="zoom:15%;" /><h1 id="Q：RDB（Redis-DataBase）-快照"><a href="#Q：RDB（Redis-DataBase）-快照" class="headerlink" title="Q：RDB（Redis DataBase） 快照"></a>Q：RDB（Redis DataBase） 快照</h1><h2 id="RDB-重写会阻塞吗？如何做快照？"><a href="#RDB-重写会阻塞吗？如何做快照？" class="headerlink" title="RDB 重写会阻塞吗？如何做快照？"></a>RDB 重写会阻塞吗？如何做快照？</h2><p>Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。</p><ul><li>save：在主线程中执行，会导致阻塞；</li><li>bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。</li></ul><p>简单来说，bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。</p><p>bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。此时，如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本（键值对 C’）。然后，主线程在这个数据副本上进行修改。同时，bgsave 子进程可以继续把原来的数据（键值对 C）写入 RDB 文件。</p><img src="https://hexo-espada.oss-cn-hangzhou.aliyuncs.com/Espada/blog_pictures/redis/redis-4b408b5ab30079ee483dc79c763200d352f3ee60.jpg" alt="img" style="zoom:5%;" /><blockquote><p>这里对数据的快照，我觉得很妙。</p><p>当存在在「快照备份的过程」中（T 时刻），如果是读操作无所谓，写操作的话，需要先将该数据复制一份副本，然后主线程在该副本上进行修改，这样子线程存储的数据则是「老」的数据，这样的话，在「快照备份的过程中」能保证快照的数据都是 T 时刻的数据了，无论该过程结束的时间是 T + N 秒。</p></blockquote><h2 id="多久做快照？"><a href="#多久做快照？" class="headerlink" title="多久做快照？"></a>多久做快照？</h2><p>虽然 bgsave 执行时不阻塞主线程，但是，如果频繁地执行全量快照，也会带来两方面的开销。</p><p>一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。</p><p>另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了（所以，在 Redis 中如果有一个 bgsave 在运行，就不会再启动第二个 bgsave 子进程）</p><blockquote><p>原文中「所以，在 Redis 中如果有一个 bgsave 在运行，就不会再启动第二个 bgsave 子进程」指的是 Redis 实际的机制，并不会出现多个 bgsave 子进程来用于快照。</p></blockquote><p>优化</p><p>Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。混</p><p>合使用 RDB 和 AOF，正好可以取两者之长，避两者之短，以较小的性能开销保证数据可靠性和性能。</p><h2 id="关于混合使用个人感想"><a href="#关于混合使用个人感想" class="headerlink" title="关于混合使用个人感想"></a>关于混合使用个人感想</h2><blockquote><p>By Matthew Han</p></blockquote><p>关于 AOF 和 RDB，AOF 有点像一个软件的小版本升级，version 1.1 &#x3D;&#x3D;&gt; version 1.2，可能只有几条数据的更新，此时采用 AOF 进行数据更新比较好，但是到了一个大的版本，比如 version 3.8，此时最好重新下一个最新版本的客户端了，所以对于 Redis 来说利用 RDB 比较好。</p><p>很多人要说了，诶？AOF 不是会重写操作记录实现 All In One 吗？那这样理解的话，无论数据怎么更新、增加、删除， AOF 的操作都应该比 RDB 这种全量的少啊？我看评论区 Kaito 的发言：</p><blockquote><p>RDB 文件内容是经过压缩的二进制数据（不同数据类型数据做了针对性优化），文件很小。</p></blockquote><p>觉得应该是如果一段时间后数据几乎全改了，此时的 AOF 文件一定是比 RDB 大的，恢复速度肯定也比不上 RDB。而且删除操作多的话，RDB 更占优势，AOF 应该会记录删除的操作记录。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="中间件" scheme="https://matthew-han.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Redis" scheme="https://matthew-han.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>大容量数组随机读写的效率问题</title>
    <link href="https://matthew-han.github.io/post/5311af30-da0d-11eb-a7d5-3f834b7c5511/"/>
    <id>https://matthew-han.github.io/post/5311af30-da0d-11eb-a7d5-3f834b7c5511/</id>
    <published>2021-07-01T01:40:32.000Z</published>
    <updated>2025-09-03T02:52:50.978Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>昨天在刷 AcWing 每日一题的第 <a href="https://www.acwing.com/problem/content/description/3735/">3732</a> 题「矩阵复原」时，发现在大容量数组作为缓存时提交无限 TLE，但是该用 HashMap 就 ac 了。</p><p>在我浅薄的知识勺中，一直认为数组的下标作为 key 随机访问其下标的元素数据时是要快于一些集合的，HashMap 有着复杂的数据结构，底层也是数组、链表和红黑树，怎么样都不会比一维数组作为缓存来的快吧，但实际上在该背景下确实是 HashMap 的效率更高。</p><p>来看这段算法的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Main</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Scanner</span> <span class="variable">sc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scanner</span>(System.in);</span><br><span class="line">        <span class="type">int</span> <span class="variable">k</span> <span class="operator">=</span> sc.nextInt();</span><br><span class="line">        <span class="keyword">while</span> (k-- &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> sc.nextInt();</span><br><span class="line">            <span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> sc.nextInt();</span><br><span class="line">            <span class="type">int</span>[][] mat1 = <span class="keyword">new</span> <span class="title class_">int</span>[n][m];</span><br><span class="line">            <span class="type">int</span>[][] mat2 = <span class="keyword">new</span> <span class="title class_">int</span>[m][n];</span><br><span class="line">            <span class="comment">// int[] cache = new int[250001];</span></span><br><span class="line">            Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">            <span class="type">int</span>[][] res = <span class="keyword">new</span> <span class="title class_">int</span>[n][m];</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>; j &lt; m; j++) &#123;</span><br><span class="line">                    mat1[i][j] = sc.nextInt();</span><br><span class="line">                    <span class="comment">// cache[mat1[i][j]] = j;</span></span><br><span class="line">                    map.put(mat1[i][j], j);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; m; i++) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>; j &lt; n; j++) &#123;</span><br><span class="line">                    mat2[i][j] = sc.nextInt();</span><br><span class="line">                    <span class="comment">// res[j][cache[mat2[i][j]]] = mat2[i][j];</span></span><br><span class="line">                    res[j][map.get(mat2[i][j])] = mat2[i][j];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="type">StringBuilder</span> <span class="variable">sb</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringBuilder</span>();</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">                sb.setLength(<span class="number">0</span>);</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>; j &lt; m; j++) &#123;</span><br><span class="line">                    sb.append(res[i][j]).append(<span class="string">&quot; &quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line">                System.out.println(sb.toString());</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>注释的地方是原先 TLE 的代码</strong>，只通过了大概 9 个 case（一共 11 个）。为什么会出现这样的情况呢？查阅了网上少量的资料和群友的解释大概是 CPU 高速缓存的命中问题，初始化需要分配的连续内存太大，造成CPU高速缓存整个缓存行失效，大大的降低了高速缓存的命中性。</p><p>可惜大学学的东西早忘完了，寻址算法都记不清了。这次正好也让我学习了在算法题中对于大数组的使用要谨慎，并非使用数组利用下标读写就是效率最高的。</p><h2 id="2021-7-2-更新"><a href="#2021-7-2-更新" class="headerlink" title="2021.7.2 更新"></a>2021.7.2 更新</h2><p>以上那段代码，我尝试在 HashMap 的初始化设定一个容量，就像这样：<code>Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(250000 * 4 / 3 + 1);</code> 发现这样果然超时了，感觉 TLE 的原因就在于初始化分配的大小。在数据量较小的 case 上，「一直扩容」是会比初始化过大的容量（250000）快的， TLE 应该是在一些数据量较小的 case 上。</p><p><code>Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(n * m * 4 / 3 + 1)</code> 这样写性能是最强的，用时最少。所以效率排名是这样的：</p><ol start="0"><li><code>Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(n * m * 4 / 3 + 1)</code> </li><li><code>Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;()</code> </li><li><code>int[] cache = new int[n * m + 1];</code></li><li><code>int[] cache = new int[250001];</code></li></ol><p>HashMap 居然比数组随机读写的速度还要快，泪目，HashMap 永远滴神！</p><h2 id="2021-7-6-更新"><a href="#2021-7-6-更新" class="headerlink" title="2021.7.6 更新"></a>2021.7.6 更新</h2><p>在复习《Redis核心技术与实战》这门课的时候，评论区的同学都非常厉害，老师抛出了一个问题：</p><blockquote><p>如果在数组上是随机访问，对CPU高速缓存还友好不？</p></blockquote><p>虽然是关于 Redis 的数据结构，但是其实本质和我们这道算法题碰到的问题类似，其中一个同学的解答非常好，我就直接在抄过来了</p><blockquote><p>@irats:</p><p>数组通过下标访问数据虽然是O(1)，但是由于cpu读取数据从高速缓存读，而高速缓存的容量很小。</p><p>比如cpu要读取nums[0]，cpu发现高速缓存没有nums[0]，就会从内存把num[0]以及nums[0]附近的数据(比如还拖取了nums[1])都拖取到高速缓存中。如果接下来cpu要读取nums[1]，由于nums[1]已经在告诉缓存中，那么cpu能马上拿到数据。但如果cpu想要读取nums[100]，显然高速缓存中没有这个数据，然后就又要到内存中把nums[100]和他附近的数据拖到高速缓存。假设高速缓存只能存两个数字。那么因为读取nums[100]，就会把原本在nums[0]的数据替换掉。如果接下来cpu又读nums[0]。。那么就又要从内存中获取。</p><p>也就是说，老师问的对cpu友好，说的并不是你理解的时间复杂度。而是对于这种从高速缓存读取数据的行为。顺便说一句，在《深入理解操作系统中》中把要读取的数据附近的数据一起拖到高速缓存的行为，叫空间局部性。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="算法" scheme="https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="数据结构" scheme="https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    <category term="算法" scheme="https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="数组" scheme="https://matthew-han.github.io/tags/%E6%95%B0%E7%BB%84/"/>
    
    <category term="内存" scheme="https://matthew-han.github.io/tags/%E5%86%85%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>LeetCode 第 243 场周赛</title>
    <link href="https://matthew-han.github.io/post/7f7138a0-c736-11eb-a4ac-bd3aa37357c3/"/>
    <id>https://matthew-han.github.io/post/7f7138a0-c736-11eb-a4ac-bd3aa37357c3/</id>
    <published>2021-06-07T02:17:24.000Z</published>
    <updated>2025-09-03T02:52:50.971Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Problem-Description"><a href="#Problem-Description" class="headerlink" title="Problem Description"></a>Problem Description</h1><ul><li><p>给你两个下标从 <code>0</code> 开始的整数数组 <code>servers</code> 和 <code>tasks</code> ，长度分别为 <code>n</code> 和 <code>m</code> 。<code>servers[i]</code> 是第 <code>i</code> 台服务器的<strong>权重</strong> ，而 <code>tasks[j] </code>是处理第 <code>j</code> 项任务<strong>所需要的时间</strong>（单位：秒）。</p></li><li><p>你正在运行一个仿真系统，在处理完所有任务后，该系统将会关闭。每台服务器只能同时处理一项任务。第 <code>0</code> 项任务在第 <code>0</code> 秒可以开始处理，相应地，第 <code>j</code> 项任务在第 <code>j</code> 秒可以开始处理。处理第 <code>j</code> 项任务时，你需要为它分配一台<strong>权重最小</strong>的空闲服务器。如果存在多台相同权重的空闲服务器，请选择<strong>下标最小</strong>的服务器。如果一台空闲服务器在第 <code>t</code> 秒分配到第 <code>j</code> 项任务，那么在 <code>t + tasks[j]</code> 时它将恢复空闲状态。</p></li><li><p>如果没有空闲服务器，则必须等待，直到出现一台空闲服务器，并<strong>尽可能早</strong>地处理剩余任务。 如果有多项任务等待分配，则按照<strong>下标递增</strong>的顺序完成分配。</p></li><li><p>如果同一时刻存在多台空闲服务器，可以同时将多项任务分别分配给它们。</p></li><li><p>构建长度为 <code>m</code> 的答案数组 <code>ans</code> ，其中 <code>ans[j]</code> 是第 <code>j</code> 项任务分配的服务器的下标。</p></li><li><p>返回答案数组 <code>ans</code> 。</p></li></ul><h2 id="note"><a href="#note" class="headerlink" title="note"></a>note</h2><ul><li><code>servers.length == n</code></li><li><code>tasks.length == m</code></li><li><code>1 &lt;= n, m &lt;= 2 * 105</code></li><li><code>1 &lt;= servers[i], tasks[j] &lt;= 2 * 105</code></li></ul><h2 id="e-g"><a href="#e-g" class="headerlink" title="e.g."></a>e.g.</h2><ul><li><p><strong>示例 1：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">输入：servers = [3,3,2], tasks = [1,2,3,2,1,2]</span><br><span class="line">输出：[2,2,0,2,1,2]</span><br><span class="line">解释：事件按时间顺序如下：</span><br><span class="line"></span><br><span class="line">0 秒时，第 0 项任务加入到任务队列，使用第 2 台服务器处理到 1 秒。</span><br><span class="line">1 秒时，第 2 台服务器空闲，第 1 项任务加入到任务队列，使用第 2 台服务器处理到 3 秒。</span><br><span class="line">2 秒时，第 2 项任务加入到任务队列，使用第 0 台服务器处理到 5 秒。</span><br><span class="line">3 秒时，第 2 台服务器空闲，第 3 项任务加入到任务队列，使用第 2 台服务器处理到 5 秒。</span><br><span class="line">4 秒时，第 4 项任务加入到任务队列，使用第 1 台服务器处理到 5 秒。</span><br><span class="line">5 秒时，所有服务器都空闲，第 5 项任务加入到任务队列，使用第 2 台服务器处理到 7 秒。</span><br></pre></td></tr></table></figure></li><li><p><strong>示例 2：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">输入：servers = [5,1,4,3,2], tasks = [2,1,2,4,5,2,1]</span><br><span class="line">输出：[1,4,1,4,1,3,2]</span><br><span class="line">解释：事件按时间顺序如下：</span><br><span class="line"></span><br><span class="line">0 秒时，第 0 项任务加入到任务队列，使用第 1 台服务器处理到 2 秒。</span><br><span class="line">1 秒时，第 1 项任务加入到任务队列，使用第 4 台服务器处理到 2 秒。</span><br><span class="line">2 秒时，第 1 台和第 4 台服务器空闲，第 2 项任务加入到任务队列，使用第 1 台服务器处理到 4 秒。</span><br><span class="line">3 秒时，第 3 项任务加入到任务队列，使用第 4 台服务器处理到 7 秒。</span><br><span class="line">4 秒时，第 1 台服务器空闲，第 4 项任务加入到任务队列，使用第 1 台服务器处理到 9 秒。</span><br><span class="line">5 秒时，第 5 项任务加入到任务队列，使用第 3 台服务器处理到 7 秒。</span><br><span class="line">6 秒时，第 6 项任务加入到任务队列，使用第 2 台服务器处理到 7 秒。</span><br></pre></td></tr></table></figure></li></ul><h1 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h1><p>第 243 场周赛的第三题，虽然这场没参加（周赛基本都起不来），不过后来做了下还挺有趣，<code>TLE</code> 了一发，感觉很适合拿来面试的考察求职者的代码设计以及优化能力。主要考察堆排序、队列、多任务处理这些点。</p><blockquote><p>甚至我都快想要开多个线程来做了。</p></blockquote><p>这题可以直接模拟，模拟法需要注意的三个地方吧，不然会超时：</p><ol start="0"><li>注意存在某个时刻会出现多个任务可被执行</li><li>防止 TLE ：直接跳转到运行队列中的最先空闲下来的服务器时间节点</li><li>防止 TLE ：两个优先队列处理（运行态和就绪态）</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span>[] assignTasks(<span class="type">int</span>[] servers, <span class="type">int</span>[] tasks) &#123;</span><br><span class="line">        <span class="type">int</span>[] ans = <span class="keyword">new</span> <span class="title class_">int</span>[tasks.length];</span><br><span class="line">        <span class="comment">// 运行态</span></span><br><span class="line">        <span class="comment">// 运行中的服务器, 之前这里是 Queue, 没有及时 break, 所以拉了</span></span><br><span class="line">        <span class="comment">// int[]: 长度为 2, 第 1 位是 serverId, 第 2 位是当前时间 + task 需要执行的时长</span></span><br><span class="line">        PriorityQueue&lt;<span class="type">int</span>[]&gt; runtimeServerQueue = <span class="keyword">new</span> <span class="title class_">PriorityQueue</span>&lt;&gt;((o1, o2) -&gt; &#123;</span><br><span class="line">            <span class="keyword">return</span> Integer.compare(o1[<span class="number">1</span>], o2[<span class="number">1</span>]);</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">// 就绪态</span></span><br><span class="line">        <span class="comment">// 等待被分配的服务器</span></span><br><span class="line">        <span class="comment">// int[]: 长度为 2, 第 1 位是 serverId, 第 2 位是服务器权重</span></span><br><span class="line">        PriorityQueue&lt;<span class="type">int</span>[]&gt; pendingServerQueue = <span class="keyword">new</span> <span class="title class_">PriorityQueue</span>&lt;&gt;((o1, o2) -&gt; &#123;</span><br><span class="line">            <span class="comment">// 先判权重升序, 权重一样, 则按照下标升序</span></span><br><span class="line">            <span class="keyword">if</span> (o1[<span class="number">1</span>] == o2[<span class="number">1</span>]) &#123;</span><br><span class="line">                <span class="keyword">return</span> Integer.compare(o1[<span class="number">0</span>], o2[<span class="number">0</span>]);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> Integer.compare(o1[<span class="number">1</span>], o2[<span class="number">1</span>]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">// 先将所有的服务器塞到等待队列中</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; servers.length; i++) &#123;</span><br><span class="line">            pendingServerQueue.offer(<span class="keyword">new</span> <span class="title class_">int</span>[]&#123;i, servers[i]&#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 每秒需要被执行的任务</span></span><br><span class="line">        Queue&lt;Integer&gt; taskQueue = <span class="keyword">new</span> <span class="title class_">LinkedList</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> t : tasks) &#123;</span><br><span class="line">            taskQueue.offer(t);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">int</span> <span class="variable">sec</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">trueSec</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (!taskQueue.isEmpty()) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">b</span> <span class="operator">=</span> <span class="number">0x3f3f3f3f</span>;</span><br><span class="line">            <span class="comment">// step0. 先处理在运行的 serverQueue</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">limit</span> <span class="operator">=</span> runtimeServerQueue.size();</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; limit; i++) &#123;</span><br><span class="line">                <span class="type">int</span>[] task = runtimeServerQueue.poll();</span><br><span class="line">                <span class="comment">// 根据当前和当前储存的预期完成时间比较, 一致则说明任务完成</span></span><br><span class="line">                <span class="keyword">if</span> (task[<span class="number">1</span>] == trueSec) &#123;</span><br><span class="line">                    <span class="comment">// 加入到等待队列</span></span><br><span class="line">                    pendingServerQueue.offer(<span class="keyword">new</span> <span class="title class_">int</span>[]&#123;task[<span class="number">0</span>], servers[task[<span class="number">0</span>]]&#125;);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">// b: 运行中的服务器中最先会空闲的预期时间</span></span><br><span class="line">                    b = Math.min(b, task[<span class="number">1</span>]);</span><br><span class="line">                    runtimeServerQueue.offer(task);</span><br><span class="line">                    <span class="comment">// 因为是优先队列, 一旦 else 了, Queue 后面服务器都不可能是这个时间节点完成</span></span><br><span class="line">                    <span class="comment">// 所以这里可以 break, 不然会 TLE</span></span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// step1. 选择 空闲 / 权重最小 / 下标最小 的服务器</span></span><br><span class="line">            <span class="comment">// 存在空闲服务器</span></span><br><span class="line">            <span class="keyword">if</span> (!pendingServerQueue.isEmpty()) &#123;</span><br><span class="line">                <span class="comment">// 因为可能轮转了很多轮, 所以 taskQueue 里面的很多任务都可以在当前时间执行了(可能会有多个任务可执行)</span></span><br><span class="line">                <span class="keyword">while</span> (sec &lt; trueSec &amp;&amp; !taskQueue.isEmpty() &amp;&amp; !pendingServerQueue.isEmpty()) &#123;</span><br><span class="line">                    <span class="type">int</span> <span class="variable">task</span> <span class="operator">=</span> taskQueue.poll();</span><br><span class="line">                    <span class="type">int</span>[] runnableServer = pendingServerQueue.poll();</span><br><span class="line">                    ans[sec++] = runnableServer[<span class="number">0</span>];</span><br><span class="line">                    <span class="comment">// 将 空闲的服务器 加入到 运行的服务器队列 中</span></span><br><span class="line">                    runtimeServerQueue.offer(<span class="keyword">new</span> <span class="title class_">int</span>[]&#123;runnableServer[<span class="number">0</span>], trueSec + task&#125;);</span><br><span class="line">                &#125;</span><br><span class="line">                trueSec++;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 防止 TLE 关键, 跳转到 runtime 服务器最先空闲的时间节点</span></span><br><span class="line">                trueSec = b;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="算法" scheme="https://matthew-han.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="数据结构" scheme="https://matthew-han.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    <category term="算法" scheme="https://matthew-han.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="leetcode" scheme="https://matthew-han.github.io/tags/leetcode/"/>
    
    <category term="队列" scheme="https://matthew-han.github.io/tags/%E9%98%9F%E5%88%97/"/>
    
    <category term="堆排序" scheme="https://matthew-han.github.io/tags/%E5%A0%86%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>位运算算法题小技巧</title>
    <link href="https://matthew-han.github.io/post/ec90b090-774b-11eb-ac09-a1bcb7588087/"/>
    <id>https://matthew-han.github.io/post/ec90b090-774b-11eb-ac09-a1bcb7588087/</id>
    <published>2021-02-25T09:29:13.000Z</published>
    <updated>2025-09-03T02:52:50.977Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h1><p>位运算的效率就不说了，每次学会一些小技巧就忘了，还是基础不够扎实吧。。</p><ol><li>计算某个 <code>int</code> 值的第 <code>i</code> 位（二进制位）是什么，可以用 <code>num &gt;&gt; i;</code> 有符号右移，不要在用 <code>Integer</code> 的 API 了</li><li>0 与 1 的转换（仅存在 1 与 0），<code>num = 1 - num;</code></li><li>汉明码常用：<code>for (int i = 0; i &lt; 32; i++) &#123;&#125;</code> 懂得都懂</li><li>汉明码常用：多个数计算汉明码距离，只要找到 1 的个数和 0 的个数相乘即可</li><li><code>num1</code> 与 <code>num2</code> 不用缓存 tmp 的交换，<code>num1 ^= num2;</code> <code>num2 ^= num1;</code> <code>num1 ^= num2;</code> 但是要记住 <code>num1</code> 与 <code>num2</code> 不能相等，不然会直接等于 0</li><li>判断奇偶这个老是记不住，<code>(num &amp; 1 == 0);</code> 因为任何二进制位和 1 做 <code>&amp;</code> 运算都是本身，偶数的末尾是 0</li><li><code>x ^ y ^ x = y</code>，<code>x ^ 0 = x</code>这个经常多用用，前缀和、异或的题属于是考麻了！</li><li>后续再更…</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="Java 技巧" scheme="https://matthew-han.github.io/categories/Java-%E6%8A%80%E5%B7%A7/"/>
    
    
    <category term="位运算" scheme="https://matthew-han.github.io/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>千千万万设计模式之装饰器模式</title>
    <link href="https://matthew-han.github.io/post/ecde1650-5185-11eb-84eb-99b80bd7ffbc/"/>
    <id>https://matthew-han.github.io/post/ecde1650-5185-11eb-84eb-99b80bd7ffbc/</id>
    <published>2021-01-08T07:48:41.000Z</published>
    <updated>2025-09-03T02:52:50.977Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="装饰器模式"><a href="#装饰器模式" class="headerlink" title="装饰器模式"></a>装饰器模式</h1><p>未完待续…</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="设计模式" scheme="https://matthew-han.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
    <category term="设计模式" scheme="https://matthew-han.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    <category term="装饰器模式" scheme="https://matthew-han.github.io/tags/%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式事务与 Seata 初探</title>
    <link href="https://matthew-han.github.io/post/2752cd30-3a98-11eb-b0c9-0b16b97a2613/"/>
    <id>https://matthew-han.github.io/post/2752cd30-3a98-11eb-b0c9-0b16b97a2613/</id>
    <published>2020-12-10T03:31:13.000Z</published>
    <updated>2025-09-03T02:52:50.977Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h1><p>布式事务的实现有很多种，最具有代表性的是由<strong>Oracle Tuxedo</strong>系统提出的<strong>XA</strong>分布式事务协议。</p><p>XA协议包含<strong>两阶段提交</strong>（2PC）和<strong>三阶段提交</strong>（3PC）两种实现。</p><p>当然该协议主要是一种理论方式，具体落地有相应的组件（Seata等）或者代码中自行实现。</p><h2 id="二段式提交"><a href="#二段式提交" class="headerlink" title="二段式提交"></a>二段式提交</h2><p><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/NtO5sialJZGp2Ny2lbXKGqaNjy4cbhqofVRL815UNR3mnXpYf81U5Lv5WtNiamohdu792UPtCuHhNLkg7FGMvicFw/640?wx_fmt=png"></p><p>当队员收到就位确认提示后，如果已经就位，就选择“是”，如果还没就位，就选择“否”。</p><p><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/NtO5sialJZGp2Ny2lbXKGqaNjy4cbhqofqPopLXT6ALzBz6elibzNxT8XoQSaEgXdJjYuRbkKV65HtVDLFibeWvVw/640?wx_fmt=png"></p><p>相应的，在队长发起就位确认的时候，有可能某些队员还并没有就位。</p><p><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/NtO5sialJZGp2Ny2lbXKGqaNjy4cbhqofYaNSnxNnZfsXwxhdicfIrx0bD8BY5GiaVBqxphFcdsuJgrdPX1iaetuOg/640?wx_fmt=png"></p><p><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/NtO5sialJZGp2Ny2lbXKGqaNjy4cbhqofqxmWafL4tcIcMFcHhAcR1AX3QvS9Fw5JCC0dPTOYvtlUSJic4uibuZHg/640?wx_fmt=png"></p><p>那么XA协议究竟是什么样子呢？在XA协议中包含着两个角色：<strong>事务协调者</strong>和<strong>事务参与者</strong>。</p><h3 id="成功的流程"><a href="#成功的流程" class="headerlink" title="成功的流程"></a>成功的流程</h3><p>让我们来看一看他们之间的交互流程：</p><p>在XA分布式事务的第一阶段，作为事务协调者的节点会首先向所有的参与者节点发送Prepare请求。</p><p>在接到Prepare请求之后，每一个参与者节点会各自执行与事务有关的数据更新，写入Undo Log和Redo Log。如果参与者执行成功，暂时不提交事务，而是向事务协调节点返回“完成”消息。</p><p>当事务协调者接到了所有参与者的返回消息，整个分布式事务将会进入第二阶段。</p><p>在XA分布式事务的第二阶段，如果事务协调节点在之前所收到都是正向返回，那么它将会向所有事务参与者发出Commit请求。</p><p>接到Commit请求之后，事务参与者节点会各自进行本地的事务提交，并释放锁资源。当本地事务完成提交后，将会向事务协调者返回“完成”消息。</p><p>当事务协调者接收到所有事务参与者的“完成”反馈，整个分布式事务完成。</p><h3 id="失败的流程"><a href="#失败的流程" class="headerlink" title="失败的流程"></a>失败的流程</h3><p>在XA的第一阶段，如果某个事务参与者反馈失败消息，说明该节点的本地事务执行不成功，必须回滚。</p><p>于是在第二阶段，事务协调节点向所有的事务参与者发送Abort请求。接收到Abort请求之后，各个事务参与者节点需要在本地进行事务的回滚操作，回滚操作依照Undo Log来进行。</p><p>以上就是XA两阶段提交协议的详细过程。</p><h3 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h3><p>首先 2PC 是一个<strong>同步阻塞协议</strong>，像第一阶段协调者会等待所有参与者响应才会进行下一步操作，当然第一阶段的<strong>协调者有超时机制</strong>，假设因为网络原因没有收到某参与者的响应或某参与者挂了，那么超时后就会判断事务失败，向所有参与者发送回滚命令。</p><h3 id="二段式提交的不足"><a href="#二段式提交的不足" class="headerlink" title="二段式提交的不足"></a>二段式提交的不足</h3><ol><li><strong>性能问题</strong></li></ol><p>XA协议遵循强一致性。在事务执行过程中，各个节点占用着数据库资源，只有当所有节点准备完毕，事务协调者才会通知提交，参与者提交后释放资源。这样的过程有着非常明显的性能问题。</p><ol start="2"><li><strong>协调者单点故障问题</strong></li></ol><p>事务协调者是整个XA模型的核心，一旦事务协调者节点挂掉，参与者收不到提交或是回滚通知，参与者会一直处于中间状态无法完成事务。（参与者不具备超时机制）</p><ol start="3"><li><strong>丢失消息导致的不一致问题。</strong></li></ol><p>在XA协议的第二个阶段，如果发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就导致了节点之间数据的不一致。</p><h2 id="三段式提交"><a href="#三段式提交" class="headerlink" title="三段式提交"></a>三段式提交</h2><ol><li><strong>MQ事务</strong></li></ol><p>利用消息中间件来异步完成事务的后一半更新，实现系统的最终一致性。这个方式避免了像XA协议那样的性能问题。</p><ol start="2"><li><strong>XA三阶段提交</strong></li></ol><p>XA三阶段提交在两阶段提交的基础上增加了CanCommit阶段，并且引入了超时机制。一旦事物参与者迟迟没有接到协调者的commit请求，会自动进行本地commit。这样有效解决了协调者单点故障的问题。但是性能问题和不一致的问题仍然没有根本解决。</p><p><img src="https://pic3.zhimg.com/80/v2-885daf4ba34102d6e1047b0b67910652_1440w.jpg"></p><ol start="3"><li><strong>TCC事务</strong></li></ol><p>TCC事务是Try - Confirm - Cancel三种指令的缩写，其逻辑模式类似于XA两阶段提交，但是实现方式是在代码层面来人为实现。</p><p>其实从思想上看和 2PC 差不多，都是先试探性的执行，如果都可以那就真正的执行，如果不行就回滚。</p><p><strong>比如说一个事务要执行A、B、C三个操作，那么先对三个操作执行预留动作。如果都预留成功了那么就执行确认操作，如果有一个预留失败那就都执行撤销动作。</strong></p><p><img src="https://pic4.zhimg.com/80/v2-90179fa933c0a389ffa6ac04e244a58f_1440w.jpg"></p><p>TCC 对业务代码的侵入较大，开发量也比较大但是提供了较好的性能。</p><h4 id="XA-和-TCC-的区别"><a href="#XA-和-TCC-的区别" class="headerlink" title="XA 和 TCC 的区别"></a>XA 和 TCC 的区别</h4><p>XA 是一整个长事务，对数据库进行加锁，所以性能拉胯而且会有长事务风险。但是 TCC 是几个小事务（本地事务），最终一致性，不会出现长事务的锁风险，保证分布式性能。</p><p>在 Seata 中如需改造成 TCC 模式，需要加上核心注解<code>@LocalTCC</code>，并写三个接口，分别对应 Try - Confirm - Cancel，如<code>saveOrder()</code>、<code>commit()</code>、<code>rollbackTcc()</code>方法。代码量确实会大一些，并且后期维护加重。</p><h2 id="Seata"><a href="#Seata" class="headerlink" title="Seata"></a>Seata</h2><p>TC：seata 服务端</p><p>TM：<code>@GlobalTransactional</code>注解的方法，事务的发起方</p><p>RM：一个数据库就是 RM，事务的参与方</p><p>TM 开启分布式事务，TM 向 TC 注册全局事务记录</p><p>业务场景，编排数据库，服务等事务内资源，RM 向 TC 报备资源准备状态</p><p>TM 结束分布式事务，事务一阶段结束（TM 通知 TC 提交或回滚分布式事务）</p><p>TC 汇总事务信息，决定分布式事务是提交还是回滚</p><p>TC 通知所有 RM 提交或回滚资源，事务二阶段结束</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text&amp;#x2F;css&quot; href=&quot;https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css&quot;&gt;&lt;link rel=&quot;st</summary>
      
    
    
    
    <category term="Java技术" scheme="https://matthew-han.github.io/categories/Java%E6%8A%80%E6%9C%AF/"/>
    
    
    <category term="分布式事务" scheme="https://matthew-han.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    
    <category term="Seata" scheme="https://matthew-han.github.io/tags/Seata/"/>
    
    <category term="中间件" scheme="https://matthew-han.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
</feed>
